
CondaError: Run 'conda init' before 'conda activate'

/next/u/stephhk/miniconda3/envs/rl/lib/python3.10/site-packages/ray/_private/parameter.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.
Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.
See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.
/next/u/stephhk/miniconda3/envs/rl/lib/python3.10/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
2025-11-04 18:51:47,565	WARNING deprecation.py:50 -- DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!
/next/u/stephhk/standalone_envs_for_yoonho/flow_reward_misspecification/flow/utils/flow_warnings.py:23: PendingDeprecationWarning: The attribute minGap in SumoCarFollowingParams is deprecated, use min_gap instead.
  warnings.warn(
2025-11-04 18:52:01,130	INFO worker.py:1642 -- Started a local Ray instance.
2025-11-04 18:52:27,580	WARNING algorithm_config.py:2578 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.
2025-11-04 18:52:27,581	WARNING algorithm_config.py:2592 -- Setting `exploration_config={'type': 'StochasticSampling'}` because you set `_enable_rl_module_api=False`. This exploration config was restored from a prior exploration config that was overriden when setting `_enable_rl_module_api=True`. This occurs because when RLModule API are enabled, exploration_config can not be set.
2025-11-04 18:52:27,584	WARNING algorithm_config.py:2578 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.
/next/u/stephhk/miniconda3/envs/rl/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:484: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
`UnifiedLogger` will be removed in Ray 2.7.
  return UnifiedLogger(config, logdir, loggers=None)
/next/u/stephhk/miniconda3/envs/rl/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/next/u/stephhk/miniconda3/envs/rl/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/next/u/stephhk/miniconda3/envs/rl/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
[2m[36m(pid=3144231)[0m Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.
[2m[36m(pid=3144231)[0m Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.
[2m[36m(pid=3144231)[0m See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.
[2m[36m(pid=3144225)[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!
[2m[36m(RolloutWorker pid=3144225)[0m /next/u/stephhk/standalone_envs_for_yoonho/flow_reward_misspecification/flow/utils/flow_warnings.py:23: PendingDeprecationWarning: The attribute minGap in SumoCarFollowingParams is deprecated, use min_gap instead.
[2m[36m(RolloutWorker pid=3144225)[0m   warnings.warn(
[2m[36m(pid=3144227)[0m Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.[32m [repeated 9x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)[0m
[2m[36m(pid=3144227)[0m Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.[32m [repeated 9x across cluster][0m
[2m[36m(pid=3144227)[0m See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.[32m [repeated 9x across cluster][0m
[2m[36m(RolloutWorker pid=3144231)[0m 2025-11-04 18:52:39,547	WARNING algorithm_config.py:2578 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.
[2m[36m(RolloutWorker pid=3144225)[0m 2025-11-04 18:52:39,571	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!
[2m[36m(RolloutWorker pid=3144225)[0m 2025-11-04 18:52:39,572	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!
[2m[36m(RolloutWorker pid=3144231)[0m 2025-11-04 18:52:39,732	WARNING catalog.py:629 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
[2m[36m(RolloutWorker pid=3144225)[0m 2025-11-04 18:52:42,507	WARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!
[2m[36m(RolloutWorker pid=3144225)[0m 2025-11-04 18:52:42,507	WARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!
[2m[36m(RolloutWorker pid=3144225)[0m 2025-11-04 18:52:42,507	WARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!
[2m[36m(RolloutWorker pid=3144225)[0m 2025-11-04 18:52:42,507	WARNING deprecation.py:50 -- DeprecationWarning: `KLCoeffMixin` has been deprecated. This will raise an error in the future!
[2m[36m(pid=3144227)[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future![32m [repeated 9x across cluster][0m
[2m[36m(RolloutWorker pid=3144225)[0m 2025-11-04 18:52:42,737	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!
2025-11-04 18:52:42,924	WARNING algorithm_config.py:2578 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.
2025-11-04 18:52:42,926	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!
2025-11-04 18:52:42,926	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!
2025-11-04 18:52:42,939	WARNING catalog.py:629 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
2025-11-04 18:52:45,270	WARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!
2025-11-04 18:52:45,271	WARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!
2025-11-04 18:52:45,271	WARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!
2025-11-04 18:52:45,271	WARNING deprecation.py:50 -- DeprecationWarning: `KLCoeffMixin` has been deprecated. This will raise an error in the future!
2025-11-04 18:52:45,281	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!
2025-11-04 18:52:45,315	INFO trainable.py:188 -- Trainable.setup took 15.260 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2025-11-04 18:52:45,316	WARNING util.py:68 -- Install gputil for GPU system monitoring.
2025-11-04 18:52:45,463	WARNING catalog.py:629 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']!
discriminator weights do not match the current discriminator architecture; ignoring discriminator weights
2025-11-04 18:57:32,678	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.multi_gpu_train_one_step` has been deprecated. This will raise an error in the future!
registering env
âœ” warm-started policy from /next/u/stephhk/orpo/data/base_policy_checkpoints/pandemic_base_policy/checkpoint_000100/policies/default_policy
Saved checkpoint to TrainingResult(checkpoint=Checkpoint(filesystem=local, path=logs/data/pandemic/20251104_185246/checkpoint_0), metrics={})
Iteration 1/100
{'custom_metrics': {'default_policy/true_reward_mean': -11.420874999999988, 'default_policy/true_reward_min': -15.237499999999981, 'default_policy/true_reward_max': -5.51250000000002, 'default_policy/proxy_reward_mean': -11.420874999999988, 'default_policy/proxy_reward_min': -15.237499999999981, 'default_policy/proxy_reward_max': -5.51250000000002, 'default_policy/modified_reward_mean': -12.368886011153391, 'default_policy/modified_reward_min': -16.17505624724525, 'default_policy/modified_reward_max': -6.490526301083181, 'default_policy/corr_btw_rewards_mean': 1.0, 'default_policy/corr_btw_rewards_min': 0.9999999999999998, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -11.420874999999988, 'true_reward_min': -15.237499999999981, 'true_reward_max': -5.51250000000002, 'proxy_reward_mean': -11.420874999999988, 'proxy_reward_min': -15.237499999999981, 'proxy_reward_max': -5.51250000000002, 'modified_reward_mean': -12.368886011153391, 'modified_reward_min': -16.17505624724525, 'modified_reward_max': -6.490526301083181, 'proxyInfectionSummaryAbsoluteReward_mean': -0.005007253886010365, 'proxyInfectionSummaryAbsoluteReward_min': -0.006994818652849745, 'proxyInfectionSummaryAbsoluteReward_max': -0.0019170984455958557, 'proxyLowerStageReward_mean': -0.091029792746114, 'proxyLowerStageReward_min': -0.10038860103626943, 'proxyLowerStageReward_max': -0.08419689119170984, 'proxySmoothStageChangesReward_mean': 0.0, 'proxySmoothStageChangesReward_min': 0.0, 'proxySmoothStageChangesReward_max': 0.0, 'trueInfectionSummaryAbsoluteReward_mean': -0.005007253886010365, 'trueInfectionSummaryAbsoluteReward_min': -0.006994818652849745, 'trueInfectionSummaryAbsoluteReward_max': -0.0019170984455958557, 'truePoliticalReward_mean': 0.0, 'truePoliticalReward_min': 0.0, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.091029792746114, 'trueLowerStageReward_min': -0.10038860103626943, 'trueLowerStageReward_max': -0.08419689119170984, 'trueSmoothStageChangesReward_mean': 0.0, 'trueSmoothStageChangesReward_min': 0.0, 'trueSmoothStageChangesReward_max': 0.0, 'total_modified_reward_mean': -12.368886011153391, 'total_modified_reward_min': -16.17505624724525, 'total_modified_reward_max': -6.490526301083181}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 3.2536868799726166, 'cur_kl_coeff': 0.19999999999999998, 'cur_lr': 0.0003, 'total_loss': 0.21701400857418776, 'policy_loss': 0.008884807044329743, 'vf_loss': 0.5120072566283246, 'vf_explained_var': 0.24697334190209708, 'kl': 0.013715197631964757, 'entropy': 0.5061746672789256, 'entropy_coeff': 0.09999999999999999}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 150.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 3860, 'num_env_steps_trained': 3860, 'num_agent_steps_sampled': 3860, 'num_agent_steps_trained': 3860}, 'sampler_results': {'episode_reward_max': -6.490526301083181, 'episode_reward_min': -16.17505624724525, 'episode_reward_mean': -12.368886011153391, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -11.420874999999988, 'default_policy/true_reward_min': -15.237499999999981, 'default_policy/true_reward_max': -5.51250000000002, 'default_policy/proxy_reward_mean': -11.420874999999988, 'default_policy/proxy_reward_min': -15.237499999999981, 'default_policy/proxy_reward_max': -5.51250000000002, 'default_policy/modified_reward_mean': -12.368886011153391, 'default_policy/modified_reward_min': -16.17505624724525, 'default_policy/modified_reward_max': -6.490526301083181, 'default_policy/corr_btw_rewards_mean': 1.0, 'default_policy/corr_btw_rewards_min': 0.9999999999999998, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -11.420874999999988, 'true_reward_min': -15.237499999999981, 'true_reward_max': -5.51250000000002, 'proxy_reward_mean': -11.420874999999988, 'proxy_reward_min': -15.237499999999981, 'proxy_reward_max': -5.51250000000002, 'modified_reward_mean': -12.368886011153391, 'modified_reward_min': -16.17505624724525, 'modified_reward_max': -6.490526301083181, 'proxyInfectionSummaryAbsoluteReward_mean': -0.005007253886010365, 'proxyInfectionSummaryAbsoluteReward_min': -0.006994818652849745, 'proxyInfectionSummaryAbsoluteReward_max': -0.0019170984455958557, 'proxyLowerStageReward_mean': -0.091029792746114, 'proxyLowerStageReward_min': -0.10038860103626943, 'proxyLowerStageReward_max': -0.08419689119170984, 'proxySmoothStageChangesReward_mean': 0.0, 'proxySmoothStageChangesReward_min': 0.0, 'proxySmoothStageChangesReward_max': 0.0, 'trueInfectionSummaryAbsoluteReward_mean': -0.005007253886010365, 'trueInfectionSummaryAbsoluteReward_min': -0.006994818652849745, 'trueInfectionSummaryAbsoluteReward_max': -0.0019170984455958557, 'truePoliticalReward_mean': 0.0, 'truePoliticalReward_min': 0.0, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.091029792746114, 'trueLowerStageReward_min': -0.10038860103626943, 'trueLowerStageReward_max': -0.08419689119170984, 'trueSmoothStageChangesReward_mean': 0.0, 'trueSmoothStageChangesReward_min': 0.0, 'trueSmoothStageChangesReward_max': 0.0, 'total_modified_reward_mean': -12.368886011153391, 'total_modified_reward_min': -16.17505624724525, 'total_modified_reward_max': -6.490526301083181}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5497775952637349, 'mean_inference_ms': 1.7638021045260956, 'mean_action_processing_ms': 0.11366953837471108, 'mean_env_wait_ms': 731.1398219692614, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -6.490526301083181, 'episode_reward_min': -16.17505624724525, 'episode_reward_mean': -12.368886011153391, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5497775952637349, 'mean_inference_ms': 1.7638021045260956, 'mean_action_processing_ms': 0.11366953837471108, 'mean_env_wait_ms': 731.1398219692614, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 3860, 'num_agent_steps_trained': 3860, 'num_env_steps_sampled': 3860, 'num_env_steps_trained': 3860, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.464663857436683, 'num_env_steps_trained_throughput_per_sec': 13.464663857436683, 'timesteps_total': 3860, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 3860, 'timers': {'training_iteration_time_ms': 286676.233, 'sample_time_ms': 285660.308, 'load_time_ms': 0.322, 'load_throughput': 11992602.548, 'learn_time_ms': 999.668, 'learn_throughput': 3861.282, 'synch_weights_time_ms': 14.604}, 'counters': {'num_env_steps_sampled': 3860, 'num_env_steps_trained': 3860, 'num_agent_steps_sampled': 3860, 'num_agent_steps_trained': 3860}, 'done': False, 'episodes_total': 20, 'training_iteration': 1, 'trial_id': 'default', 'date': '2025-11-04_18-57-33', 'timestamp': 1762311453, 'time_this_iter_s': 286.68585991859436, 'time_total_s': 286.68585991859436, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e2512230>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e2511810>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2511ae0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2511fc0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 286.68585991859436, 'iterations_since_restore': 1, 'perf': {'cpu_util_percent': 19.498300970873785, 'ram_util_percent': 5.520388349514564}}
Iteration 2/100
{'custom_metrics': {'default_policy/true_reward_mean': -11.643543965521921, 'default_policy/true_reward_min': -28.120521279348136, 'default_policy/true_reward_max': -5.51250000000002, 'default_policy/proxy_reward_mean': -10.74354396552192, 'default_policy/proxy_reward_min': -15.237499999999981, 'default_policy/proxy_reward_max': -4.8201659402887005, 'default_policy/modified_reward_mean': -11.995701500538758, 'default_policy/modified_reward_min': -16.17505624724525, 'default_policy/modified_reward_max': -6.490526301083181, 'default_policy/corr_btw_rewards_mean': 0.942666601967745, 'default_policy/corr_btw_rewards_min': 0.10701637698393927, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -11.643543965521921, 'true_reward_min': -28.120521279348136, 'true_reward_max': -5.51250000000002, 'proxy_reward_mean': -10.74354396552192, 'proxy_reward_min': -15.237499999999981, 'proxy_reward_max': -4.8201659402887005, 'modified_reward_mean': -11.995701500538758, 'modified_reward_min': -16.17505624724525, 'modified_reward_max': -6.490526301083181, 'proxyInfectionSummaryAbsoluteReward_mean': -0.004382383419689122, 'proxyInfectionSummaryAbsoluteReward_min': -0.006994818652849745, 'proxyInfectionSummaryAbsoluteReward_max': -3.108808290155441e-05, 'proxyLowerStageReward_mean': -0.11629761479388238, 'proxyLowerStageReward_min': -0.24458659478487244, 'proxyLowerStageReward_max': -0.08008863617195101, 'proxySmoothStageChangesReward_mean': -0.021243523316062173, 'proxySmoothStageChangesReward_min': -0.09326424870466321, 'proxySmoothStageChangesReward_max': 0.0, 'trueInfectionSummaryAbsoluteReward_mean': -0.004382383419689122, 'trueInfectionSummaryAbsoluteReward_min': -0.006994818652849745, 'trueInfectionSummaryAbsoluteReward_max': -3.108808290155441e-05, 'truePoliticalReward_mean': -0.000466321243523316, 'truePoliticalReward_min': -0.01160621761658031, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.11629761479388238, 'trueLowerStageReward_min': -0.24458659478487244, 'trueLowerStageReward_max': -0.08008863617195101, 'trueSmoothStageChangesReward_mean': -0.021243523316062173, 'trueSmoothStageChangesReward_min': -0.09326424870466321, 'trueSmoothStageChangesReward_max': 0.0, 'total_modified_reward_mean': -11.995701500538758, 'total_modified_reward_min': -16.17505624724525, 'total_modified_reward_max': -6.490526301083181}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 2.67760388592879, 'cur_kl_coeff': 0.19999999999999998, 'cur_lr': 0.0003, 'total_loss': 0.08455723544427504, 'policy_loss': -0.0012205653203030428, 'vf_loss': 0.3022812778071966, 'vf_explained_var': 0.3494005811214447, 'kl': 0.024166495977271274, 'entropy': 0.7068727281689644, 'entropy_coeff': 0.0993052}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 450.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 7720, 'num_env_steps_trained': 7720, 'num_agent_steps_sampled': 7720, 'num_agent_steps_trained': 7720}, 'sampler_results': {'episode_reward_max': -6.490526301083181, 'episode_reward_min': -16.17505624724525, 'episode_reward_mean': -11.995701500538758, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -11.643543965521921, 'default_policy/true_reward_min': -28.120521279348136, 'default_policy/true_reward_max': -5.51250000000002, 'default_policy/proxy_reward_mean': -10.74354396552192, 'default_policy/proxy_reward_min': -15.237499999999981, 'default_policy/proxy_reward_max': -4.8201659402887005, 'default_policy/modified_reward_mean': -11.995701500538758, 'default_policy/modified_reward_min': -16.17505624724525, 'default_policy/modified_reward_max': -6.490526301083181, 'default_policy/corr_btw_rewards_mean': 0.942666601967745, 'default_policy/corr_btw_rewards_min': 0.10701637698393927, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -11.643543965521921, 'true_reward_min': -28.120521279348136, 'true_reward_max': -5.51250000000002, 'proxy_reward_mean': -10.74354396552192, 'proxy_reward_min': -15.237499999999981, 'proxy_reward_max': -4.8201659402887005, 'modified_reward_mean': -11.995701500538758, 'modified_reward_min': -16.17505624724525, 'modified_reward_max': -6.490526301083181, 'proxyInfectionSummaryAbsoluteReward_mean': -0.004382383419689122, 'proxyInfectionSummaryAbsoluteReward_min': -0.006994818652849745, 'proxyInfectionSummaryAbsoluteReward_max': -3.108808290155441e-05, 'proxyLowerStageReward_mean': -0.11629761479388238, 'proxyLowerStageReward_min': -0.24458659478487244, 'proxyLowerStageReward_max': -0.08008863617195101, 'proxySmoothStageChangesReward_mean': -0.021243523316062173, 'proxySmoothStageChangesReward_min': -0.09326424870466321, 'proxySmoothStageChangesReward_max': 0.0, 'trueInfectionSummaryAbsoluteReward_mean': -0.004382383419689122, 'trueInfectionSummaryAbsoluteReward_min': -0.006994818652849745, 'trueInfectionSummaryAbsoluteReward_max': -3.108808290155441e-05, 'truePoliticalReward_mean': -0.000466321243523316, 'truePoliticalReward_min': -0.01160621761658031, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.11629761479388238, 'trueLowerStageReward_min': -0.24458659478487244, 'trueLowerStageReward_max': -0.08008863617195101, 'trueSmoothStageChangesReward_mean': -0.021243523316062173, 'trueSmoothStageChangesReward_min': -0.09326424870466321, 'trueSmoothStageChangesReward_max': 0.0, 'total_modified_reward_mean': -11.995701500538758, 'total_modified_reward_min': -16.17505624724525, 'total_modified_reward_max': -6.490526301083181}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5500756546308392, 'mean_inference_ms': 1.7614630458854268, 'mean_action_processing_ms': 0.114308143093934, 'mean_env_wait_ms': 738.8150531632093, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -6.490526301083181, 'episode_reward_min': -16.17505624724525, 'episode_reward_mean': -11.995701500538758, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5500756546308392, 'mean_inference_ms': 1.7614630458854268, 'mean_action_processing_ms': 0.114308143093934, 'mean_env_wait_ms': 738.8150531632093, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 7720, 'num_agent_steps_trained': 7720, 'num_env_steps_sampled': 7720, 'num_env_steps_trained': 7720, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.740121645429113, 'num_env_steps_trained_throughput_per_sec': 12.740121645429113, 'timesteps_total': 7720, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 7720, 'timers': {'training_iteration_time_ms': 294828.012, 'sample_time_ms': 293879.27, 'load_time_ms': 1.66, 'load_throughput': 2324982.184, 'learn_time_ms': 931.177, 'learn_throughput': 4145.292, 'synch_weights_time_ms': 14.962}, 'counters': {'num_env_steps_sampled': 7720, 'num_env_steps_trained': 7720, 'num_agent_steps_sampled': 7720, 'num_agent_steps_trained': 7720}, 'done': False, 'episodes_total': 40, 'training_iteration': 2, 'trial_id': 'default', 'date': '2025-11-04_19-02-36', 'timestamp': 1762311756, 'time_this_iter_s': 302.9904532432556, 'time_total_s': 589.67631316185, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14cba9d18850>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6a9205360>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699611420>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699612020>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 589.67631316185, 'iterations_since_restore': 2, 'perf': {'cpu_util_percent': 19.703472222222224, 'ram_util_percent': 5.9}}
Iteration 3/100
{'custom_metrics': {'default_policy/true_reward_mean': -20.243590095297584, 'default_policy/true_reward_min': -84.91162517628035, 'default_policy/true_reward_max': -5.51250000000002, 'default_policy/proxy_reward_mean': -8.923590095297557, 'default_policy/proxy_reward_min': -15.237499999999981, 'default_policy/proxy_reward_max': -4.511625176280141, 'default_policy/modified_reward_mean': -10.62737239488342, 'default_policy/modified_reward_min': -16.17505624724525, 'default_policy/modified_reward_max': -6.490526301083181, 'default_policy/corr_btw_rewards_mean': 0.706923330956446, 'default_policy/corr_btw_rewards_min': 0.10701637698393927, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -20.243590095297584, 'true_reward_min': -84.91162517628035, 'true_reward_max': -5.51250000000002, 'proxy_reward_mean': -8.923590095297557, 'proxy_reward_min': -15.237499999999981, 'proxy_reward_max': -4.511625176280141, 'modified_reward_mean': -10.62737239488342, 'modified_reward_min': -16.17505624724525, 'modified_reward_max': -6.490526301083181, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0030260794473229726, 'proxyInfectionSummaryAbsoluteReward_min': -0.006994818652849745, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.1552464643504782, 'proxyLowerStageReward_min': -0.24458659478487244, 'proxyLowerStageReward_max': -0.08008863617195101, 'proxySmoothStageChangesReward_mean': -0.04507772020725389, 'proxySmoothStageChangesReward_min': -0.13471502590673576, 'proxySmoothStageChangesReward_max': 0.0, 'trueInfectionSummaryAbsoluteReward_mean': -0.0030260794473229726, 'trueInfectionSummaryAbsoluteReward_min': -0.006994818652849745, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.005865284974093265, 'truePoliticalReward_min': -0.0416580310880829, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.1552464643504782, 'trueLowerStageReward_min': -0.24458659478487244, 'trueLowerStageReward_max': -0.08008863617195101, 'trueSmoothStageChangesReward_mean': -0.04507772020725389, 'trueSmoothStageChangesReward_min': -0.13471502590673576, 'trueSmoothStageChangesReward_max': 0.0, 'total_modified_reward_mean': -10.62737239488342, 'total_modified_reward_min': -16.17505624724525, 'total_modified_reward_max': -6.490526301083181}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0524523871640363, 'cur_kl_coeff': 0.3, 'cur_lr': 0.0003, 'total_loss': -0.07684856937577327, 'policy_loss': -0.010423680492676795, 'vf_loss': 0.022259981773483258, 'vf_explained_var': 0.5963844468196233, 'kl': 0.02096602421547909, 'entropy': 0.850262093146642, 'entropy_coeff': 0.0986104}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 750.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 11580, 'num_env_steps_trained': 11580, 'num_agent_steps_sampled': 11580, 'num_agent_steps_trained': 11580}, 'sampler_results': {'episode_reward_max': -6.490526301083181, 'episode_reward_min': -16.17505624724525, 'episode_reward_mean': -10.62737239488342, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -20.243590095297584, 'default_policy/true_reward_min': -84.91162517628035, 'default_policy/true_reward_max': -5.51250000000002, 'default_policy/proxy_reward_mean': -8.923590095297557, 'default_policy/proxy_reward_min': -15.237499999999981, 'default_policy/proxy_reward_max': -4.511625176280141, 'default_policy/modified_reward_mean': -10.62737239488342, 'default_policy/modified_reward_min': -16.17505624724525, 'default_policy/modified_reward_max': -6.490526301083181, 'default_policy/corr_btw_rewards_mean': 0.706923330956446, 'default_policy/corr_btw_rewards_min': 0.10701637698393927, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -20.243590095297584, 'true_reward_min': -84.91162517628035, 'true_reward_max': -5.51250000000002, 'proxy_reward_mean': -8.923590095297557, 'proxy_reward_min': -15.237499999999981, 'proxy_reward_max': -4.511625176280141, 'modified_reward_mean': -10.62737239488342, 'modified_reward_min': -16.17505624724525, 'modified_reward_max': -6.490526301083181, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0030260794473229726, 'proxyInfectionSummaryAbsoluteReward_min': -0.006994818652849745, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.1552464643504782, 'proxyLowerStageReward_min': -0.24458659478487244, 'proxyLowerStageReward_max': -0.08008863617195101, 'proxySmoothStageChangesReward_mean': -0.04507772020725389, 'proxySmoothStageChangesReward_min': -0.13471502590673576, 'proxySmoothStageChangesReward_max': 0.0, 'trueInfectionSummaryAbsoluteReward_mean': -0.0030260794473229726, 'trueInfectionSummaryAbsoluteReward_min': -0.006994818652849745, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.005865284974093265, 'truePoliticalReward_min': -0.0416580310880829, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.1552464643504782, 'trueLowerStageReward_min': -0.24458659478487244, 'trueLowerStageReward_max': -0.08008863617195101, 'trueSmoothStageChangesReward_mean': -0.04507772020725389, 'trueSmoothStageChangesReward_min': -0.13471502590673576, 'trueSmoothStageChangesReward_max': 0.0, 'total_modified_reward_mean': -10.62737239488342, 'total_modified_reward_min': -16.17505624724525, 'total_modified_reward_max': -6.490526301083181}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5468304220980114, 'mean_inference_ms': 1.7558901862757665, 'mean_action_processing_ms': 0.11383833746673964, 'mean_env_wait_ms': 751.6476969145338, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -6.490526301083181, 'episode_reward_min': -16.17505624724525, 'episode_reward_mean': -10.62737239488342, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5468304220980114, 'mean_inference_ms': 1.7558901862757665, 'mean_action_processing_ms': 0.11383833746673964, 'mean_env_wait_ms': 751.6476969145338, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 11580, 'num_agent_steps_trained': 11580, 'num_env_steps_sampled': 11580, 'num_env_steps_trained': 11580, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 11.40338620419623, 'num_env_steps_trained_throughput_per_sec': 11.40338620419623, 'timesteps_total': 11580, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 11580, 'timers': {'training_iteration_time_ms': 309383.967, 'sample_time_ms': 308428.908, 'load_time_ms': 1.964, 'load_throughput': 1965761.71, 'learn_time_ms': 937.754, 'learn_throughput': 4116.218, 'synch_weights_time_ms': 14.426}, 'counters': {'num_env_steps_sampled': 11580, 'num_env_steps_trained': 11580, 'num_agent_steps_sampled': 11580, 'num_agent_steps_trained': 11580}, 'done': False, 'episodes_total': 60, 'training_iteration': 3, 'trial_id': 'default', 'date': '2025-11-04_19-08-15', 'timestamp': 1762312095, 'time_this_iter_s': 338.511114358902, 'time_total_s': 928.187427520752, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e2513a30>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e2511090>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2510160>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2511420>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 928.187427520752, 'iterations_since_restore': 3, 'perf': {'cpu_util_percent': 20.12712215320911, 'ram_util_percent': 6.015734989648034}}
Iteration 4/100
{'custom_metrics': {'default_policy/true_reward_mean': -29.984434656627023, 'default_policy/true_reward_min': -107.9487824638056, 'default_policy/true_reward_max': -4.687005768508885, 'default_policy/proxy_reward_mean': -7.864434656626978, 'default_policy/proxy_reward_min': -15.237499999999981, 'default_policy/proxy_reward_max': -4.27129509039023, 'default_policy/modified_reward_mean': -9.74323107695274, 'default_policy/modified_reward_min': -16.17505624724525, 'default_policy/modified_reward_max': -6.490526301083181, 'default_policy/corr_btw_rewards_mean': 0.6212632410221205, 'default_policy/corr_btw_rewards_min': 0.10701637698393927, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -29.984434656627023, 'true_reward_min': -107.9487824638056, 'true_reward_max': -4.687005768508885, 'proxy_reward_mean': -7.864434656626978, 'proxy_reward_min': -15.237499999999981, 'proxy_reward_max': -4.27129509039023, 'modified_reward_mean': -9.74323107695274, 'modified_reward_min': -16.17505624724525, 'modified_reward_max': -6.490526301083181, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0023272020725388616, 'proxyInfectionSummaryAbsoluteReward_min': -0.006994818652849745, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.1681507594107245, 'proxyLowerStageReward_min': -0.24458659478487244, 'proxyLowerStageReward_max': -0.08008863617195101, 'proxySmoothStageChangesReward_mean': -0.06612694300518134, 'proxySmoothStageChangesReward_min': -0.20725388601036268, 'proxySmoothStageChangesReward_max': 0.0, 'trueInfectionSummaryAbsoluteReward_mean': -0.0023272020725388616, 'trueInfectionSummaryAbsoluteReward_min': -0.006994818652849745, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.011461139896373058, 'truePoliticalReward_min': -0.053678756476683936, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.1681507594107245, 'trueLowerStageReward_min': -0.24458659478487244, 'trueLowerStageReward_max': -0.08008863617195101, 'trueSmoothStageChangesReward_mean': -0.06612694300518134, 'trueSmoothStageChangesReward_min': -0.20725388601036268, 'trueSmoothStageChangesReward_max': 0.0, 'total_modified_reward_mean': -9.74323107695274, 'total_modified_reward_min': -16.17505624724525, 'total_modified_reward_max': -6.490526301083181}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0869423975795507, 'cur_kl_coeff': 0.4500000000000001, 'cur_lr': 0.0003, 'total_loss': -0.0756644658651203, 'policy_loss': -0.006212732782587409, 'vf_loss': 0.016305381803928563, 'vf_explained_var': 0.7192330235242843, 'kl': 0.0142135352065111, 'entropy': 0.8578869740168253, 'entropy_coeff': 0.0979156}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 1050.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 15440, 'num_env_steps_trained': 15440, 'num_agent_steps_sampled': 15440, 'num_agent_steps_trained': 15440}, 'sampler_results': {'episode_reward_max': -6.490526301083181, 'episode_reward_min': -16.17505624724525, 'episode_reward_mean': -9.74323107695274, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -29.984434656627023, 'default_policy/true_reward_min': -107.9487824638056, 'default_policy/true_reward_max': -4.687005768508885, 'default_policy/proxy_reward_mean': -7.864434656626978, 'default_policy/proxy_reward_min': -15.237499999999981, 'default_policy/proxy_reward_max': -4.27129509039023, 'default_policy/modified_reward_mean': -9.74323107695274, 'default_policy/modified_reward_min': -16.17505624724525, 'default_policy/modified_reward_max': -6.490526301083181, 'default_policy/corr_btw_rewards_mean': 0.6212632410221205, 'default_policy/corr_btw_rewards_min': 0.10701637698393927, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -29.984434656627023, 'true_reward_min': -107.9487824638056, 'true_reward_max': -4.687005768508885, 'proxy_reward_mean': -7.864434656626978, 'proxy_reward_min': -15.237499999999981, 'proxy_reward_max': -4.27129509039023, 'modified_reward_mean': -9.74323107695274, 'modified_reward_min': -16.17505624724525, 'modified_reward_max': -6.490526301083181, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0023272020725388616, 'proxyInfectionSummaryAbsoluteReward_min': -0.006994818652849745, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.1681507594107245, 'proxyLowerStageReward_min': -0.24458659478487244, 'proxyLowerStageReward_max': -0.08008863617195101, 'proxySmoothStageChangesReward_mean': -0.06612694300518134, 'proxySmoothStageChangesReward_min': -0.20725388601036268, 'proxySmoothStageChangesReward_max': 0.0, 'trueInfectionSummaryAbsoluteReward_mean': -0.0023272020725388616, 'trueInfectionSummaryAbsoluteReward_min': -0.006994818652849745, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.011461139896373058, 'truePoliticalReward_min': -0.053678756476683936, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.1681507594107245, 'trueLowerStageReward_min': -0.24458659478487244, 'trueLowerStageReward_max': -0.08008863617195101, 'trueSmoothStageChangesReward_mean': -0.06612694300518134, 'trueSmoothStageChangesReward_min': -0.20725388601036268, 'trueSmoothStageChangesReward_max': 0.0, 'total_modified_reward_mean': -9.74323107695274, 'total_modified_reward_min': -16.17505624724525, 'total_modified_reward_max': -6.490526301083181}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.543769662776865, 'mean_inference_ms': 1.7513980167065657, 'mean_action_processing_ms': 0.11333619406582449, 'mean_env_wait_ms': 761.6589998564248, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -6.490526301083181, 'episode_reward_min': -16.17505624724525, 'episode_reward_mean': -9.74323107695274, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.543769662776865, 'mean_inference_ms': 1.7513980167065657, 'mean_action_processing_ms': 0.11333619406582449, 'mean_env_wait_ms': 761.6589998564248, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 15440, 'num_agent_steps_trained': 15440, 'num_env_steps_sampled': 15440, 'num_env_steps_trained': 15440, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 11.764182043931852, 'num_env_steps_trained_throughput_per_sec': 11.764182043931852, 'timesteps_total': 15440, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 15440, 'timers': {'training_iteration_time_ms': 314066.618, 'sample_time_ms': 313127.325, 'load_time_ms': 2.287, 'load_throughput': 1687690.341, 'learn_time_ms': 921.87, 'learn_throughput': 4187.141, 'synch_weights_time_ms': 14.319}, 'counters': {'num_env_steps_sampled': 15440, 'num_env_steps_trained': 15440, 'num_agent_steps_sampled': 15440, 'num_agent_steps_trained': 15440}, 'done': False, 'episodes_total': 80, 'training_iteration': 4, 'trial_id': 'default', 'date': '2025-11-04_19-13-43', 'timestamp': 1762312423, 'time_this_iter_s': 328.1308400630951, 'time_total_s': 1256.318267583847, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6995372e0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14ccde8bf7c0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6882fc940>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6882fdf90>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 1256.318267583847, 'iterations_since_restore': 4, 'perf': {'cpu_util_percent': 20.176659528907923, 'ram_util_percent': 6.024839400428266}}
Iteration 5/100
{'custom_metrics': {'default_policy/true_reward_mean': -39.87293235676204, 'default_policy/true_reward_min': -147.8073737341528, 'default_policy/true_reward_max': -4.687005768508885, 'default_policy/proxy_reward_mean': -7.18093235676199, 'default_policy/proxy_reward_min': -15.237499999999981, 'default_policy/proxy_reward_max': -3.7752543263816682, 'default_policy/modified_reward_mean': -9.12889992381115, 'default_policy/modified_reward_min': -16.17505624724525, 'default_policy/modified_reward_max': -5.932088084283853, 'default_policy/corr_btw_rewards_mean': 0.5883577878722687, 'default_policy/corr_btw_rewards_min': 0.10701637698393927, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -39.87293235676204, 'true_reward_min': -147.8073737341528, 'true_reward_max': -4.687005768508885, 'proxy_reward_mean': -7.18093235676199, 'proxy_reward_min': -15.237499999999981, 'proxy_reward_max': -3.7752543263816682, 'modified_reward_mean': -9.12889992381115, 'modified_reward_min': -16.17505624724525, 'modified_reward_max': -5.932088084283853, 'proxyInfectionSummaryAbsoluteReward_mean': -0.001918031088082903, 'proxyInfectionSummaryAbsoluteReward_min': -0.006994818652849745, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.1723177386923312, 'proxyLowerStageReward_min': -0.24458659478487244, 'proxyLowerStageReward_max': -0.08008863617195101, 'proxySmoothStageChangesReward_mean': -0.07948186528497408, 'proxySmoothStageChangesReward_min': -0.20725388601036268, 'proxySmoothStageChangesReward_max': 0.0, 'trueInfectionSummaryAbsoluteReward_mean': -0.001918031088082903, 'trueInfectionSummaryAbsoluteReward_min': -0.006994818652849745, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.016938860103626944, 'truePoliticalReward_min': -0.07440414507772021, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.1723177386923312, 'trueLowerStageReward_min': -0.24458659478487244, 'trueLowerStageReward_max': -0.08008863617195101, 'trueSmoothStageChangesReward_mean': -0.07948186528497408, 'trueSmoothStageChangesReward_min': -0.20725388601036268, 'trueSmoothStageChangesReward_max': 0.0, 'total_modified_reward_mean': -9.12889992381115, 'total_modified_reward_min': -16.17505624724525, 'total_modified_reward_max': -5.932088084283853}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0112942746529976, 'cur_kl_coeff': 0.4500000000000001, 'cur_lr': 0.0003, 'total_loss': -0.07137946449103766, 'policy_loss': -0.00964395135641098, 'vf_loss': 0.028971144267901157, 'vf_explained_var': 0.7036301773786545, 'kl': 0.011308416120556842, 'entropy': 0.8363423198461533, 'entropy_coeff': 0.09722080000000001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 1350.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 19300, 'num_env_steps_trained': 19300, 'num_agent_steps_sampled': 19300, 'num_agent_steps_trained': 19300}, 'sampler_results': {'episode_reward_max': -5.932088084283853, 'episode_reward_min': -16.17505624724525, 'episode_reward_mean': -9.12889992381115, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -39.87293235676204, 'default_policy/true_reward_min': -147.8073737341528, 'default_policy/true_reward_max': -4.687005768508885, 'default_policy/proxy_reward_mean': -7.18093235676199, 'default_policy/proxy_reward_min': -15.237499999999981, 'default_policy/proxy_reward_max': -3.7752543263816682, 'default_policy/modified_reward_mean': -9.12889992381115, 'default_policy/modified_reward_min': -16.17505624724525, 'default_policy/modified_reward_max': -5.932088084283853, 'default_policy/corr_btw_rewards_mean': 0.5883577878722687, 'default_policy/corr_btw_rewards_min': 0.10701637698393927, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -39.87293235676204, 'true_reward_min': -147.8073737341528, 'true_reward_max': -4.687005768508885, 'proxy_reward_mean': -7.18093235676199, 'proxy_reward_min': -15.237499999999981, 'proxy_reward_max': -3.7752543263816682, 'modified_reward_mean': -9.12889992381115, 'modified_reward_min': -16.17505624724525, 'modified_reward_max': -5.932088084283853, 'proxyInfectionSummaryAbsoluteReward_mean': -0.001918031088082903, 'proxyInfectionSummaryAbsoluteReward_min': -0.006994818652849745, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.1723177386923312, 'proxyLowerStageReward_min': -0.24458659478487244, 'proxyLowerStageReward_max': -0.08008863617195101, 'proxySmoothStageChangesReward_mean': -0.07948186528497408, 'proxySmoothStageChangesReward_min': -0.20725388601036268, 'proxySmoothStageChangesReward_max': 0.0, 'trueInfectionSummaryAbsoluteReward_mean': -0.001918031088082903, 'trueInfectionSummaryAbsoluteReward_min': -0.006994818652849745, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.016938860103626944, 'truePoliticalReward_min': -0.07440414507772021, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.1723177386923312, 'trueLowerStageReward_min': -0.24458659478487244, 'trueLowerStageReward_max': -0.08008863617195101, 'trueSmoothStageChangesReward_mean': -0.07948186528497408, 'trueSmoothStageChangesReward_min': -0.20725388601036268, 'trueSmoothStageChangesReward_max': 0.0, 'total_modified_reward_mean': -9.12889992381115, 'total_modified_reward_min': -16.17505624724525, 'total_modified_reward_max': -5.932088084283853}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5445158299686149, 'mean_inference_ms': 1.748505985505109, 'mean_action_processing_ms': 0.11307465174818589, 'mean_env_wait_ms': 769.0767387922506, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -5.932088084283853, 'episode_reward_min': -16.17505624724525, 'episode_reward_mean': -9.12889992381115, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5445158299686149, 'mean_inference_ms': 1.748505985505109, 'mean_action_processing_ms': 0.11307465174818589, 'mean_env_wait_ms': 769.0767387922506, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 19300, 'num_agent_steps_trained': 19300, 'num_env_steps_sampled': 19300, 'num_env_steps_trained': 19300, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 11.67543883701395, 'num_env_steps_trained_throughput_per_sec': 11.67543883701395, 'timesteps_total': 19300, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 19300, 'timers': {'training_iteration_time_ms': 317374.985, 'sample_time_ms': 316401.502, 'load_time_ms': 2.767, 'load_throughput': 1395185.66, 'learn_time_ms': 955.138, 'learn_throughput': 4041.3, 'synch_weights_time_ms': 14.733}, 'counters': {'num_env_steps_sampled': 19300, 'num_env_steps_trained': 19300, 'num_agent_steps_sampled': 19300, 'num_agent_steps_trained': 19300}, 'done': False, 'episodes_total': 100, 'training_iteration': 5, 'trial_id': 'default', 'date': '2025-11-04_19-19-14', 'timestamp': 1762312754, 'time_this_iter_s': 330.6241455078125, 'time_total_s': 1586.9424130916595, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a699613e80>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699610ac0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699535f30>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699537a60>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 1586.9424130916595, 'iterations_since_restore': 5, 'perf': {'cpu_util_percent': 20.34470338983051, 'ram_util_percent': 6.0262711864406775}}
Iteration 6/100
{'custom_metrics': {'default_policy/true_reward_mean': -53.75744678632468, 'default_policy/true_reward_min': -147.8073737341528, 'default_policy/true_reward_max': -4.687005768508885, 'default_policy/proxy_reward_mean': -5.669446786324588, 'default_policy/proxy_reward_min': -15.168210678118653, 'default_policy/proxy_reward_max': -3.482779579551083, 'default_policy/modified_reward_mean': -7.847897846628557, 'default_policy/modified_reward_min': -16.129962386251716, 'default_policy/modified_reward_max': -5.437189761292093, 'default_policy/corr_btw_rewards_mean': 0.47956851316938404, 'default_policy/corr_btw_rewards_min': 0.10701637698393927, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -53.75744678632468, 'true_reward_min': -147.8073737341528, 'true_reward_max': -4.687005768508885, 'proxy_reward_mean': -5.669446786324588, 'proxy_reward_min': -15.168210678118653, 'proxy_reward_max': -3.482779579551083, 'modified_reward_mean': -7.847897846628557, 'modified_reward_min': -16.129962386251716, 'modified_reward_max': -5.437189761292093, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0009400000000000005, 'proxyInfectionSummaryAbsoluteReward_min': -0.0069533678756476735, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.18870708737433087, 'proxyLowerStageReward_min': -0.24458659478487244, 'proxyLowerStageReward_max': -0.08008863617195101, 'proxySmoothStageChangesReward_mean': -0.11046632124352332, 'proxySmoothStageChangesReward_min': -0.25906735751295334, 'proxySmoothStageChangesReward_max': -0.010362694300518135, 'trueInfectionSummaryAbsoluteReward_mean': -0.0009400000000000005, 'trueInfectionSummaryAbsoluteReward_min': -0.0069533678756476735, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.0249160621761658, 'truePoliticalReward_min': -0.07440414507772021, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.18870708737433087, 'trueLowerStageReward_min': -0.24458659478487244, 'trueLowerStageReward_max': -0.08008863617195101, 'trueSmoothStageChangesReward_mean': -0.11046632124352332, 'trueSmoothStageChangesReward_min': -0.25906735751295334, 'trueSmoothStageChangesReward_max': -0.010362694300518135, 'total_modified_reward_mean': -7.847897846628557, 'total_modified_reward_min': -16.129962386251716, 'total_modified_reward_max': -5.437189761292093}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.00061909938852, 'cur_kl_coeff': 0.4500000000000001, 'cur_lr': 0.0003, 'total_loss': -0.07339311509082715, 'policy_loss': -0.01105793426434199, 'vf_loss': 0.011231138753937558, 'vf_explained_var': 0.7958006858825684, 'kl': 0.011132379644015967, 'entropy': 0.7558619072039922, 'entropy_coeff': 0.096526}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 1650.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 23160, 'num_env_steps_trained': 23160, 'num_agent_steps_sampled': 23160, 'num_agent_steps_trained': 23160}, 'sampler_results': {'episode_reward_max': -5.437189761292093, 'episode_reward_min': -16.129962386251716, 'episode_reward_mean': -7.847897846628557, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -53.75744678632468, 'default_policy/true_reward_min': -147.8073737341528, 'default_policy/true_reward_max': -4.687005768508885, 'default_policy/proxy_reward_mean': -5.669446786324588, 'default_policy/proxy_reward_min': -15.168210678118653, 'default_policy/proxy_reward_max': -3.482779579551083, 'default_policy/modified_reward_mean': -7.847897846628557, 'default_policy/modified_reward_min': -16.129962386251716, 'default_policy/modified_reward_max': -5.437189761292093, 'default_policy/corr_btw_rewards_mean': 0.47956851316938404, 'default_policy/corr_btw_rewards_min': 0.10701637698393927, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -53.75744678632468, 'true_reward_min': -147.8073737341528, 'true_reward_max': -4.687005768508885, 'proxy_reward_mean': -5.669446786324588, 'proxy_reward_min': -15.168210678118653, 'proxy_reward_max': -3.482779579551083, 'modified_reward_mean': -7.847897846628557, 'modified_reward_min': -16.129962386251716, 'modified_reward_max': -5.437189761292093, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0009400000000000005, 'proxyInfectionSummaryAbsoluteReward_min': -0.0069533678756476735, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.18870708737433087, 'proxyLowerStageReward_min': -0.24458659478487244, 'proxyLowerStageReward_max': -0.08008863617195101, 'proxySmoothStageChangesReward_mean': -0.11046632124352332, 'proxySmoothStageChangesReward_min': -0.25906735751295334, 'proxySmoothStageChangesReward_max': -0.010362694300518135, 'trueInfectionSummaryAbsoluteReward_mean': -0.0009400000000000005, 'trueInfectionSummaryAbsoluteReward_min': -0.0069533678756476735, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.0249160621761658, 'truePoliticalReward_min': -0.07440414507772021, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.18870708737433087, 'trueLowerStageReward_min': -0.24458659478487244, 'trueLowerStageReward_max': -0.08008863617195101, 'trueSmoothStageChangesReward_mean': -0.11046632124352332, 'trueSmoothStageChangesReward_min': -0.25906735751295334, 'trueSmoothStageChangesReward_max': -0.010362694300518135, 'total_modified_reward_mean': -7.847897846628557, 'total_modified_reward_min': -16.129962386251716, 'total_modified_reward_max': -5.437189761292093}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5425679959025735, 'mean_inference_ms': 1.742371884205257, 'mean_action_processing_ms': 0.11260480606812966, 'mean_env_wait_ms': 783.0666954335658, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -5.437189761292093, 'episode_reward_min': -16.129962386251716, 'episode_reward_mean': -7.847897846628557, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5425679959025735, 'mean_inference_ms': 1.742371884205257, 'mean_action_processing_ms': 0.11260480606812966, 'mean_env_wait_ms': 783.0666954335658, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 23160, 'num_agent_steps_trained': 23160, 'num_env_steps_sampled': 23160, 'num_env_steps_trained': 23160, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 11.204215532005906, 'num_env_steps_trained_throughput_per_sec': 11.204215532005906, 'timesteps_total': 23160, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 23160, 'timers': {'training_iteration_time_ms': 321898.003, 'sample_time_ms': 320904.181, 'load_time_ms': 2.936, 'load_throughput': 1314515.692, 'learn_time_ms': 975.305, 'learn_throughput': 3957.738, 'synch_weights_time_ms': 14.735}, 'counters': {'num_env_steps_sampled': 23160, 'num_env_steps_trained': 23160, 'num_agent_steps_sampled': 23160, 'num_agent_steps_trained': 23160}, 'done': False, 'episodes_total': 120, 'training_iteration': 6, 'trial_id': 'default', 'date': '2025-11-04_19-24-59', 'timestamp': 1762313099, 'time_this_iter_s': 344.53375577926636, 'time_total_s': 1931.476168870926, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6a9255cf0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6997839a0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffdd80>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0fffe80>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 1931.476168870926, 'iterations_since_restore': 6, 'perf': {'cpu_util_percent': 19.649183673469388, 'ram_util_percent': 6.04734693877551}}
Iteration 7/100
{'custom_metrics': {'default_policy/true_reward_mean': -72.45262267018563, 'default_policy/true_reward_min': -187.1624242404913, 'default_policy/true_reward_max': -4.687005768508885, 'default_policy/proxy_reward_mean': -4.416622670185521, 'default_policy/proxy_reward_min': -9.504568901432382, 'default_policy/proxy_reward_max': -3.370292206135795, 'default_policy/modified_reward_mean': -6.687144680617439, 'default_policy/modified_reward_min': -11.262668380014972, 'default_policy/modified_reward_max': -5.242767077249853, 'default_policy/corr_btw_rewards_mean': 0.40872740505300664, 'default_policy/corr_btw_rewards_min': 0.11069038529160294, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -72.45262267018563, 'true_reward_min': -187.1624242404913, 'true_reward_max': -4.687005768508885, 'proxy_reward_mean': -4.416622670185521, 'proxy_reward_min': -9.504568901432382, 'proxy_reward_max': -3.370292206135795, 'modified_reward_mean': -6.687144680617439, 'modified_reward_min': -11.262668380014972, 'modified_reward_max': -5.242767077249853, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00022880829015544055, 'proxyInfectionSummaryAbsoluteReward_min': -0.003316062176165805, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.19182500881790232, 'proxyLowerStageReward_min': -0.24416117104815446, 'proxyLowerStageReward_max': -0.14413154484676222, 'proxySmoothStageChangesReward_mean': -0.14134715025906738, 'proxySmoothStageChangesReward_min': -0.25906735751295334, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.00022880829015544055, 'trueInfectionSummaryAbsoluteReward_min': -0.003316062176165805, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.03525181347150258, 'truePoliticalReward_min': -0.09512953367875647, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.19182500881790232, 'trueLowerStageReward_min': -0.24416117104815446, 'trueLowerStageReward_max': -0.14413154484676222, 'trueSmoothStageChangesReward_mean': -0.14134715025906738, 'trueSmoothStageChangesReward_min': -0.25906735751295334, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -6.687144680617439, 'total_modified_reward_min': -11.262668380014972, 'total_modified_reward_max': -5.242767077249853}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0015689606467884, 'cur_kl_coeff': 0.4500000000000001, 'cur_lr': 0.0003, 'total_loss': -0.0633441184919017, 'policy_loss': -0.002618653050934275, 'vf_loss': 0.01140694152796641, 'vf_explained_var': 0.8367891772588094, 'kl': 0.004384900539166173, 'entropy': 0.7137773448228836, 'entropy_coeff': 0.0958312}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 1950.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 27020, 'num_env_steps_trained': 27020, 'num_agent_steps_sampled': 27020, 'num_agent_steps_trained': 27020}, 'sampler_results': {'episode_reward_max': -5.242767077249853, 'episode_reward_min': -11.262668380014972, 'episode_reward_mean': -6.687144680617439, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -72.45262267018563, 'default_policy/true_reward_min': -187.1624242404913, 'default_policy/true_reward_max': -4.687005768508885, 'default_policy/proxy_reward_mean': -4.416622670185521, 'default_policy/proxy_reward_min': -9.504568901432382, 'default_policy/proxy_reward_max': -3.370292206135795, 'default_policy/modified_reward_mean': -6.687144680617439, 'default_policy/modified_reward_min': -11.262668380014972, 'default_policy/modified_reward_max': -5.242767077249853, 'default_policy/corr_btw_rewards_mean': 0.40872740505300664, 'default_policy/corr_btw_rewards_min': 0.11069038529160294, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -72.45262267018563, 'true_reward_min': -187.1624242404913, 'true_reward_max': -4.687005768508885, 'proxy_reward_mean': -4.416622670185521, 'proxy_reward_min': -9.504568901432382, 'proxy_reward_max': -3.370292206135795, 'modified_reward_mean': -6.687144680617439, 'modified_reward_min': -11.262668380014972, 'modified_reward_max': -5.242767077249853, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00022880829015544055, 'proxyInfectionSummaryAbsoluteReward_min': -0.003316062176165805, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.19182500881790232, 'proxyLowerStageReward_min': -0.24416117104815446, 'proxyLowerStageReward_max': -0.14413154484676222, 'proxySmoothStageChangesReward_mean': -0.14134715025906738, 'proxySmoothStageChangesReward_min': -0.25906735751295334, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.00022880829015544055, 'trueInfectionSummaryAbsoluteReward_min': -0.003316062176165805, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.03525181347150258, 'truePoliticalReward_min': -0.09512953367875647, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.19182500881790232, 'trueLowerStageReward_min': -0.24416117104815446, 'trueLowerStageReward_max': -0.14413154484676222, 'trueSmoothStageChangesReward_mean': -0.14134715025906738, 'trueSmoothStageChangesReward_min': -0.25906735751295334, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -6.687144680617439, 'total_modified_reward_min': -11.262668380014972, 'total_modified_reward_max': -5.242767077249853}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.541637619865158, 'mean_inference_ms': 1.7360919600351945, 'mean_action_processing_ms': 0.11179213308174081, 'mean_env_wait_ms': 793.791876724444, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -5.242767077249853, 'episode_reward_min': -11.262668380014972, 'episode_reward_mean': -6.687144680617439, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.541637619865158, 'mean_inference_ms': 1.7360919600351945, 'mean_action_processing_ms': 0.11179213308174081, 'mean_env_wait_ms': 793.791876724444, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 27020, 'num_agent_steps_trained': 27020, 'num_env_steps_sampled': 27020, 'num_env_steps_trained': 27020, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.179613017830413, 'num_env_steps_trained_throughput_per_sec': 12.179613017830413, 'timesteps_total': 27020, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 27020, 'timers': {'training_iteration_time_ms': 321187.277, 'sample_time_ms': 320207.05, 'load_time_ms': 3.275, 'load_throughput': 1178790.465, 'learn_time_ms': 960.551, 'learn_throughput': 4018.527, 'synch_weights_time_ms': 15.543}, 'counters': {'num_env_steps_sampled': 27020, 'num_env_steps_trained': 27020, 'num_agent_steps_sampled': 27020, 'num_agent_steps_trained': 27020}, 'done': False, 'episodes_total': 140, 'training_iteration': 7, 'trial_id': 'default', 'date': '2025-11-04_19-30-16', 'timestamp': 1762313416, 'time_this_iter_s': 316.94546341896057, 'time_total_s': 2248.4216322898865, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a699612320>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699611ea0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699612f50>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699610820>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 2248.4216322898865, 'iterations_since_restore': 7, 'perf': {'cpu_util_percent': 20.240486725663718, 'ram_util_percent': 6.001106194690266}}
Iteration 8/100
{'custom_metrics': {'default_policy/true_reward_mean': -83.12653867005446, 'default_policy/true_reward_min': -187.1624242404913, 'default_policy/true_reward_max': -4.687005768508885, 'default_policy/proxy_reward_mean': -4.0625386700543515, 'default_policy/proxy_reward_min': -9.504568901432382, 'default_policy/proxy_reward_max': -2.8296067811865524, 'default_policy/modified_reward_mean': -6.195734688625525, 'default_policy/modified_reward_min': -11.262668380014972, 'default_policy/modified_reward_max': -4.436168444878765, 'default_policy/corr_btw_rewards_mean': 0.4705784074095189, 'default_policy/corr_btw_rewards_min': 0.17655370447789046, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -83.12653867005446, 'true_reward_min': -187.1624242404913, 'true_reward_max': -4.687005768508885, 'proxy_reward_mean': -4.0625386700543515, 'proxy_reward_min': -9.504568901432382, 'proxy_reward_max': -2.8296067811865524, 'modified_reward_mean': -6.195734688625525, 'modified_reward_min': -11.262668380014972, 'modified_reward_max': -4.436168444878765, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00019139896373057002, 'proxyInfectionSummaryAbsoluteReward_min': -0.003316062176165805, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.17555640777483653, 'proxyLowerStageReward_min': -0.22208652006325452, 'proxyLowerStageReward_max': -0.13249257933609052, 'proxySmoothStageChangesReward_mean': -0.157979274611399, 'proxySmoothStageChangesReward_min': -0.25906735751295334, 'proxySmoothStageChangesReward_max': -0.06735751295336788, 'trueInfectionSummaryAbsoluteReward_mean': -0.00019139896373057002, 'trueInfectionSummaryAbsoluteReward_min': -0.003316062176165805, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.04096580310880829, 'truePoliticalReward_min': -0.09512953367875647, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.17555640777483653, 'trueLowerStageReward_min': -0.22208652006325452, 'trueLowerStageReward_max': -0.13249257933609052, 'trueSmoothStageChangesReward_mean': -0.157979274611399, 'trueSmoothStageChangesReward_min': -0.25906735751295334, 'trueSmoothStageChangesReward_max': -0.06735751295336788, 'total_modified_reward_mean': -6.195734688625525, 'total_modified_reward_min': -11.262668380014972, 'total_modified_reward_max': -4.436168444878765}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9183152083307504, 'cur_kl_coeff': 0.22500000000000006, 'cur_lr': 0.0003, 'total_loss': -0.06400397048176577, 'policy_loss': -0.008428101887305578, 'vf_loss': 0.007960106866667047, 'vf_explained_var': 0.9073475285371144, 'kl': 0.008029398534147685, 'entropy': 0.6449954034884771, 'entropy_coeff': 0.09513640000000002}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 2250.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 30880, 'num_env_steps_trained': 30880, 'num_agent_steps_sampled': 30880, 'num_agent_steps_trained': 30880}, 'sampler_results': {'episode_reward_max': -4.436168444878765, 'episode_reward_min': -11.262668380014972, 'episode_reward_mean': -6.195734688625525, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -83.12653867005446, 'default_policy/true_reward_min': -187.1624242404913, 'default_policy/true_reward_max': -4.687005768508885, 'default_policy/proxy_reward_mean': -4.0625386700543515, 'default_policy/proxy_reward_min': -9.504568901432382, 'default_policy/proxy_reward_max': -2.8296067811865524, 'default_policy/modified_reward_mean': -6.195734688625525, 'default_policy/modified_reward_min': -11.262668380014972, 'default_policy/modified_reward_max': -4.436168444878765, 'default_policy/corr_btw_rewards_mean': 0.4705784074095189, 'default_policy/corr_btw_rewards_min': 0.17655370447789046, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -83.12653867005446, 'true_reward_min': -187.1624242404913, 'true_reward_max': -4.687005768508885, 'proxy_reward_mean': -4.0625386700543515, 'proxy_reward_min': -9.504568901432382, 'proxy_reward_max': -2.8296067811865524, 'modified_reward_mean': -6.195734688625525, 'modified_reward_min': -11.262668380014972, 'modified_reward_max': -4.436168444878765, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00019139896373057002, 'proxyInfectionSummaryAbsoluteReward_min': -0.003316062176165805, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.17555640777483653, 'proxyLowerStageReward_min': -0.22208652006325452, 'proxyLowerStageReward_max': -0.13249257933609052, 'proxySmoothStageChangesReward_mean': -0.157979274611399, 'proxySmoothStageChangesReward_min': -0.25906735751295334, 'proxySmoothStageChangesReward_max': -0.06735751295336788, 'trueInfectionSummaryAbsoluteReward_mean': -0.00019139896373057002, 'trueInfectionSummaryAbsoluteReward_min': -0.003316062176165805, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.04096580310880829, 'truePoliticalReward_min': -0.09512953367875647, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.17555640777483653, 'trueLowerStageReward_min': -0.22208652006325452, 'trueLowerStageReward_max': -0.13249257933609052, 'trueSmoothStageChangesReward_mean': -0.157979274611399, 'trueSmoothStageChangesReward_min': -0.25906735751295334, 'trueSmoothStageChangesReward_max': -0.06735751295336788, 'total_modified_reward_mean': -6.195734688625525, 'total_modified_reward_min': -11.262668380014972, 'total_modified_reward_max': -4.436168444878765}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.541773460826312, 'mean_inference_ms': 1.7312727404542243, 'mean_action_processing_ms': 0.11125558635037641, 'mean_env_wait_ms': 798.3008156805221, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -4.436168444878765, 'episode_reward_min': -11.262668380014972, 'episode_reward_mean': -6.195734688625525, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.541773460826312, 'mean_inference_ms': 1.7312727404542243, 'mean_action_processing_ms': 0.11125558635037641, 'mean_env_wait_ms': 798.3008156805221, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 30880, 'num_agent_steps_trained': 30880, 'num_env_steps_sampled': 30880, 'num_env_steps_trained': 30880, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.108289278673153, 'num_env_steps_trained_throughput_per_sec': 12.108289278673153, 'timesteps_total': 30880, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 30880, 'timers': {'training_iteration_time_ms': 320887.58, 'sample_time_ms': 319885.186, 'load_time_ms': 3.491, 'load_throughput': 1105733.619, 'learn_time_ms': 982.332, 'learn_throughput': 3929.426, 'synch_weights_time_ms': 15.667}, 'counters': {'num_env_steps_sampled': 30880, 'num_env_steps_trained': 30880, 'num_agent_steps_sampled': 30880, 'num_agent_steps_trained': 30880}, 'done': False, 'episodes_total': 160, 'training_iteration': 8, 'trial_id': 'default', 'date': '2025-11-04_19-35-35', 'timestamp': 1762313735, 'time_this_iter_s': 318.8089847564697, 'time_total_s': 2567.230617046356, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e24f8c10>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699611360>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e24f97e0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e24fa530>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 2567.230617046356, 'iterations_since_restore': 8, 'perf': {'cpu_util_percent': 20.226593406593413, 'ram_util_percent': 6.0}}
Iteration 9/100
{'custom_metrics': {'default_policy/true_reward_mean': -87.54513210486816, 'default_policy/true_reward_min': -187.1624242404913, 'default_policy/true_reward_max': -7.57808441227158, 'default_policy/proxy_reward_mean': -3.797132104868026, 'default_policy/proxy_reward_min': -9.504568901432382, 'default_policy/proxy_reward_max': -2.8296067811865524, 'default_policy/modified_reward_mean': -5.807486281615542, 'default_policy/modified_reward_min': -11.262668380014972, 'default_policy/modified_reward_max': -4.436168444878765, 'default_policy/corr_btw_rewards_mean': 0.5041324628219693, 'default_policy/corr_btw_rewards_min': 0.27180618505262166, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -87.54513210486816, 'true_reward_min': -187.1624242404913, 'true_reward_max': -7.57808441227158, 'proxy_reward_mean': -3.797132104868026, 'proxy_reward_min': -9.504568901432382, 'proxy_reward_max': -2.8296067811865524, 'modified_reward_mean': -5.807486281615542, 'modified_reward_min': -11.262668380014972, 'modified_reward_max': -4.436168444878765, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00017709844559585505, 'proxyInfectionSummaryAbsoluteReward_min': -0.003316062176165805, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.16261824377554493, 'proxyLowerStageReward_min': -0.2032502110472666, 'proxyLowerStageReward_max': -0.12547934933301655, 'proxySmoothStageChangesReward_mean': -0.16414507772020726, 'proxySmoothStageChangesReward_min': -0.25906735751295334, 'proxySmoothStageChangesReward_max': -0.06735751295336788, 'trueInfectionSummaryAbsoluteReward_mean': -0.00017709844559585505, 'trueInfectionSummaryAbsoluteReward_min': -0.003316062176165805, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.04339274611398963, 'truePoliticalReward_min': -0.09512953367875647, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.16261824377554493, 'trueLowerStageReward_min': -0.2032502110472666, 'trueLowerStageReward_max': -0.12547934933301655, 'trueSmoothStageChangesReward_mean': -0.16414507772020726, 'trueSmoothStageChangesReward_min': -0.25906735751295334, 'trueSmoothStageChangesReward_max': -0.06735751295336788, 'total_modified_reward_mean': -5.807486281615542, 'total_modified_reward_min': -11.262668380014972, 'total_modified_reward_max': -4.436168444878765}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.8831495085358619, 'cur_kl_coeff': 0.22500000000000006, 'cur_lr': 0.0003, 'total_loss': -0.06626033795415424, 'policy_loss': -0.014165961594941715, 'vf_loss': 0.006797613191689985, 'vf_explained_var': 0.9440199083089829, 'kl': 0.006704130148050451, 'entropy': 0.6035646688938141, 'entropy_coeff': 0.0944416}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 2550.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 34740, 'num_env_steps_trained': 34740, 'num_agent_steps_sampled': 34740, 'num_agent_steps_trained': 34740}, 'sampler_results': {'episode_reward_max': -4.436168444878765, 'episode_reward_min': -11.262668380014972, 'episode_reward_mean': -5.807486281615542, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -87.54513210486816, 'default_policy/true_reward_min': -187.1624242404913, 'default_policy/true_reward_max': -7.57808441227158, 'default_policy/proxy_reward_mean': -3.797132104868026, 'default_policy/proxy_reward_min': -9.504568901432382, 'default_policy/proxy_reward_max': -2.8296067811865524, 'default_policy/modified_reward_mean': -5.807486281615542, 'default_policy/modified_reward_min': -11.262668380014972, 'default_policy/modified_reward_max': -4.436168444878765, 'default_policy/corr_btw_rewards_mean': 0.5041324628219693, 'default_policy/corr_btw_rewards_min': 0.27180618505262166, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -87.54513210486816, 'true_reward_min': -187.1624242404913, 'true_reward_max': -7.57808441227158, 'proxy_reward_mean': -3.797132104868026, 'proxy_reward_min': -9.504568901432382, 'proxy_reward_max': -2.8296067811865524, 'modified_reward_mean': -5.807486281615542, 'modified_reward_min': -11.262668380014972, 'modified_reward_max': -4.436168444878765, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00017709844559585505, 'proxyInfectionSummaryAbsoluteReward_min': -0.003316062176165805, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.16261824377554493, 'proxyLowerStageReward_min': -0.2032502110472666, 'proxyLowerStageReward_max': -0.12547934933301655, 'proxySmoothStageChangesReward_mean': -0.16414507772020726, 'proxySmoothStageChangesReward_min': -0.25906735751295334, 'proxySmoothStageChangesReward_max': -0.06735751295336788, 'trueInfectionSummaryAbsoluteReward_mean': -0.00017709844559585505, 'trueInfectionSummaryAbsoluteReward_min': -0.003316062176165805, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.04339274611398963, 'truePoliticalReward_min': -0.09512953367875647, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.16261824377554493, 'trueLowerStageReward_min': -0.2032502110472666, 'trueLowerStageReward_max': -0.12547934933301655, 'trueSmoothStageChangesReward_mean': -0.16414507772020726, 'trueSmoothStageChangesReward_min': -0.25906735751295334, 'trueSmoothStageChangesReward_max': -0.06735751295336788, 'total_modified_reward_mean': -5.807486281615542, 'total_modified_reward_min': -11.262668380014972, 'total_modified_reward_max': -4.436168444878765}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.54222859026459, 'mean_inference_ms': 1.7265983725346847, 'mean_action_processing_ms': 0.11081883932815051, 'mean_env_wait_ms': 799.2551867231449, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -4.436168444878765, 'episode_reward_min': -11.262668380014972, 'episode_reward_mean': -5.807486281615542, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.54222859026459, 'mean_inference_ms': 1.7265983725346847, 'mean_action_processing_ms': 0.11081883932815051, 'mean_env_wait_ms': 799.2551867231449, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 34740, 'num_agent_steps_trained': 34740, 'num_env_steps_sampled': 34740, 'num_env_steps_trained': 34740, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 10.504651036470024, 'num_env_steps_trained_throughput_per_sec': 10.504651036470024, 'timesteps_total': 34740, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 34740, 'timers': {'training_iteration_time_ms': 326061.866, 'sample_time_ms': 325047.644, 'load_time_ms': 3.626, 'load_throughput': 1064533.274, 'learn_time_ms': 993.811, 'learn_throughput': 3884.037, 'synch_weights_time_ms': 15.899}, 'counters': {'num_env_steps_sampled': 34740, 'num_env_steps_trained': 34740, 'num_agent_steps_sampled': 34740, 'num_agent_steps_trained': 34740}, 'done': False, 'episodes_total': 180, 'training_iteration': 9, 'trial_id': 'default', 'date': '2025-11-04_19-41-42', 'timestamp': 1762314102, 'time_this_iter_s': 367.47559237480164, 'time_total_s': 2934.706209421158, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a688188370>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6a9cdb8b0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffdc00>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffe080>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 2934.706209421158, 'iterations_since_restore': 9, 'perf': {'cpu_util_percent': 18.375809523809522, 'ram_util_percent': 6.0}}
Iteration 10/100
{'custom_metrics': {'default_policy/true_reward_mean': -82.36250043136282, 'default_policy/true_reward_min': -187.1624242404913, 'default_policy/true_reward_max': -6.847106781186554, 'default_policy/proxy_reward_mean': -3.5745004313627295, 'default_policy/proxy_reward_min': -5.267094154601843, 'default_policy/proxy_reward_max': -2.73104076400857, 'default_policy/modified_reward_mean': -5.472297090409541, 'default_policy/modified_reward_min': -7.063240110861145, 'default_policy/modified_reward_max': -4.287584191504131, 'default_policy/corr_btw_rewards_mean': 0.5082091202088462, 'default_policy/corr_btw_rewards_min': 0.13020614530266408, 'default_policy/corr_btw_rewards_max': 0.7796681325038016, 'true_reward_mean': -82.36250043136282, 'true_reward_min': -187.1624242404913, 'true_reward_max': -6.847106781186554, 'proxy_reward_mean': -3.5745004313627295, 'proxy_reward_min': -5.267094154601843, 'proxy_reward_max': -2.73104076400857, 'modified_reward_mean': -5.472297090409541, 'modified_reward_min': -7.063240110861145, 'modified_reward_max': -4.287584191504131, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00016880829015544047, 'proxyInfectionSummaryAbsoluteReward_min': -0.001150259067357514, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.15203111043330153, 'proxyLowerStageReward_min': -0.18526474950471436, 'proxyLowerStageReward_max': -0.1187994863155394, 'proxySmoothStageChangesReward_mean': -0.16295336787564768, 'proxySmoothStageChangesReward_min': -0.25906735751295334, 'proxySmoothStageChangesReward_max': -0.06735751295336788, 'trueInfectionSummaryAbsoluteReward_mean': -0.00016880829015544047, 'trueInfectionSummaryAbsoluteReward_min': -0.001150259067357514, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.04082279792746115, 'truePoliticalReward_min': -0.09512953367875647, 'truePoliticalReward_max': -0.0018652849740932642, 'trueLowerStageReward_mean': -0.15203111043330153, 'trueLowerStageReward_min': -0.18526474950471436, 'trueLowerStageReward_max': -0.1187994863155394, 'trueSmoothStageChangesReward_mean': -0.16295336787564768, 'trueSmoothStageChangesReward_min': -0.25906735751295334, 'trueSmoothStageChangesReward_max': -0.06735751295336788, 'total_modified_reward_mean': -5.472297090409541, 'total_modified_reward_min': -7.063240110861145, 'total_modified_reward_max': -4.287584191504131}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9791728961964449, 'cur_kl_coeff': 0.22500000000000006, 'cur_lr': 0.0003, 'total_loss': -0.06200211567648997, 'policy_loss': -0.014313626953711113, 'vf_loss': 0.01493733743399692, 'vf_explained_var': 0.8982459940512975, 'kl': 0.00570394350160304, 'entropy': 0.6020529658595721, 'entropy_coeff': 0.0937468}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 2850.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 38600, 'num_env_steps_trained': 38600, 'num_agent_steps_sampled': 38600, 'num_agent_steps_trained': 38600}, 'sampler_results': {'episode_reward_max': -4.287584191504131, 'episode_reward_min': -7.063240110861145, 'episode_reward_mean': -5.472297090409541, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -82.36250043136282, 'default_policy/true_reward_min': -187.1624242404913, 'default_policy/true_reward_max': -6.847106781186554, 'default_policy/proxy_reward_mean': -3.5745004313627295, 'default_policy/proxy_reward_min': -5.267094154601843, 'default_policy/proxy_reward_max': -2.73104076400857, 'default_policy/modified_reward_mean': -5.472297090409541, 'default_policy/modified_reward_min': -7.063240110861145, 'default_policy/modified_reward_max': -4.287584191504131, 'default_policy/corr_btw_rewards_mean': 0.5082091202088462, 'default_policy/corr_btw_rewards_min': 0.13020614530266408, 'default_policy/corr_btw_rewards_max': 0.7796681325038016, 'true_reward_mean': -82.36250043136282, 'true_reward_min': -187.1624242404913, 'true_reward_max': -6.847106781186554, 'proxy_reward_mean': -3.5745004313627295, 'proxy_reward_min': -5.267094154601843, 'proxy_reward_max': -2.73104076400857, 'modified_reward_mean': -5.472297090409541, 'modified_reward_min': -7.063240110861145, 'modified_reward_max': -4.287584191504131, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00016880829015544047, 'proxyInfectionSummaryAbsoluteReward_min': -0.001150259067357514, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.15203111043330153, 'proxyLowerStageReward_min': -0.18526474950471436, 'proxyLowerStageReward_max': -0.1187994863155394, 'proxySmoothStageChangesReward_mean': -0.16295336787564768, 'proxySmoothStageChangesReward_min': -0.25906735751295334, 'proxySmoothStageChangesReward_max': -0.06735751295336788, 'trueInfectionSummaryAbsoluteReward_mean': -0.00016880829015544047, 'trueInfectionSummaryAbsoluteReward_min': -0.001150259067357514, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.04082279792746115, 'truePoliticalReward_min': -0.09512953367875647, 'truePoliticalReward_max': -0.0018652849740932642, 'trueLowerStageReward_mean': -0.15203111043330153, 'trueLowerStageReward_min': -0.18526474950471436, 'trueLowerStageReward_max': -0.1187994863155394, 'trueSmoothStageChangesReward_mean': -0.16295336787564768, 'trueSmoothStageChangesReward_min': -0.25906735751295334, 'trueSmoothStageChangesReward_max': -0.06735751295336788, 'total_modified_reward_mean': -5.472297090409541, 'total_modified_reward_min': -7.063240110861145, 'total_modified_reward_max': -4.287584191504131}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5392816240376493, 'mean_inference_ms': 1.721248304640889, 'mean_action_processing_ms': 0.11033493521740637, 'mean_env_wait_ms': 798.7406393959966, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -4.287584191504131, 'episode_reward_min': -7.063240110861145, 'episode_reward_mean': -5.472297090409541, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5392816240376493, 'mean_inference_ms': 1.721248304640889, 'mean_action_processing_ms': 0.11033493521740637, 'mean_env_wait_ms': 798.7406393959966, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 38600, 'num_agent_steps_trained': 38600, 'num_env_steps_sampled': 38600, 'num_env_steps_trained': 38600, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.12003302425528, 'num_env_steps_trained_throughput_per_sec': 12.12003302425528, 'timesteps_total': 38600, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 38600, 'timers': {'training_iteration_time_ms': 325303.77, 'sample_time_ms': 324278.843, 'load_time_ms': 3.778, 'load_throughput': 1021806.522, 'learn_time_ms': 1004.351, 'learn_throughput': 3843.277, 'synch_weights_time_ms': 15.929}, 'counters': {'num_env_steps_sampled': 38600, 'num_env_steps_trained': 38600, 'num_agent_steps_sampled': 38600, 'num_agent_steps_trained': 38600}, 'done': False, 'episodes_total': 200, 'training_iteration': 10, 'trial_id': 'default', 'date': '2025-11-04_19-47-01', 'timestamp': 1762314421, 'time_this_iter_s': 318.5006513595581, 'time_total_s': 3253.206860780716, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e0ffcbb0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e0ffc100>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffd120>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffe560>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 3253.206860780716, 'iterations_since_restore': 10, 'perf': {'cpu_util_percent': 19.984988962472407, 'ram_util_percent': 6.0}}
Saved checkpoint to TrainingResult(checkpoint=Checkpoint(filesystem=local, path=logs/data/pandemic/20251104_185246/checkpoint_10), metrics={'custom_metrics': {'default_policy/true_reward_mean': -82.36250043136282, 'default_policy/true_reward_min': -187.1624242404913, 'default_policy/true_reward_max': -6.847106781186554, 'default_policy/proxy_reward_mean': -3.5745004313627295, 'default_policy/proxy_reward_min': -5.267094154601843, 'default_policy/proxy_reward_max': -2.73104076400857, 'default_policy/modified_reward_mean': -5.472297090409541, 'default_policy/modified_reward_min': -7.063240110861145, 'default_policy/modified_reward_max': -4.287584191504131, 'default_policy/corr_btw_rewards_mean': 0.5082091202088462, 'default_policy/corr_btw_rewards_min': 0.13020614530266408, 'default_policy/corr_btw_rewards_max': 0.7796681325038016, 'true_reward_mean': -82.36250043136282, 'true_reward_min': -187.1624242404913, 'true_reward_max': -6.847106781186554, 'proxy_reward_mean': -3.5745004313627295, 'proxy_reward_min': -5.267094154601843, 'proxy_reward_max': -2.73104076400857, 'modified_reward_mean': -5.472297090409541, 'modified_reward_min': -7.063240110861145, 'modified_reward_max': -4.287584191504131, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00016880829015544047, 'proxyInfectionSummaryAbsoluteReward_min': -0.001150259067357514, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.15203111043330153, 'proxyLowerStageReward_min': -0.18526474950471436, 'proxyLowerStageReward_max': -0.1187994863155394, 'proxySmoothStageChangesReward_mean': -0.16295336787564768, 'proxySmoothStageChangesReward_min': -0.25906735751295334, 'proxySmoothStageChangesReward_max': -0.06735751295336788, 'trueInfectionSummaryAbsoluteReward_mean': -0.00016880829015544047, 'trueInfectionSummaryAbsoluteReward_min': -0.001150259067357514, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.04082279792746115, 'truePoliticalReward_min': -0.09512953367875647, 'truePoliticalReward_max': -0.0018652849740932642, 'trueLowerStageReward_mean': -0.15203111043330153, 'trueLowerStageReward_min': -0.18526474950471436, 'trueLowerStageReward_max': -0.1187994863155394, 'trueSmoothStageChangesReward_mean': -0.16295336787564768, 'trueSmoothStageChangesReward_min': -0.25906735751295334, 'trueSmoothStageChangesReward_max': -0.06735751295336788, 'total_modified_reward_mean': -5.472297090409541, 'total_modified_reward_min': -7.063240110861145, 'total_modified_reward_max': -4.287584191504131}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9791728961964449, 'cur_kl_coeff': 0.22500000000000006, 'cur_lr': 0.0003, 'total_loss': -0.06200211567648997, 'policy_loss': -0.014313626953711113, 'vf_loss': 0.01493733743399692, 'vf_explained_var': 0.8982459940512975, 'kl': 0.00570394350160304, 'entropy': 0.6020529658595721, 'entropy_coeff': 0.0937468}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 2850.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 38600, 'num_env_steps_trained': 38600, 'num_agent_steps_sampled': 38600, 'num_agent_steps_trained': 38600}, 'sampler_results': {'episode_reward_max': -4.287584191504131, 'episode_reward_min': -7.063240110861145, 'episode_reward_mean': -5.472297090409541, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -82.36250043136282, 'default_policy/true_reward_min': -187.1624242404913, 'default_policy/true_reward_max': -6.847106781186554, 'default_policy/proxy_reward_mean': -3.5745004313627295, 'default_policy/proxy_reward_min': -5.267094154601843, 'default_policy/proxy_reward_max': -2.73104076400857, 'default_policy/modified_reward_mean': -5.472297090409541, 'default_policy/modified_reward_min': -7.063240110861145, 'default_policy/modified_reward_max': -4.287584191504131, 'default_policy/corr_btw_rewards_mean': 0.5082091202088462, 'default_policy/corr_btw_rewards_min': 0.13020614530266408, 'default_policy/corr_btw_rewards_max': 0.7796681325038016, 'true_reward_mean': -82.36250043136282, 'true_reward_min': -187.1624242404913, 'true_reward_max': -6.847106781186554, 'proxy_reward_mean': -3.5745004313627295, 'proxy_reward_min': -5.267094154601843, 'proxy_reward_max': -2.73104076400857, 'modified_reward_mean': -5.472297090409541, 'modified_reward_min': -7.063240110861145, 'modified_reward_max': -4.287584191504131, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00016880829015544047, 'proxyInfectionSummaryAbsoluteReward_min': -0.001150259067357514, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.15203111043330153, 'proxyLowerStageReward_min': -0.18526474950471436, 'proxyLowerStageReward_max': -0.1187994863155394, 'proxySmoothStageChangesReward_mean': -0.16295336787564768, 'proxySmoothStageChangesReward_min': -0.25906735751295334, 'proxySmoothStageChangesReward_max': -0.06735751295336788, 'trueInfectionSummaryAbsoluteReward_mean': -0.00016880829015544047, 'trueInfectionSummaryAbsoluteReward_min': -0.001150259067357514, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.04082279792746115, 'truePoliticalReward_min': -0.09512953367875647, 'truePoliticalReward_max': -0.0018652849740932642, 'trueLowerStageReward_mean': -0.15203111043330153, 'trueLowerStageReward_min': -0.18526474950471436, 'trueLowerStageReward_max': -0.1187994863155394, 'trueSmoothStageChangesReward_mean': -0.16295336787564768, 'trueSmoothStageChangesReward_min': -0.25906735751295334, 'trueSmoothStageChangesReward_max': -0.06735751295336788, 'total_modified_reward_mean': -5.472297090409541, 'total_modified_reward_min': -7.063240110861145, 'total_modified_reward_max': -4.287584191504131}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5392816240376493, 'mean_inference_ms': 1.721248304640889, 'mean_action_processing_ms': 0.11033493521740637, 'mean_env_wait_ms': 798.7406393959966, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -4.287584191504131, 'episode_reward_min': -7.063240110861145, 'episode_reward_mean': -5.472297090409541, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5392816240376493, 'mean_inference_ms': 1.721248304640889, 'mean_action_processing_ms': 0.11033493521740637, 'mean_env_wait_ms': 798.7406393959966, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 38600, 'num_agent_steps_trained': 38600, 'num_env_steps_sampled': 38600, 'num_env_steps_trained': 38600, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.12003302425528, 'num_env_steps_trained_throughput_per_sec': 12.12003302425528, 'timesteps_total': 38600, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 38600, 'timers': {'training_iteration_time_ms': 325303.77, 'sample_time_ms': 324278.843, 'load_time_ms': 3.778, 'load_throughput': 1021806.522, 'learn_time_ms': 1004.351, 'learn_throughput': 3843.277, 'synch_weights_time_ms': 15.929}, 'counters': {'num_env_steps_sampled': 38600, 'num_env_steps_trained': 38600, 'num_agent_steps_sampled': 38600, 'num_agent_steps_trained': 38600}, 'done': False, 'episodes_total': 200, 'training_iteration': 10, 'trial_id': 'default', 'date': '2025-11-04_19-47-01', 'timestamp': 1762314421, 'time_this_iter_s': 318.5006513595581, 'time_total_s': 3253.206860780716, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e0ffcbb0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e0ffc100>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffd120>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffe560>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 3253.206860780716, 'iterations_since_restore': 10, 'perf': {'cpu_util_percent': 19.984988962472407, 'ram_util_percent': 6.0}})
Iteration 11/100
{'custom_metrics': {'default_policy/true_reward_mean': -77.2014294359762, 'default_policy/true_reward_min': -187.1624242404913, 'default_policy/true_reward_max': -6.639962120245892, 'default_policy/proxy_reward_mean': -3.4654294359760853, 'default_policy/proxy_reward_min': -9.470330085889913, 'default_policy/proxy_reward_max': -2.244264068711928, 'default_policy/modified_reward_mean': -5.2540883753581715, 'default_policy/modified_reward_min': -10.90173794482183, 'default_policy/modified_reward_max': -3.510518485068473, 'default_policy/corr_btw_rewards_mean': 0.5124104201956097, 'default_policy/corr_btw_rewards_min': 0.06787263362451555, 'default_policy/corr_btw_rewards_max': 0.7796681325038016, 'true_reward_mean': -77.2014294359762, 'true_reward_min': -187.1624242404913, 'true_reward_max': -6.639962120245892, 'proxy_reward_mean': -3.4654294359760853, 'proxy_reward_min': -9.470330085889913, 'proxy_reward_max': -2.244264068711928, 'modified_reward_mean': -5.2540883753581715, 'modified_reward_min': -10.90173794482183, 'modified_reward_max': -3.510518485068473, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00021222797927461154, 'proxyInfectionSummaryAbsoluteReward_min': -0.0035854922279792774, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.1426077427966879, 'proxyLowerStageReward_min': -0.16868574707825923, 'proxyLowerStageReward_max': -0.11006549578818282, 'proxySmoothStageChangesReward_mean': -0.1572538860103627, 'proxySmoothStageChangesReward_min': -0.25906735751295334, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.00021222797927461154, 'trueInfectionSummaryAbsoluteReward_min': -0.0035854922279792774, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.03820518134715026, 'truePoliticalReward_min': -0.09512953367875647, 'truePoliticalReward_max': -0.0016580310880829018, 'trueLowerStageReward_mean': -0.1426077427966879, 'trueLowerStageReward_min': -0.16868574707825923, 'trueLowerStageReward_max': -0.11006549578818282, 'trueSmoothStageChangesReward_mean': -0.1572538860103627, 'trueSmoothStageChangesReward_min': -0.25906735751295334, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -5.2540883753581715, 'total_modified_reward_min': -10.90173794482183, 'total_modified_reward_max': -3.510518485068473}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.1241854670643807, 'cur_kl_coeff': 0.22500000000000006, 'cur_lr': 0.0003, 'total_loss': -0.05128723635959129, 'policy_loss': -0.005993696457395951, 'vf_loss': 0.028373283724067732, 'vf_explained_var': 0.9169227614005406, 'kl': 0.006448967309327272, 'entropy': 0.6548080939054489, 'entropy_coeff': 0.09305200000000001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 3150.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 42460, 'num_env_steps_trained': 42460, 'num_agent_steps_sampled': 42460, 'num_agent_steps_trained': 42460}, 'sampler_results': {'episode_reward_max': -3.510518485068473, 'episode_reward_min': -10.90173794482183, 'episode_reward_mean': -5.2540883753581715, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -77.2014294359762, 'default_policy/true_reward_min': -187.1624242404913, 'default_policy/true_reward_max': -6.639962120245892, 'default_policy/proxy_reward_mean': -3.4654294359760853, 'default_policy/proxy_reward_min': -9.470330085889913, 'default_policy/proxy_reward_max': -2.244264068711928, 'default_policy/modified_reward_mean': -5.2540883753581715, 'default_policy/modified_reward_min': -10.90173794482183, 'default_policy/modified_reward_max': -3.510518485068473, 'default_policy/corr_btw_rewards_mean': 0.5124104201956097, 'default_policy/corr_btw_rewards_min': 0.06787263362451555, 'default_policy/corr_btw_rewards_max': 0.7796681325038016, 'true_reward_mean': -77.2014294359762, 'true_reward_min': -187.1624242404913, 'true_reward_max': -6.639962120245892, 'proxy_reward_mean': -3.4654294359760853, 'proxy_reward_min': -9.470330085889913, 'proxy_reward_max': -2.244264068711928, 'modified_reward_mean': -5.2540883753581715, 'modified_reward_min': -10.90173794482183, 'modified_reward_max': -3.510518485068473, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00021222797927461154, 'proxyInfectionSummaryAbsoluteReward_min': -0.0035854922279792774, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.1426077427966879, 'proxyLowerStageReward_min': -0.16868574707825923, 'proxyLowerStageReward_max': -0.11006549578818282, 'proxySmoothStageChangesReward_mean': -0.1572538860103627, 'proxySmoothStageChangesReward_min': -0.25906735751295334, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.00021222797927461154, 'trueInfectionSummaryAbsoluteReward_min': -0.0035854922279792774, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.03820518134715026, 'truePoliticalReward_min': -0.09512953367875647, 'truePoliticalReward_max': -0.0016580310880829018, 'trueLowerStageReward_mean': -0.1426077427966879, 'trueLowerStageReward_min': -0.16868574707825923, 'trueLowerStageReward_max': -0.11006549578818282, 'trueSmoothStageChangesReward_mean': -0.1572538860103627, 'trueSmoothStageChangesReward_min': -0.25906735751295334, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -5.2540883753581715, 'total_modified_reward_min': -10.90173794482183, 'total_modified_reward_max': -3.510518485068473}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5374420107699254, 'mean_inference_ms': 1.7163511271529162, 'mean_action_processing_ms': 0.10993215706397796, 'mean_env_wait_ms': 797.3098621722969, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -3.510518485068473, 'episode_reward_min': -10.90173794482183, 'episode_reward_mean': -5.2540883753581715, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5374420107699254, 'mean_inference_ms': 1.7163511271529162, 'mean_action_processing_ms': 0.10993215706397796, 'mean_env_wait_ms': 797.3098621722969, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 42460, 'num_agent_steps_trained': 42460, 'num_env_steps_sampled': 42460, 'num_env_steps_trained': 42460, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.526195793333093, 'num_env_steps_trained_throughput_per_sec': 12.526195793333093, 'timesteps_total': 42460, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 42460, 'timers': {'training_iteration_time_ms': 327451.562, 'sample_time_ms': 326422.662, 'load_time_ms': 4.086, 'load_throughput': 944718.186, 'learn_time_ms': 1007.866, 'learn_throughput': 3829.873, 'synch_weights_time_ms': 16.146}, 'counters': {'num_env_steps_sampled': 42460, 'num_env_steps_trained': 42460, 'num_agent_steps_sampled': 42460, 'num_agent_steps_trained': 42460}, 'done': False, 'episodes_total': 220, 'training_iteration': 11, 'trial_id': 'default', 'date': '2025-11-04_19-52-10', 'timestamp': 1762314730, 'time_this_iter_s': 308.170702457428, 'time_total_s': 3561.377563238144, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e11b9510>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699563a90>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e25120e0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e11ba9e0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 3561.377563238144, 'iterations_since_restore': 11, 'perf': {'cpu_util_percent': 20.037272727272725, 'ram_util_percent': 6.0}}
Iteration 12/100
{'custom_metrics': {'default_policy/true_reward_mean': -63.834271914503724, 'default_policy/true_reward_min': -158.01993686707664, 'default_policy/true_reward_max': -4.726040764008578, 'default_policy/proxy_reward_mean': -3.3582719145036064, 'default_policy/proxy_reward_min': -9.470330085889913, 'default_policy/proxy_reward_max': -2.244264068711928, 'default_policy/modified_reward_mean': -5.045066081292729, 'default_policy/modified_reward_min': -10.90173794482183, 'default_policy/modified_reward_max': -3.510518485068473, 'default_policy/corr_btw_rewards_mean': 0.48149431351826066, 'default_policy/corr_btw_rewards_min': 0.06787263362451555, 'default_policy/corr_btw_rewards_max': 0.7796681325038016, 'true_reward_mean': -63.834271914503724, 'true_reward_min': -158.01993686707664, 'true_reward_max': -4.726040764008578, 'proxy_reward_mean': -3.3582719145036064, 'proxy_reward_min': -9.470330085889913, 'proxy_reward_max': -2.244264068711928, 'modified_reward_mean': -5.045066081292729, 'modified_reward_min': -10.90173794482183, 'modified_reward_max': -3.510518485068473, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002407253886010364, 'proxyInfectionSummaryAbsoluteReward_min': -0.0035854922279792774, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.1358223789898238, 'proxyLowerStageReward_min': -0.16792695635594454, 'proxyLowerStageReward_max': -0.11006549578818282, 'proxySmoothStageChangesReward_mean': -0.14108808290155442, 'proxySmoothStageChangesReward_min': -0.24870466321243523, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002407253886010364, 'trueInfectionSummaryAbsoluteReward_min': -0.0035854922279792774, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.031334715025906734, 'truePoliticalReward_min': -0.07999999999999999, 'truePoliticalReward_max': -0.0008290155440414509, 'trueLowerStageReward_mean': -0.1358223789898238, 'trueLowerStageReward_min': -0.16792695635594454, 'trueLowerStageReward_max': -0.11006549578818282, 'trueSmoothStageChangesReward_mean': -0.14108808290155442, 'trueSmoothStageChangesReward_min': -0.24870466321243523, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -5.045066081292729, 'total_modified_reward_min': -10.90173794482183, 'total_modified_reward_max': -3.510518485068473}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0691099454214175, 'cur_kl_coeff': 0.22500000000000006, 'cur_lr': 0.0003, 'total_loss': -0.05157471631964048, 'policy_loss': -0.006378968719703456, 'vf_loss': 0.03145349034797012, 'vf_explained_var': 0.8380946260690689, 'kl': 0.004187911402127688, 'entropy': 0.6698424275716146, 'entropy_coeff': 0.09235720000000001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 3450.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 46320, 'num_env_steps_trained': 46320, 'num_agent_steps_sampled': 46320, 'num_agent_steps_trained': 46320}, 'sampler_results': {'episode_reward_max': -3.510518485068473, 'episode_reward_min': -10.90173794482183, 'episode_reward_mean': -5.045066081292729, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -63.834271914503724, 'default_policy/true_reward_min': -158.01993686707664, 'default_policy/true_reward_max': -4.726040764008578, 'default_policy/proxy_reward_mean': -3.3582719145036064, 'default_policy/proxy_reward_min': -9.470330085889913, 'default_policy/proxy_reward_max': -2.244264068711928, 'default_policy/modified_reward_mean': -5.045066081292729, 'default_policy/modified_reward_min': -10.90173794482183, 'default_policy/modified_reward_max': -3.510518485068473, 'default_policy/corr_btw_rewards_mean': 0.48149431351826066, 'default_policy/corr_btw_rewards_min': 0.06787263362451555, 'default_policy/corr_btw_rewards_max': 0.7796681325038016, 'true_reward_mean': -63.834271914503724, 'true_reward_min': -158.01993686707664, 'true_reward_max': -4.726040764008578, 'proxy_reward_mean': -3.3582719145036064, 'proxy_reward_min': -9.470330085889913, 'proxy_reward_max': -2.244264068711928, 'modified_reward_mean': -5.045066081292729, 'modified_reward_min': -10.90173794482183, 'modified_reward_max': -3.510518485068473, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002407253886010364, 'proxyInfectionSummaryAbsoluteReward_min': -0.0035854922279792774, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.1358223789898238, 'proxyLowerStageReward_min': -0.16792695635594454, 'proxyLowerStageReward_max': -0.11006549578818282, 'proxySmoothStageChangesReward_mean': -0.14108808290155442, 'proxySmoothStageChangesReward_min': -0.24870466321243523, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002407253886010364, 'trueInfectionSummaryAbsoluteReward_min': -0.0035854922279792774, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.031334715025906734, 'truePoliticalReward_min': -0.07999999999999999, 'truePoliticalReward_max': -0.0008290155440414509, 'trueLowerStageReward_mean': -0.1358223789898238, 'trueLowerStageReward_min': -0.16792695635594454, 'trueLowerStageReward_max': -0.11006549578818282, 'trueSmoothStageChangesReward_mean': -0.14108808290155442, 'trueSmoothStageChangesReward_min': -0.24870466321243523, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -5.045066081292729, 'total_modified_reward_min': -10.90173794482183, 'total_modified_reward_max': -3.510518485068473}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.534094931825019, 'mean_inference_ms': 1.7119381566597114, 'mean_action_processing_ms': 0.10959236937306883, 'mean_env_wait_ms': 795.6821912930245, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -3.510518485068473, 'episode_reward_min': -10.90173794482183, 'episode_reward_mean': -5.045066081292729, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.534094931825019, 'mean_inference_ms': 1.7119381566597114, 'mean_action_processing_ms': 0.10959236937306883, 'mean_env_wait_ms': 795.6821912930245, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 46320, 'num_agent_steps_trained': 46320, 'num_env_steps_sampled': 46320, 'num_env_steps_trained': 46320, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.593095236815335, 'num_env_steps_trained_throughput_per_sec': 12.593095236815335, 'timesteps_total': 46320, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 46320, 'timers': {'training_iteration_time_ms': 327805.291, 'sample_time_ms': 326755.268, 'load_time_ms': 4.265, 'load_throughput': 905076.78, 'learn_time_ms': 1028.843, 'learn_throughput': 3751.787, 'synch_weights_time_ms': 16.083}, 'counters': {'num_env_steps_sampled': 46320, 'num_env_steps_trained': 46320, 'num_agent_steps_sampled': 46320, 'num_agent_steps_trained': 46320}, 'done': False, 'episodes_total': 240, 'training_iteration': 12, 'trial_id': 'default', 'date': '2025-11-04_19-57-16', 'timestamp': 1762315036, 'time_this_iter_s': 306.53745794296265, 'time_total_s': 3867.9150211811066, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e24fb2b0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e24f91e0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e24f8f40>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e24f81c0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 3867.9150211811066, 'iterations_since_restore': 12, 'perf': {'cpu_util_percent': 20.061784897025177, 'ram_util_percent': 6.0}}
Iteration 13/100
{'custom_metrics': {'default_policy/true_reward_mean': -56.93172341174702, 'default_policy/true_reward_min': -127.15744949366142, 'default_policy/true_reward_max': -4.726040764008578, 'default_policy/proxy_reward_mean': -3.2717234117468967, 'default_policy/proxy_reward_min': -9.470330085889913, 'default_policy/proxy_reward_max': -2.244264068711928, 'default_policy/modified_reward_mean': -4.881101650466316, 'default_policy/modified_reward_min': -10.90173794482183, 'default_policy/modified_reward_max': -3.510518485068473, 'default_policy/corr_btw_rewards_mean': 0.4612192728813222, 'default_policy/corr_btw_rewards_min': 0.06787263362451555, 'default_policy/corr_btw_rewards_max': 0.7796681325038016, 'true_reward_mean': -56.93172341174702, 'true_reward_min': -127.15744949366142, 'true_reward_max': -4.726040764008578, 'proxy_reward_mean': -3.2717234117468967, 'proxy_reward_min': -9.470330085889913, 'proxy_reward_max': -2.244264068711928, 'modified_reward_mean': -4.881101650466316, 'modified_reward_min': -10.90173794482183, 'modified_reward_max': -3.510518485068473, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00026124352331606234, 'proxyInfectionSummaryAbsoluteReward_min': -0.0035854922279792774, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.13033800060864711, 'proxyLowerStageReward_min': -0.15123683160095722, 'proxyLowerStageReward_max': -0.11006549578818282, 'proxySmoothStageChangesReward_mean': -0.1305699481865285, 'proxySmoothStageChangesReward_min': -0.20725388601036268, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.00026124352331606234, 'trueInfectionSummaryAbsoluteReward_min': -0.0035854922279792774, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.02780310880829016, 'truePoliticalReward_min': -0.06424870466321243, 'truePoliticalReward_max': -0.0008290155440414509, 'trueLowerStageReward_mean': -0.13033800060864711, 'trueLowerStageReward_min': -0.15123683160095722, 'trueLowerStageReward_max': -0.11006549578818282, 'trueSmoothStageChangesReward_mean': -0.1305699481865285, 'trueSmoothStageChangesReward_min': -0.20725388601036268, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -4.881101650466316, 'total_modified_reward_min': -10.90173794482183, 'total_modified_reward_max': -3.510518485068473}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0532770418127377, 'cur_kl_coeff': 0.11250000000000003, 'cur_lr': 0.0003, 'total_loss': -0.05032988578566195, 'policy_loss': 0.0008632747052858273, 'vf_loss': 0.0200518126001892, 'vf_explained_var': 0.8682156572739284, 'kl': 0.008486815484695617, 'entropy': 0.6782916055123012, 'entropy_coeff': 0.09166240000000002}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 3750.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 50180, 'num_env_steps_trained': 50180, 'num_agent_steps_sampled': 50180, 'num_agent_steps_trained': 50180}, 'sampler_results': {'episode_reward_max': -3.510518485068473, 'episode_reward_min': -10.90173794482183, 'episode_reward_mean': -4.881101650466316, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -56.93172341174702, 'default_policy/true_reward_min': -127.15744949366142, 'default_policy/true_reward_max': -4.726040764008578, 'default_policy/proxy_reward_mean': -3.2717234117468967, 'default_policy/proxy_reward_min': -9.470330085889913, 'default_policy/proxy_reward_max': -2.244264068711928, 'default_policy/modified_reward_mean': -4.881101650466316, 'default_policy/modified_reward_min': -10.90173794482183, 'default_policy/modified_reward_max': -3.510518485068473, 'default_policy/corr_btw_rewards_mean': 0.4612192728813222, 'default_policy/corr_btw_rewards_min': 0.06787263362451555, 'default_policy/corr_btw_rewards_max': 0.7796681325038016, 'true_reward_mean': -56.93172341174702, 'true_reward_min': -127.15744949366142, 'true_reward_max': -4.726040764008578, 'proxy_reward_mean': -3.2717234117468967, 'proxy_reward_min': -9.470330085889913, 'proxy_reward_max': -2.244264068711928, 'modified_reward_mean': -4.881101650466316, 'modified_reward_min': -10.90173794482183, 'modified_reward_max': -3.510518485068473, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00026124352331606234, 'proxyInfectionSummaryAbsoluteReward_min': -0.0035854922279792774, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.13033800060864711, 'proxyLowerStageReward_min': -0.15123683160095722, 'proxyLowerStageReward_max': -0.11006549578818282, 'proxySmoothStageChangesReward_mean': -0.1305699481865285, 'proxySmoothStageChangesReward_min': -0.20725388601036268, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.00026124352331606234, 'trueInfectionSummaryAbsoluteReward_min': -0.0035854922279792774, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.02780310880829016, 'truePoliticalReward_min': -0.06424870466321243, 'truePoliticalReward_max': -0.0008290155440414509, 'trueLowerStageReward_mean': -0.13033800060864711, 'trueLowerStageReward_min': -0.15123683160095722, 'trueLowerStageReward_max': -0.11006549578818282, 'trueSmoothStageChangesReward_mean': -0.1305699481865285, 'trueSmoothStageChangesReward_min': -0.20725388601036268, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -4.881101650466316, 'total_modified_reward_min': -10.90173794482183, 'total_modified_reward_max': -3.510518485068473}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5315139521301768, 'mean_inference_ms': 1.7083885081642725, 'mean_action_processing_ms': 0.10934226500217946, 'mean_env_wait_ms': 793.8432866142106, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -3.510518485068473, 'episode_reward_min': -10.90173794482183, 'episode_reward_mean': -4.881101650466316, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5315139521301768, 'mean_inference_ms': 1.7083885081642725, 'mean_action_processing_ms': 0.10934226500217946, 'mean_env_wait_ms': 793.8432866142106, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 50180, 'num_agent_steps_trained': 50180, 'num_env_steps_sampled': 50180, 'num_env_steps_trained': 50180, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.570896030867884, 'num_env_steps_trained_throughput_per_sec': 12.570896030867884, 'timesteps_total': 50180, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 50180, 'timers': {'training_iteration_time_ms': 324661.544, 'sample_time_ms': 323618.093, 'load_time_ms': 4.45, 'load_throughput': 867450.717, 'learn_time_ms': 1021.822, 'learn_throughput': 3777.567, 'synch_weights_time_ms': 16.371}, 'counters': {'num_env_steps_sampled': 50180, 'num_env_steps_trained': 50180, 'num_agent_steps_sampled': 50180, 'num_agent_steps_trained': 50180}, 'done': False, 'episodes_total': 260, 'training_iteration': 13, 'trial_id': 'default', 'date': '2025-11-04_20-02-23', 'timestamp': 1762315343, 'time_this_iter_s': 307.0782220363617, 'time_total_s': 4174.993243217468, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e2630820>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6a9255cf0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699561e70>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699561c30>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 4174.993243217468, 'iterations_since_restore': 13, 'perf': {'cpu_util_percent': 20.32105263157895, 'ram_util_percent': 6.0}}
Iteration 14/100
{'custom_metrics': {'default_policy/true_reward_mean': -50.77017492693715, 'default_policy/true_reward_min': -112.8342514421275, 'default_policy/true_reward_max': -3.0563961030679008, 'default_policy/proxy_reward_mean': -3.2501749269370617, 'default_policy/proxy_reward_min': -9.470330085889913, 'default_policy/proxy_reward_max': -2.244264068711928, 'default_policy/modified_reward_mean': -4.804888114477021, 'default_policy/modified_reward_min': -10.90173794482183, 'default_policy/modified_reward_max': -3.510518485068473, 'default_policy/corr_btw_rewards_mean': 0.44898902786593553, 'default_policy/corr_btw_rewards_min': 0.05262429493363519, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -50.77017492693715, 'true_reward_min': -112.8342514421275, 'true_reward_max': -3.0563961030679008, 'proxy_reward_mean': -3.2501749269370617, 'proxy_reward_min': -9.470330085889913, 'proxy_reward_max': -2.244264068711928, 'modified_reward_mean': -4.804888114477021, 'modified_reward_min': -10.90173794482183, 'modified_reward_max': -3.510518485068473, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002946113989637307, 'proxyInfectionSummaryAbsoluteReward_min': -0.0035854922279792774, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.12681735372730854, 'proxyLowerStageReward_min': -0.14886840268289225, 'proxyLowerStageReward_max': -0.11006549578818282, 'proxySmoothStageChangesReward_mean': -0.12124352331606218, 'proxySmoothStageChangesReward_min': -0.19689119170984457, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002946113989637307, 'trueInfectionSummaryAbsoluteReward_min': -0.0035854922279792774, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.02462176165803109, 'truePoliticalReward_min': -0.05699481865284974, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.12681735372730854, 'trueLowerStageReward_min': -0.14886840268289225, 'trueLowerStageReward_max': -0.11006549578818282, 'trueSmoothStageChangesReward_mean': -0.12124352331606218, 'trueSmoothStageChangesReward_min': -0.19689119170984457, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -4.804888114477021, 'total_modified_reward_min': -10.90173794482183, 'total_modified_reward_max': -3.510518485068473}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0213692071040472, 'cur_kl_coeff': 0.11250000000000003, 'cur_lr': 0.0003, 'total_loss': -0.053535440963848185, 'policy_loss': -0.004742327663116157, 'vf_loss': 0.022172083766587698, 'vf_explained_var': 0.9339948310454687, 'kl': 0.006574412978520954, 'entropy': 0.6663776540756225, 'entropy_coeff': 0.09096760000000002}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 4050.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 54040, 'num_env_steps_trained': 54040, 'num_agent_steps_sampled': 54040, 'num_agent_steps_trained': 54040}, 'sampler_results': {'episode_reward_max': -3.510518485068473, 'episode_reward_min': -10.90173794482183, 'episode_reward_mean': -4.804888114477021, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -50.77017492693715, 'default_policy/true_reward_min': -112.8342514421275, 'default_policy/true_reward_max': -3.0563961030679008, 'default_policy/proxy_reward_mean': -3.2501749269370617, 'default_policy/proxy_reward_min': -9.470330085889913, 'default_policy/proxy_reward_max': -2.244264068711928, 'default_policy/modified_reward_mean': -4.804888114477021, 'default_policy/modified_reward_min': -10.90173794482183, 'default_policy/modified_reward_max': -3.510518485068473, 'default_policy/corr_btw_rewards_mean': 0.44898902786593553, 'default_policy/corr_btw_rewards_min': 0.05262429493363519, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -50.77017492693715, 'true_reward_min': -112.8342514421275, 'true_reward_max': -3.0563961030679008, 'proxy_reward_mean': -3.2501749269370617, 'proxy_reward_min': -9.470330085889913, 'proxy_reward_max': -2.244264068711928, 'modified_reward_mean': -4.804888114477021, 'modified_reward_min': -10.90173794482183, 'modified_reward_max': -3.510518485068473, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002946113989637307, 'proxyInfectionSummaryAbsoluteReward_min': -0.0035854922279792774, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.12681735372730854, 'proxyLowerStageReward_min': -0.14886840268289225, 'proxyLowerStageReward_max': -0.11006549578818282, 'proxySmoothStageChangesReward_mean': -0.12124352331606218, 'proxySmoothStageChangesReward_min': -0.19689119170984457, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002946113989637307, 'trueInfectionSummaryAbsoluteReward_min': -0.0035854922279792774, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.02462176165803109, 'truePoliticalReward_min': -0.05699481865284974, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.12681735372730854, 'trueLowerStageReward_min': -0.14886840268289225, 'trueLowerStageReward_max': -0.11006549578818282, 'trueSmoothStageChangesReward_mean': -0.12124352331606218, 'trueSmoothStageChangesReward_min': -0.19689119170984457, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -4.804888114477021, 'total_modified_reward_min': -10.90173794482183, 'total_modified_reward_max': -3.510518485068473}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5294431656708162, 'mean_inference_ms': 1.7057299262983963, 'mean_action_processing_ms': 0.10917381277398669, 'mean_env_wait_ms': 792.5838939113778, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -3.510518485068473, 'episode_reward_min': -10.90173794482183, 'episode_reward_mean': -4.804888114477021, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5294431656708162, 'mean_inference_ms': 1.7057299262983963, 'mean_action_processing_ms': 0.10917381277398669, 'mean_env_wait_ms': 792.5838939113778, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 54040, 'num_agent_steps_trained': 54040, 'num_env_steps_sampled': 54040, 'num_env_steps_trained': 54040, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.289252887317149, 'num_env_steps_trained_throughput_per_sec': 12.289252887317149, 'timesteps_total': 54040, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 54040, 'timers': {'training_iteration_time_ms': 323259.635, 'sample_time_ms': 322213.64, 'load_time_ms': 4.645, 'load_throughput': 830990.075, 'learn_time_ms': 1022.962, 'learn_throughput': 3773.356, 'synch_weights_time_ms': 17.528}, 'counters': {'num_env_steps_sampled': 54040, 'num_env_steps_trained': 54040, 'num_agent_steps_sampled': 54040, 'num_agent_steps_trained': 54040}, 'done': False, 'episodes_total': 280, 'training_iteration': 14, 'trial_id': 'default', 'date': '2025-11-04_20-07-38', 'timestamp': 1762315658, 'time_this_iter_s': 314.11688923835754, 'time_total_s': 4489.110132455826, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a699535cc0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699537370>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699611510>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699610040>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 4489.110132455826, 'iterations_since_restore': 14, 'perf': {'cpu_util_percent': 20.062276785714285, 'ram_util_percent': 6.0}}
Iteration 15/100
{'custom_metrics': {'default_policy/true_reward_mean': -49.610617820155966, 'default_policy/true_reward_min': -112.8342514421275, 'default_policy/true_reward_max': -3.0563961030679008, 'default_policy/proxy_reward_mean': -3.154617820155874, 'default_policy/proxy_reward_min': -9.470330085889913, 'default_policy/proxy_reward_max': -2.244264068711928, 'default_policy/modified_reward_mean': -4.6705405055301235, 'default_policy/modified_reward_min': -10.90173794482183, 'default_policy/modified_reward_max': -3.510518485068473, 'default_policy/corr_btw_rewards_mean': 0.4383869290127829, 'default_policy/corr_btw_rewards_min': 0.05262429493363519, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -49.610617820155966, 'true_reward_min': -112.8342514421275, 'true_reward_max': -3.0563961030679008, 'proxy_reward_mean': -3.154617820155874, 'proxy_reward_min': -9.470330085889913, 'proxy_reward_max': -2.244264068711928, 'modified_reward_mean': -4.6705405055301235, 'modified_reward_min': -10.90173794482183, 'modified_reward_max': -3.510518485068473, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002809326424870468, 'proxyInfectionSummaryAbsoluteReward_min': -0.0035854922279792774, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.12339988705470815, 'proxyLowerStageReward_min': -0.14433472392641553, 'proxyLowerStageReward_max': -0.11006549578818282, 'proxySmoothStageChangesReward_mean': -0.1195854922279793, 'proxySmoothStageChangesReward_min': -0.19689119170984457, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002809326424870468, 'trueInfectionSummaryAbsoluteReward_min': -0.0035854922279792774, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.024070466321243524, 'truePoliticalReward_min': -0.05699481865284974, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.12339988705470815, 'trueLowerStageReward_min': -0.14433472392641553, 'trueLowerStageReward_max': -0.11006549578818282, 'trueSmoothStageChangesReward_mean': -0.1195854922279793, 'trueSmoothStageChangesReward_min': -0.19689119170984457, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -4.6705405055301235, 'total_modified_reward_min': -10.90173794482183, 'total_modified_reward_max': -3.510518485068473}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0444825731714567, 'cur_kl_coeff': 0.11250000000000003, 'cur_lr': 0.0003, 'total_loss': -0.05338840277904334, 'policy_loss': -0.0069585607309515275, 'vf_loss': 0.015586788887934138, 'vf_explained_var': 0.9090368970235189, 'kl': 0.006045739512497734, 'entropy': 0.6081940725445747, 'entropy_coeff': 0.09027280000000003}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 4350.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 57900, 'num_env_steps_trained': 57900, 'num_agent_steps_sampled': 57900, 'num_agent_steps_trained': 57900}, 'sampler_results': {'episode_reward_max': -3.510518485068473, 'episode_reward_min': -10.90173794482183, 'episode_reward_mean': -4.6705405055301235, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -49.610617820155966, 'default_policy/true_reward_min': -112.8342514421275, 'default_policy/true_reward_max': -3.0563961030679008, 'default_policy/proxy_reward_mean': -3.154617820155874, 'default_policy/proxy_reward_min': -9.470330085889913, 'default_policy/proxy_reward_max': -2.244264068711928, 'default_policy/modified_reward_mean': -4.6705405055301235, 'default_policy/modified_reward_min': -10.90173794482183, 'default_policy/modified_reward_max': -3.510518485068473, 'default_policy/corr_btw_rewards_mean': 0.4383869290127829, 'default_policy/corr_btw_rewards_min': 0.05262429493363519, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -49.610617820155966, 'true_reward_min': -112.8342514421275, 'true_reward_max': -3.0563961030679008, 'proxy_reward_mean': -3.154617820155874, 'proxy_reward_min': -9.470330085889913, 'proxy_reward_max': -2.244264068711928, 'modified_reward_mean': -4.6705405055301235, 'modified_reward_min': -10.90173794482183, 'modified_reward_max': -3.510518485068473, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002809326424870468, 'proxyInfectionSummaryAbsoluteReward_min': -0.0035854922279792774, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.12339988705470815, 'proxyLowerStageReward_min': -0.14433472392641553, 'proxyLowerStageReward_max': -0.11006549578818282, 'proxySmoothStageChangesReward_mean': -0.1195854922279793, 'proxySmoothStageChangesReward_min': -0.19689119170984457, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002809326424870468, 'trueInfectionSummaryAbsoluteReward_min': -0.0035854922279792774, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.024070466321243524, 'truePoliticalReward_min': -0.05699481865284974, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.12339988705470815, 'trueLowerStageReward_min': -0.14433472392641553, 'trueLowerStageReward_max': -0.11006549578818282, 'trueSmoothStageChangesReward_mean': -0.1195854922279793, 'trueSmoothStageChangesReward_min': -0.19689119170984457, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -4.6705405055301235, 'total_modified_reward_min': -10.90173794482183, 'total_modified_reward_max': -3.510518485068473}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.528060112631669, 'mean_inference_ms': 1.7035452918203005, 'mean_action_processing_ms': 0.10900535789557467, 'mean_env_wait_ms': 791.2816924858926, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -3.510518485068473, 'episode_reward_min': -10.90173794482183, 'episode_reward_mean': -4.6705405055301235, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.528060112631669, 'mean_inference_ms': 1.7035452918203005, 'mean_action_processing_ms': 0.10900535789557467, 'mean_env_wait_ms': 791.2816924858926, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 57900, 'num_agent_steps_trained': 57900, 'num_env_steps_sampled': 57900, 'num_env_steps_trained': 57900, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.268228196372053, 'num_env_steps_trained_throughput_per_sec': 12.268228196372053, 'timesteps_total': 57900, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 57900, 'timers': {'training_iteration_time_ms': 321662.163, 'sample_time_ms': 320616.616, 'load_time_ms': 4.567, 'load_throughput': 845197.592, 'learn_time_ms': 1022.803, 'learn_throughput': 3773.944, 'synch_weights_time_ms': 17.327}, 'counters': {'num_env_steps_sampled': 57900, 'num_env_steps_trained': 57900, 'num_agent_steps_sampled': 57900, 'num_agent_steps_trained': 57900}, 'done': False, 'episodes_total': 300, 'training_iteration': 15, 'trial_id': 'default', 'date': '2025-11-04_20-12-53', 'timestamp': 1762315973, 'time_this_iter_s': 314.6593019962311, 'time_total_s': 4803.769434452057, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a699534880>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e2632440>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e25104f0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffc370>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 4803.769434452057, 'iterations_since_restore': 15, 'perf': {'cpu_util_percent': 20.150000000000002, 'ram_util_percent': 6.0}}
Iteration 16/100
{'custom_metrics': {'default_policy/true_reward_mean': -47.02350779131339, 'default_policy/true_reward_min': -103.38318542494945, 'default_policy/true_reward_max': -3.0563961030679008, 'default_policy/proxy_reward_mean': -3.0435077913133295, 'default_policy/proxy_reward_min': -8.092119407771255, 'default_policy/proxy_reward_max': -2.2339087296525997, 'default_policy/modified_reward_mean': -4.531158357623709, 'default_policy/modified_reward_min': -9.424196599436643, 'default_policy/modified_reward_max': -3.494575397619266, 'default_policy/corr_btw_rewards_mean': 0.433494279780833, 'default_policy/corr_btw_rewards_min': 0.05262429493363519, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -47.02350779131339, 'true_reward_min': -103.38318542494945, 'true_reward_max': -3.0563961030679008, 'proxy_reward_mean': -3.0435077913133295, 'proxy_reward_min': -8.092119407771255, 'proxy_reward_max': -2.2339087296525997, 'modified_reward_mean': -4.531158357623709, 'modified_reward_min': -9.424196599436643, 'modified_reward_max': -3.494575397619266, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00024715025906735764, 'proxyInfectionSummaryAbsoluteReward_min': -0.002984455958549225, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.1214149114670116, 'proxyLowerStageReward_min': -0.14433472392641553, 'proxyLowerStageReward_max': -0.10445872490120588, 'proxySmoothStageChangesReward_mean': -0.1156476683937824, 'proxySmoothStageChangesReward_min': -0.19689119170984457, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00024715025906735764, 'trueInfectionSummaryAbsoluteReward_min': -0.002984455958549225, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.022787564766839376, 'truePoliticalReward_min': -0.0522279792746114, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.1214149114670116, 'trueLowerStageReward_min': -0.14433472392641553, 'trueLowerStageReward_max': -0.10445872490120588, 'trueSmoothStageChangesReward_mean': -0.1156476683937824, 'trueSmoothStageChangesReward_min': -0.19689119170984457, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -4.531158357623709, 'total_modified_reward_min': -9.424196599436643, 'total_modified_reward_max': -3.494575397619266}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.8668531311800083, 'cur_kl_coeff': 0.11250000000000003, 'cur_lr': 0.0003, 'total_loss': -0.05660023915969456, 'policy_loss': -0.012702498125533262, 'vf_loss': 0.00800055088242516, 'vf_explained_var': 0.9290256987015406, 'kl': 0.007410275421647867, 'entropy': 0.5440138345956802, 'entropy_coeff': 0.08957800000000003}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 4650.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 61760, 'num_env_steps_trained': 61760, 'num_agent_steps_sampled': 61760, 'num_agent_steps_trained': 61760}, 'sampler_results': {'episode_reward_max': -3.494575397619266, 'episode_reward_min': -9.424196599436643, 'episode_reward_mean': -4.531158357623709, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -47.02350779131339, 'default_policy/true_reward_min': -103.38318542494945, 'default_policy/true_reward_max': -3.0563961030679008, 'default_policy/proxy_reward_mean': -3.0435077913133295, 'default_policy/proxy_reward_min': -8.092119407771255, 'default_policy/proxy_reward_max': -2.2339087296525997, 'default_policy/modified_reward_mean': -4.531158357623709, 'default_policy/modified_reward_min': -9.424196599436643, 'default_policy/modified_reward_max': -3.494575397619266, 'default_policy/corr_btw_rewards_mean': 0.433494279780833, 'default_policy/corr_btw_rewards_min': 0.05262429493363519, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -47.02350779131339, 'true_reward_min': -103.38318542494945, 'true_reward_max': -3.0563961030679008, 'proxy_reward_mean': -3.0435077913133295, 'proxy_reward_min': -8.092119407771255, 'proxy_reward_max': -2.2339087296525997, 'modified_reward_mean': -4.531158357623709, 'modified_reward_min': -9.424196599436643, 'modified_reward_max': -3.494575397619266, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00024715025906735764, 'proxyInfectionSummaryAbsoluteReward_min': -0.002984455958549225, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.1214149114670116, 'proxyLowerStageReward_min': -0.14433472392641553, 'proxyLowerStageReward_max': -0.10445872490120588, 'proxySmoothStageChangesReward_mean': -0.1156476683937824, 'proxySmoothStageChangesReward_min': -0.19689119170984457, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00024715025906735764, 'trueInfectionSummaryAbsoluteReward_min': -0.002984455958549225, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.022787564766839376, 'truePoliticalReward_min': -0.0522279792746114, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.1214149114670116, 'trueLowerStageReward_min': -0.14433472392641553, 'trueLowerStageReward_max': -0.10445872490120588, 'trueSmoothStageChangesReward_mean': -0.1156476683937824, 'trueSmoothStageChangesReward_min': -0.19689119170984457, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -4.531158357623709, 'total_modified_reward_min': -9.424196599436643, 'total_modified_reward_max': -3.494575397619266}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5279067290855366, 'mean_inference_ms': 1.7015526829026237, 'mean_action_processing_ms': 0.10888902570092406, 'mean_env_wait_ms': 790.3789242174494, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -3.494575397619266, 'episode_reward_min': -9.424196599436643, 'episode_reward_mean': -4.531158357623709, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5279067290855366, 'mean_inference_ms': 1.7015526829026237, 'mean_action_processing_ms': 0.10888902570092406, 'mean_env_wait_ms': 790.3789242174494, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 61760, 'num_agent_steps_trained': 61760, 'num_env_steps_sampled': 61760, 'num_env_steps_trained': 61760, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.345641738308592, 'num_env_steps_trained_throughput_per_sec': 12.345641738308592, 'timesteps_total': 61760, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 61760, 'timers': {'training_iteration_time_ms': 318476.94, 'sample_time_ms': 317430.902, 'load_time_ms': 4.715, 'load_throughput': 818711.173, 'learn_time_ms': 1022.892, 'learn_throughput': 3773.614, 'synch_weights_time_ms': 17.542}, 'counters': {'num_env_steps_sampled': 61760, 'num_env_steps_trained': 61760, 'num_agent_steps_sampled': 61760, 'num_agent_steps_trained': 61760}, 'done': False, 'episodes_total': 320, 'training_iteration': 16, 'trial_id': 'default', 'date': '2025-11-04_20-18-05', 'timestamp': 1762316285, 'time_this_iter_s': 312.6813094615936, 'time_total_s': 5116.4507439136505, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e177ab90>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e0ffdba0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e177b940>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e177b340>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 5116.4507439136505, 'iterations_since_restore': 16, 'perf': {'cpu_util_percent': 20.295525727069357, 'ram_util_percent': 6.0}}
Iteration 17/100
{'custom_metrics': {'default_policy/true_reward_mean': -44.8640525785199, 'default_policy/true_reward_min': -103.38318542494945, 'default_policy/true_reward_max': -3.0563961030679008, 'default_policy/proxy_reward_mean': -2.9040525785198468, 'default_policy/proxy_reward_min': -8.092119407771255, 'default_policy/proxy_reward_max': -2.1164087296525986, 'default_policy/modified_reward_mean': -4.345839871481114, 'default_policy/modified_reward_min': -9.424196599436643, 'default_policy/modified_reward_max': -3.322880298916405, 'default_policy/corr_btw_rewards_mean': 0.43185516581610467, 'default_policy/corr_btw_rewards_min': 0.05262429493363519, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -44.8640525785199, 'true_reward_min': -103.38318542494945, 'true_reward_max': -3.0563961030679008, 'proxy_reward_mean': -2.9040525785198468, 'proxy_reward_min': -8.092119407771255, 'proxy_reward_max': -2.1164087296525986, 'modified_reward_mean': -4.345839871481114, 'modified_reward_min': -9.424196599436643, 'modified_reward_max': -3.322880298916405, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002121243523316063, 'proxyInfectionSummaryAbsoluteReward_min': -0.002984455958549225, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.11848977090776389, 'proxyLowerStageReward_min': -0.13722943717222053, 'proxyLowerStageReward_max': -0.10164580666901181, 'proxySmoothStageChangesReward_mean': -0.10766839378238342, 'proxySmoothStageChangesReward_min': -0.19689119170984457, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002121243523316063, 'trueInfectionSummaryAbsoluteReward_min': -0.002984455958549225, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.021740932642487044, 'truePoliticalReward_min': -0.0522279792746114, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.11848977090776389, 'trueLowerStageReward_min': -0.13722943717222053, 'trueLowerStageReward_max': -0.10164580666901181, 'trueSmoothStageChangesReward_mean': -0.10766839378238342, 'trueSmoothStageChangesReward_min': -0.19689119170984457, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -4.345839871481114, 'total_modified_reward_min': -9.424196599436643, 'total_modified_reward_max': -3.322880298916405}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.8222770564258098, 'cur_kl_coeff': 0.11250000000000003, 'cur_lr': 0.0003, 'total_loss': -0.053393323830484105, 'policy_loss': -0.01609807631932199, 'vf_loss': 0.00748236496806688, 'vf_explained_var': 0.9690105233589809, 'kl': 0.0078549380145392, 'entropy': 0.4716314419110616, 'entropy_coeff': 0.08888320000000002}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 4950.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 65620, 'num_env_steps_trained': 65620, 'num_agent_steps_sampled': 65620, 'num_agent_steps_trained': 65620}, 'sampler_results': {'episode_reward_max': -3.322880298916405, 'episode_reward_min': -9.424196599436643, 'episode_reward_mean': -4.345839871481114, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -44.8640525785199, 'default_policy/true_reward_min': -103.38318542494945, 'default_policy/true_reward_max': -3.0563961030679008, 'default_policy/proxy_reward_mean': -2.9040525785198468, 'default_policy/proxy_reward_min': -8.092119407771255, 'default_policy/proxy_reward_max': -2.1164087296525986, 'default_policy/modified_reward_mean': -4.345839871481114, 'default_policy/modified_reward_min': -9.424196599436643, 'default_policy/modified_reward_max': -3.322880298916405, 'default_policy/corr_btw_rewards_mean': 0.43185516581610467, 'default_policy/corr_btw_rewards_min': 0.05262429493363519, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -44.8640525785199, 'true_reward_min': -103.38318542494945, 'true_reward_max': -3.0563961030679008, 'proxy_reward_mean': -2.9040525785198468, 'proxy_reward_min': -8.092119407771255, 'proxy_reward_max': -2.1164087296525986, 'modified_reward_mean': -4.345839871481114, 'modified_reward_min': -9.424196599436643, 'modified_reward_max': -3.322880298916405, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002121243523316063, 'proxyInfectionSummaryAbsoluteReward_min': -0.002984455958549225, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.11848977090776389, 'proxyLowerStageReward_min': -0.13722943717222053, 'proxyLowerStageReward_max': -0.10164580666901181, 'proxySmoothStageChangesReward_mean': -0.10766839378238342, 'proxySmoothStageChangesReward_min': -0.19689119170984457, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002121243523316063, 'trueInfectionSummaryAbsoluteReward_min': -0.002984455958549225, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.021740932642487044, 'truePoliticalReward_min': -0.0522279792746114, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.11848977090776389, 'trueLowerStageReward_min': -0.13722943717222053, 'trueLowerStageReward_max': -0.10164580666901181, 'trueSmoothStageChangesReward_mean': -0.10766839378238342, 'trueSmoothStageChangesReward_min': -0.19689119170984457, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -4.345839871481114, 'total_modified_reward_min': -9.424196599436643, 'total_modified_reward_max': -3.322880298916405}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5279108771314803, 'mean_inference_ms': 1.6997571237953009, 'mean_action_processing_ms': 0.10875839708522307, 'mean_env_wait_ms': 789.8844251128271, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -3.322880298916405, 'episode_reward_min': -9.424196599436643, 'episode_reward_mean': -4.345839871481114, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5279108771314803, 'mean_inference_ms': 1.6997571237953009, 'mean_action_processing_ms': 0.10875839708522307, 'mean_env_wait_ms': 789.8844251128271, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 65620, 'num_agent_steps_trained': 65620, 'num_env_steps_sampled': 65620, 'num_env_steps_trained': 65620, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.376178909563562, 'num_env_steps_trained_throughput_per_sec': 12.376178909563562, 'timesteps_total': 65620, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 65620, 'timers': {'training_iteration_time_ms': 317973.585, 'sample_time_ms': 316927.335, 'load_time_ms': 5.34, 'load_throughput': 722800.725, 'learn_time_ms': 1022.995, 'learn_throughput': 3773.235, 'synch_weights_time_ms': 17.035}, 'counters': {'num_env_steps_sampled': 65620, 'num_env_steps_trained': 65620, 'num_agent_steps_sampled': 65620, 'num_agent_steps_trained': 65620}, 'done': False, 'episodes_total': 340, 'training_iteration': 17, 'trial_id': 'default', 'date': '2025-11-04_20-23-18', 'timestamp': 1762316598, 'time_this_iter_s': 311.90805220603943, 'time_total_s': 5428.35879611969, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e2633f70>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e26318a0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699560880>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6995623b0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 5428.35879611969, 'iterations_since_restore': 17, 'perf': {'cpu_util_percent': 20.035135135135135, 'ram_util_percent': 6.0}}
Iteration 18/100
{'custom_metrics': {'default_policy/true_reward_mean': -38.530126171648696, 'default_policy/true_reward_min': -103.38318542494945, 'default_policy/true_reward_max': -3.0563961030679008, 'default_policy/proxy_reward_mean': -2.822126171648654, 'default_policy/proxy_reward_min': -8.092119407771255, 'default_policy/proxy_reward_max': -2.1164087296525986, 'default_policy/modified_reward_mean': -4.204494519164691, 'default_policy/modified_reward_min': -9.424196599436643, 'default_policy/modified_reward_max': -3.322880298916405, 'default_policy/corr_btw_rewards_mean': 0.4196380048265847, 'default_policy/corr_btw_rewards_min': 0.05262429493363519, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -38.530126171648696, 'true_reward_min': -103.38318542494945, 'true_reward_max': -3.0563961030679008, 'proxy_reward_mean': -2.822126171648654, 'proxy_reward_min': -8.092119407771255, 'proxy_reward_max': -2.1164087296525986, 'modified_reward_mean': -4.204494519164691, 'modified_reward_min': -9.424196599436643, 'modified_reward_max': -3.322880298916405, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00021917098445595868, 'proxyInfectionSummaryAbsoluteReward_min': -0.002984455958549225, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.11442622651029274, 'proxyLowerStageReward_min': -0.13656270320102695, 'proxyLowerStageReward_max': -0.09637240276763169, 'proxySmoothStageChangesReward_mean': -0.09880829015544045, 'proxySmoothStageChangesReward_min': -0.19689119170984457, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00021917098445595868, 'trueInfectionSummaryAbsoluteReward_min': -0.002984455958549225, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.01850155440414508, 'truePoliticalReward_min': -0.0522279792746114, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.11442622651029274, 'trueLowerStageReward_min': -0.13656270320102695, 'trueLowerStageReward_max': -0.09637240276763169, 'trueSmoothStageChangesReward_mean': -0.09880829015544045, 'trueSmoothStageChangesReward_min': -0.19689119170984457, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -4.204494519164691, 'total_modified_reward_min': -9.424196599436643, 'total_modified_reward_max': -3.322880298916405}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0592358663181465, 'cur_kl_coeff': 0.11250000000000003, 'cur_lr': 0.0003, 'total_loss': -0.03655354836412395, 'policy_loss': -0.007461193435980628, 'vf_loss': 0.020697468728855407, 'vf_explained_var': 0.88449347615242, 'kl': 0.00322511922102087, 'entropy': 0.45135089665651323, 'entropy_coeff': 0.08818839999999999}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 5250.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 69480, 'num_env_steps_trained': 69480, 'num_agent_steps_sampled': 69480, 'num_agent_steps_trained': 69480}, 'sampler_results': {'episode_reward_max': -3.322880298916405, 'episode_reward_min': -9.424196599436643, 'episode_reward_mean': -4.204494519164691, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -38.530126171648696, 'default_policy/true_reward_min': -103.38318542494945, 'default_policy/true_reward_max': -3.0563961030679008, 'default_policy/proxy_reward_mean': -2.822126171648654, 'default_policy/proxy_reward_min': -8.092119407771255, 'default_policy/proxy_reward_max': -2.1164087296525986, 'default_policy/modified_reward_mean': -4.204494519164691, 'default_policy/modified_reward_min': -9.424196599436643, 'default_policy/modified_reward_max': -3.322880298916405, 'default_policy/corr_btw_rewards_mean': 0.4196380048265847, 'default_policy/corr_btw_rewards_min': 0.05262429493363519, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -38.530126171648696, 'true_reward_min': -103.38318542494945, 'true_reward_max': -3.0563961030679008, 'proxy_reward_mean': -2.822126171648654, 'proxy_reward_min': -8.092119407771255, 'proxy_reward_max': -2.1164087296525986, 'modified_reward_mean': -4.204494519164691, 'modified_reward_min': -9.424196599436643, 'modified_reward_max': -3.322880298916405, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00021917098445595868, 'proxyInfectionSummaryAbsoluteReward_min': -0.002984455958549225, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.11442622651029274, 'proxyLowerStageReward_min': -0.13656270320102695, 'proxyLowerStageReward_max': -0.09637240276763169, 'proxySmoothStageChangesReward_mean': -0.09880829015544045, 'proxySmoothStageChangesReward_min': -0.19689119170984457, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00021917098445595868, 'trueInfectionSummaryAbsoluteReward_min': -0.002984455958549225, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.01850155440414508, 'truePoliticalReward_min': -0.0522279792746114, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.11442622651029274, 'trueLowerStageReward_min': -0.13656270320102695, 'trueLowerStageReward_max': -0.09637240276763169, 'trueSmoothStageChangesReward_mean': -0.09880829015544045, 'trueSmoothStageChangesReward_min': -0.19689119170984457, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -4.204494519164691, 'total_modified_reward_min': -9.424196599436643, 'total_modified_reward_max': -3.322880298916405}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5293511702464865, 'mean_inference_ms': 1.698149737444648, 'mean_action_processing_ms': 0.1086449421094052, 'mean_env_wait_ms': 789.5900408887359, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -3.322880298916405, 'episode_reward_min': -9.424196599436643, 'episode_reward_mean': -4.204494519164691, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5293511702464865, 'mean_inference_ms': 1.698149737444648, 'mean_action_processing_ms': 0.1086449421094052, 'mean_env_wait_ms': 789.5900408887359, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 69480, 'num_agent_steps_trained': 69480, 'num_env_steps_sampled': 69480, 'num_env_steps_trained': 69480, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.437258540265221, 'num_env_steps_trained_throughput_per_sec': 12.437258540265221, 'timesteps_total': 69480, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 69480, 'timers': {'training_iteration_time_ms': 317130.384, 'sample_time_ms': 316087.927, 'load_time_ms': 5.658, 'load_throughput': 682239.186, 'learn_time_ms': 1018.336, 'learn_throughput': 3790.499, 'synch_weights_time_ms': 17.577}, 'counters': {'num_env_steps_sampled': 69480, 'num_env_steps_trained': 69480, 'num_agent_steps_sampled': 69480, 'num_agent_steps_trained': 69480}, 'done': False, 'episodes_total': 360, 'training_iteration': 18, 'trial_id': 'default', 'date': '2025-11-04_20-28-28', 'timestamp': 1762316908, 'time_this_iter_s': 310.3867390155792, 'time_total_s': 5738.745535135269, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6a9cdb8e0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6a92067d0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2510100>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2510040>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 5738.745535135269, 'iterations_since_restore': 18, 'perf': {'cpu_util_percent': 20.347855530474042, 'ram_util_percent': 6.0}}
Iteration 19/100
{'custom_metrics': {'default_policy/true_reward_mean': -33.06860229009441, 'default_policy/true_reward_min': -103.38318542494945, 'default_policy/true_reward_max': -2.4717766952966387, 'default_policy/proxy_reward_mean': -2.708602290094402, 'default_policy/proxy_reward_min': -4.897830085889906, 'default_policy/proxy_reward_max': -2.0131980515339425, 'default_policy/modified_reward_mean': -4.023628844419381, 'default_policy/modified_reward_min': -6.294572792281034, 'default_policy/modified_reward_max': -3.160809007369156, 'default_policy/corr_btw_rewards_mean': 0.4036141165168914, 'default_policy/corr_btw_rewards_min': 0.1012959625897605, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -33.06860229009441, 'true_reward_min': -103.38318542494945, 'true_reward_max': -2.4717766952966387, 'proxy_reward_mean': -2.708602290094402, 'proxy_reward_min': -4.897830085889906, 'proxy_reward_max': -2.0131980515339425, 'modified_reward_mean': -4.023628844419381, 'modified_reward_min': -6.294572792281034, 'modified_reward_max': -3.160809007369156, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00021740932642487056, 'proxyInfectionSummaryAbsoluteReward_min': -0.0012849740932642491, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.1096115176214715, 'proxyLowerStageReward_min': -0.1316226662852436, 'proxyLowerStageReward_max': -0.09248639240493739, 'proxySmoothStageChangesReward_mean': -0.08989637305699484, 'proxySmoothStageChangesReward_min': -0.16580310880829016, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00021740932642487056, 'trueInfectionSummaryAbsoluteReward_min': -0.0012849740932642491, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.01573056994818653, 'truePoliticalReward_min': -0.0522279792746114, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.1096115176214715, 'trueLowerStageReward_min': -0.1316226662852436, 'trueLowerStageReward_max': -0.09248639240493739, 'trueSmoothStageChangesReward_mean': -0.08989637305699484, 'trueSmoothStageChangesReward_min': -0.16580310880829016, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -4.023628844419381, 'total_modified_reward_min': -6.294572792281034, 'total_modified_reward_max': -3.160809007369156}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0875614803284406, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.030082186388317497, 'policy_loss': -0.0038249732445304594, 'vf_loss': 0.026519543806401393, 'vf_explained_var': 0.8534849522511164, 'kl': 0.0050471256882796064, 'entropy': 0.45490050862232845, 'entropy_coeff': 0.0874936}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 5550.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 73340, 'num_env_steps_trained': 73340, 'num_agent_steps_sampled': 73340, 'num_agent_steps_trained': 73340}, 'sampler_results': {'episode_reward_max': -3.160809007369156, 'episode_reward_min': -6.294572792281034, 'episode_reward_mean': -4.023628844419381, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -33.06860229009441, 'default_policy/true_reward_min': -103.38318542494945, 'default_policy/true_reward_max': -2.4717766952966387, 'default_policy/proxy_reward_mean': -2.708602290094402, 'default_policy/proxy_reward_min': -4.897830085889906, 'default_policy/proxy_reward_max': -2.0131980515339425, 'default_policy/modified_reward_mean': -4.023628844419381, 'default_policy/modified_reward_min': -6.294572792281034, 'default_policy/modified_reward_max': -3.160809007369156, 'default_policy/corr_btw_rewards_mean': 0.4036141165168914, 'default_policy/corr_btw_rewards_min': 0.1012959625897605, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -33.06860229009441, 'true_reward_min': -103.38318542494945, 'true_reward_max': -2.4717766952966387, 'proxy_reward_mean': -2.708602290094402, 'proxy_reward_min': -4.897830085889906, 'proxy_reward_max': -2.0131980515339425, 'modified_reward_mean': -4.023628844419381, 'modified_reward_min': -6.294572792281034, 'modified_reward_max': -3.160809007369156, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00021740932642487056, 'proxyInfectionSummaryAbsoluteReward_min': -0.0012849740932642491, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.1096115176214715, 'proxyLowerStageReward_min': -0.1316226662852436, 'proxyLowerStageReward_max': -0.09248639240493739, 'proxySmoothStageChangesReward_mean': -0.08989637305699484, 'proxySmoothStageChangesReward_min': -0.16580310880829016, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00021740932642487056, 'trueInfectionSummaryAbsoluteReward_min': -0.0012849740932642491, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.01573056994818653, 'truePoliticalReward_min': -0.0522279792746114, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.1096115176214715, 'trueLowerStageReward_min': -0.1316226662852436, 'trueLowerStageReward_max': -0.09248639240493739, 'trueSmoothStageChangesReward_mean': -0.08989637305699484, 'trueSmoothStageChangesReward_min': -0.16580310880829016, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -4.023628844419381, 'total_modified_reward_min': -6.294572792281034, 'total_modified_reward_max': -3.160809007369156}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5310862288685964, 'mean_inference_ms': 1.6967088844406066, 'mean_action_processing_ms': 0.10856775800323604, 'mean_env_wait_ms': 789.27219122625, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -3.160809007369156, 'episode_reward_min': -6.294572792281034, 'episode_reward_mean': -4.023628844419381, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5310862288685964, 'mean_inference_ms': 1.6967088844406066, 'mean_action_processing_ms': 0.10856775800323604, 'mean_env_wait_ms': 789.27219122625, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 73340, 'num_agent_steps_trained': 73340, 'num_env_steps_sampled': 73340, 'num_env_steps_trained': 73340, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.203422897935882, 'num_env_steps_trained_throughput_per_sec': 12.203422897935882, 'timesteps_total': 73340, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 73340, 'timers': {'training_iteration_time_ms': 312015.232, 'sample_time_ms': 310995.637, 'load_time_ms': 5.658, 'load_throughput': 682259.311, 'learn_time_ms': 995.913, 'learn_throughput': 3875.842, 'synch_weights_time_ms': 17.131}, 'counters': {'num_env_steps_sampled': 73340, 'num_env_steps_trained': 73340, 'num_agent_steps_sampled': 73340, 'num_agent_steps_trained': 73340}, 'done': False, 'episodes_total': 380, 'training_iteration': 19, 'trial_id': 'default', 'date': '2025-11-04_20-33-45', 'timestamp': 1762317225, 'time_this_iter_s': 316.3219745159149, 'time_total_s': 6055.067509651184, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e2513460>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e2510070>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2511120>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2512fb0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 6055.067509651184, 'iterations_since_restore': 19, 'perf': {'cpu_util_percent': 19.959111111111117, 'ram_util_percent': 6.0}}
Iteration 20/100
{'custom_metrics': {'default_policy/true_reward_mean': -28.075970796695565, 'default_policy/true_reward_min': -103.38318542494945, 'default_policy/true_reward_max': -2.087132034355961, 'default_policy/proxy_reward_mean': -2.6279707966955757, 'default_policy/proxy_reward_min': -4.897830085889906, 'default_policy/proxy_reward_max': -1.937487373415287, 'default_policy/modified_reward_mean': -3.8789043795892524, 'default_policy/modified_reward_min': -6.294572792281034, 'default_policy/modified_reward_max': -3.0074128504167157, 'default_policy/corr_btw_rewards_mean': 0.40045926014266287, 'default_policy/corr_btw_rewards_min': 0.1012959625897605, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -28.075970796695565, 'true_reward_min': -103.38318542494945, 'true_reward_max': -2.087132034355961, 'proxy_reward_mean': -2.6279707966955757, 'proxy_reward_min': -4.897830085889906, 'proxy_reward_max': -1.937487373415287, 'modified_reward_mean': -3.8789043795892524, 'modified_reward_min': -6.294572792281034, 'modified_reward_max': -3.0074128504167157, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00022797927461139906, 'proxyInfectionSummaryAbsoluteReward_min': -0.0012849740932642491, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.10545444542464111, 'proxyLowerStageReward_min': -0.1316226662852436, 'proxyLowerStageReward_max': -0.0870828005976138, 'proxySmoothStageChangesReward_mean': -0.07911917098445598, 'proxySmoothStageChangesReward_min': -0.15544041450777202, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00022797927461139906, 'trueInfectionSummaryAbsoluteReward_min': -0.0012849740932642491, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.013185492227979273, 'truePoliticalReward_min': -0.0522279792746114, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.10545444542464111, 'trueLowerStageReward_min': -0.1316226662852436, 'trueLowerStageReward_max': -0.0870828005976138, 'trueSmoothStageChangesReward_mean': -0.07911917098445598, 'trueSmoothStageChangesReward_min': -0.15544041450777202, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.8789043795892524, 'total_modified_reward_min': -6.294572792281034, 'total_modified_reward_max': -3.0074128504167157}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9605717005332312, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.035589844640344384, 'policy_loss': -0.005864350354919831, 'vf_loss': 0.013902012792823371, 'vf_explained_var': 0.9068762065966924, 'kl': 0.005027941700265067, 'entropy': 0.4258045381307602, 'entropy_coeff': 0.08679880000000001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 5850.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 77200, 'num_env_steps_trained': 77200, 'num_agent_steps_sampled': 77200, 'num_agent_steps_trained': 77200}, 'sampler_results': {'episode_reward_max': -3.0074128504167157, 'episode_reward_min': -6.294572792281034, 'episode_reward_mean': -3.8789043795892524, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -28.075970796695565, 'default_policy/true_reward_min': -103.38318542494945, 'default_policy/true_reward_max': -2.087132034355961, 'default_policy/proxy_reward_mean': -2.6279707966955757, 'default_policy/proxy_reward_min': -4.897830085889906, 'default_policy/proxy_reward_max': -1.937487373415287, 'default_policy/modified_reward_mean': -3.8789043795892524, 'default_policy/modified_reward_min': -6.294572792281034, 'default_policy/modified_reward_max': -3.0074128504167157, 'default_policy/corr_btw_rewards_mean': 0.40045926014266287, 'default_policy/corr_btw_rewards_min': 0.1012959625897605, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -28.075970796695565, 'true_reward_min': -103.38318542494945, 'true_reward_max': -2.087132034355961, 'proxy_reward_mean': -2.6279707966955757, 'proxy_reward_min': -4.897830085889906, 'proxy_reward_max': -1.937487373415287, 'modified_reward_mean': -3.8789043795892524, 'modified_reward_min': -6.294572792281034, 'modified_reward_max': -3.0074128504167157, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00022797927461139906, 'proxyInfectionSummaryAbsoluteReward_min': -0.0012849740932642491, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.10545444542464111, 'proxyLowerStageReward_min': -0.1316226662852436, 'proxyLowerStageReward_max': -0.0870828005976138, 'proxySmoothStageChangesReward_mean': -0.07911917098445598, 'proxySmoothStageChangesReward_min': -0.15544041450777202, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00022797927461139906, 'trueInfectionSummaryAbsoluteReward_min': -0.0012849740932642491, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.013185492227979273, 'truePoliticalReward_min': -0.0522279792746114, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.10545444542464111, 'trueLowerStageReward_min': -0.1316226662852436, 'trueLowerStageReward_max': -0.0870828005976138, 'trueSmoothStageChangesReward_mean': -0.07911917098445598, 'trueSmoothStageChangesReward_min': -0.15544041450777202, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.8789043795892524, 'total_modified_reward_min': -6.294572792281034, 'total_modified_reward_max': -3.0074128504167157}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5328504167871037, 'mean_inference_ms': 1.6956022496884742, 'mean_action_processing_ms': 0.108471997994716, 'mean_env_wait_ms': 789.028456013228, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -3.0074128504167157, 'episode_reward_min': -6.294572792281034, 'episode_reward_mean': -3.8789043795892524, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5328504167871037, 'mean_inference_ms': 1.6956022496884742, 'mean_action_processing_ms': 0.108471997994716, 'mean_env_wait_ms': 789.028456013228, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 77200, 'num_agent_steps_trained': 77200, 'num_env_steps_sampled': 77200, 'num_env_steps_trained': 77200, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.303077872266748, 'num_env_steps_trained_throughput_per_sec': 12.303077872266748, 'timesteps_total': 77200, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 77200, 'timers': {'training_iteration_time_ms': 311541.397, 'sample_time_ms': 310519.409, 'load_time_ms': 5.596, 'load_throughput': 689761.521, 'learn_time_ms': 998.346, 'learn_throughput': 3866.396, 'synch_weights_time_ms': 17.129}, 'counters': {'num_env_steps_sampled': 77200, 'num_env_steps_trained': 77200, 'num_agent_steps_sampled': 77200, 'num_agent_steps_trained': 77200}, 'done': False, 'episodes_total': 400, 'training_iteration': 20, 'trial_id': 'default', 'date': '2025-11-04_20-38-59', 'timestamp': 1762317539, 'time_this_iter_s': 313.7656280994415, 'time_total_s': 6368.833137750626, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e2510c40>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e2511000>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2513580>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2512a70>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 6368.833137750626, 'iterations_since_restore': 20, 'perf': {'cpu_util_percent': 20.221205357142857, 'ram_util_percent': 6.0}}
Saved checkpoint to TrainingResult(checkpoint=Checkpoint(filesystem=local, path=logs/data/pandemic/20251104_185246/checkpoint_20), metrics={'custom_metrics': {'default_policy/true_reward_mean': -28.075970796695565, 'default_policy/true_reward_min': -103.38318542494945, 'default_policy/true_reward_max': -2.087132034355961, 'default_policy/proxy_reward_mean': -2.6279707966955757, 'default_policy/proxy_reward_min': -4.897830085889906, 'default_policy/proxy_reward_max': -1.937487373415287, 'default_policy/modified_reward_mean': -3.8789043795892524, 'default_policy/modified_reward_min': -6.294572792281034, 'default_policy/modified_reward_max': -3.0074128504167157, 'default_policy/corr_btw_rewards_mean': 0.40045926014266287, 'default_policy/corr_btw_rewards_min': 0.1012959625897605, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -28.075970796695565, 'true_reward_min': -103.38318542494945, 'true_reward_max': -2.087132034355961, 'proxy_reward_mean': -2.6279707966955757, 'proxy_reward_min': -4.897830085889906, 'proxy_reward_max': -1.937487373415287, 'modified_reward_mean': -3.8789043795892524, 'modified_reward_min': -6.294572792281034, 'modified_reward_max': -3.0074128504167157, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00022797927461139906, 'proxyInfectionSummaryAbsoluteReward_min': -0.0012849740932642491, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.10545444542464111, 'proxyLowerStageReward_min': -0.1316226662852436, 'proxyLowerStageReward_max': -0.0870828005976138, 'proxySmoothStageChangesReward_mean': -0.07911917098445598, 'proxySmoothStageChangesReward_min': -0.15544041450777202, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00022797927461139906, 'trueInfectionSummaryAbsoluteReward_min': -0.0012849740932642491, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.013185492227979273, 'truePoliticalReward_min': -0.0522279792746114, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.10545444542464111, 'trueLowerStageReward_min': -0.1316226662852436, 'trueLowerStageReward_max': -0.0870828005976138, 'trueSmoothStageChangesReward_mean': -0.07911917098445598, 'trueSmoothStageChangesReward_min': -0.15544041450777202, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.8789043795892524, 'total_modified_reward_min': -6.294572792281034, 'total_modified_reward_max': -3.0074128504167157}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9605717005332312, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.035589844640344384, 'policy_loss': -0.005864350354919831, 'vf_loss': 0.013902012792823371, 'vf_explained_var': 0.9068762065966924, 'kl': 0.005027941700265067, 'entropy': 0.4258045381307602, 'entropy_coeff': 0.08679880000000001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 5850.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 77200, 'num_env_steps_trained': 77200, 'num_agent_steps_sampled': 77200, 'num_agent_steps_trained': 77200}, 'sampler_results': {'episode_reward_max': -3.0074128504167157, 'episode_reward_min': -6.294572792281034, 'episode_reward_mean': -3.8789043795892524, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -28.075970796695565, 'default_policy/true_reward_min': -103.38318542494945, 'default_policy/true_reward_max': -2.087132034355961, 'default_policy/proxy_reward_mean': -2.6279707966955757, 'default_policy/proxy_reward_min': -4.897830085889906, 'default_policy/proxy_reward_max': -1.937487373415287, 'default_policy/modified_reward_mean': -3.8789043795892524, 'default_policy/modified_reward_min': -6.294572792281034, 'default_policy/modified_reward_max': -3.0074128504167157, 'default_policy/corr_btw_rewards_mean': 0.40045926014266287, 'default_policy/corr_btw_rewards_min': 0.1012959625897605, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -28.075970796695565, 'true_reward_min': -103.38318542494945, 'true_reward_max': -2.087132034355961, 'proxy_reward_mean': -2.6279707966955757, 'proxy_reward_min': -4.897830085889906, 'proxy_reward_max': -1.937487373415287, 'modified_reward_mean': -3.8789043795892524, 'modified_reward_min': -6.294572792281034, 'modified_reward_max': -3.0074128504167157, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00022797927461139906, 'proxyInfectionSummaryAbsoluteReward_min': -0.0012849740932642491, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.10545444542464111, 'proxyLowerStageReward_min': -0.1316226662852436, 'proxyLowerStageReward_max': -0.0870828005976138, 'proxySmoothStageChangesReward_mean': -0.07911917098445598, 'proxySmoothStageChangesReward_min': -0.15544041450777202, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00022797927461139906, 'trueInfectionSummaryAbsoluteReward_min': -0.0012849740932642491, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.013185492227979273, 'truePoliticalReward_min': -0.0522279792746114, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.10545444542464111, 'trueLowerStageReward_min': -0.1316226662852436, 'trueLowerStageReward_max': -0.0870828005976138, 'trueSmoothStageChangesReward_mean': -0.07911917098445598, 'trueSmoothStageChangesReward_min': -0.15544041450777202, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.8789043795892524, 'total_modified_reward_min': -6.294572792281034, 'total_modified_reward_max': -3.0074128504167157}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5328504167871037, 'mean_inference_ms': 1.6956022496884742, 'mean_action_processing_ms': 0.108471997994716, 'mean_env_wait_ms': 789.028456013228, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -3.0074128504167157, 'episode_reward_min': -6.294572792281034, 'episode_reward_mean': -3.8789043795892524, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5328504167871037, 'mean_inference_ms': 1.6956022496884742, 'mean_action_processing_ms': 0.108471997994716, 'mean_env_wait_ms': 789.028456013228, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 77200, 'num_agent_steps_trained': 77200, 'num_env_steps_sampled': 77200, 'num_env_steps_trained': 77200, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.303077872266748, 'num_env_steps_trained_throughput_per_sec': 12.303077872266748, 'timesteps_total': 77200, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 77200, 'timers': {'training_iteration_time_ms': 311541.397, 'sample_time_ms': 310519.409, 'load_time_ms': 5.596, 'load_throughput': 689761.521, 'learn_time_ms': 998.346, 'learn_throughput': 3866.396, 'synch_weights_time_ms': 17.129}, 'counters': {'num_env_steps_sampled': 77200, 'num_env_steps_trained': 77200, 'num_agent_steps_sampled': 77200, 'num_agent_steps_trained': 77200}, 'done': False, 'episodes_total': 400, 'training_iteration': 20, 'trial_id': 'default', 'date': '2025-11-04_20-38-59', 'timestamp': 1762317539, 'time_this_iter_s': 313.7656280994415, 'time_total_s': 6368.833137750626, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e2510c40>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e2511000>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2513580>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2512a70>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 6368.833137750626, 'iterations_since_restore': 20, 'perf': {'cpu_util_percent': 20.221205357142857, 'ram_util_percent': 6.0}})
Iteration 21/100
{'custom_metrics': {'default_policy/true_reward_mean': -22.688137788106566, 'default_policy/true_reward_min': -67.13996212024598, 'default_policy/true_reward_max': -2.0417766952966327, 'default_policy/proxy_reward_mean': -2.5761377881065837, 'default_policy/proxy_reward_min': -4.897830085889906, 'default_policy/proxy_reward_max': -1.8799873734152874, 'default_policy/modified_reward_mean': -3.770541908575378, 'default_policy/modified_reward_min': -6.294572792281034, 'default_policy/modified_reward_max': -2.9496778234977534, 'default_policy/corr_btw_rewards_mean': 0.38585059239658775, 'default_policy/corr_btw_rewards_min': 0.1012959625897605, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -22.688137788106566, 'true_reward_min': -67.13996212024598, 'true_reward_max': -2.0417766952966327, 'proxy_reward_mean': -2.5761377881065837, 'proxy_reward_min': -4.897830085889906, 'proxy_reward_max': -1.8799873734152874, 'modified_reward_mean': -3.770541908575378, 'modified_reward_min': -6.294572792281034, 'modified_reward_max': -2.9496778234977534, 'proxyInfectionSummaryAbsoluteReward_mean': -0.000247357512953368, 'proxyInfectionSummaryAbsoluteReward_min': -0.0012849740932642491, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.10177397865837216, 'proxyLowerStageReward_min': -0.11739302719944236, 'proxyLowerStageReward_max': -0.0870828005976138, 'proxySmoothStageChangesReward_mean': -0.06968911917098447, 'proxySmoothStageChangesReward_min': -0.13471502590673576, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.000247357512953368, 'trueInfectionSummaryAbsoluteReward_min': -0.0012849740932642491, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010420725388601036, 'truePoliticalReward_min': -0.03316062176165803, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.10177397865837216, 'trueLowerStageReward_min': -0.11739302719944236, 'trueLowerStageReward_max': -0.0870828005976138, 'trueSmoothStageChangesReward_mean': -0.06968911917098447, 'trueSmoothStageChangesReward_min': -0.13471502590673576, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.770541908575378, 'total_modified_reward_min': -6.294572792281034, 'total_modified_reward_max': -2.9496778234977534}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.8349876310427984, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.041038037508357474, 'policy_loss': -0.01373151248941819, 'vf_loss': 0.013864147969482777, 'vf_explained_var': 0.8502977993090948, 'kl': 0.0059072258058009645, 'entropy': 0.4015014511346817, 'entropy_coeff': 0.08610399999999999}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 6150.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 81060, 'num_env_steps_trained': 81060, 'num_agent_steps_sampled': 81060, 'num_agent_steps_trained': 81060}, 'sampler_results': {'episode_reward_max': -2.9496778234977534, 'episode_reward_min': -6.294572792281034, 'episode_reward_mean': -3.770541908575378, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -22.688137788106566, 'default_policy/true_reward_min': -67.13996212024598, 'default_policy/true_reward_max': -2.0417766952966327, 'default_policy/proxy_reward_mean': -2.5761377881065837, 'default_policy/proxy_reward_min': -4.897830085889906, 'default_policy/proxy_reward_max': -1.8799873734152874, 'default_policy/modified_reward_mean': -3.770541908575378, 'default_policy/modified_reward_min': -6.294572792281034, 'default_policy/modified_reward_max': -2.9496778234977534, 'default_policy/corr_btw_rewards_mean': 0.38585059239658775, 'default_policy/corr_btw_rewards_min': 0.1012959625897605, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -22.688137788106566, 'true_reward_min': -67.13996212024598, 'true_reward_max': -2.0417766952966327, 'proxy_reward_mean': -2.5761377881065837, 'proxy_reward_min': -4.897830085889906, 'proxy_reward_max': -1.8799873734152874, 'modified_reward_mean': -3.770541908575378, 'modified_reward_min': -6.294572792281034, 'modified_reward_max': -2.9496778234977534, 'proxyInfectionSummaryAbsoluteReward_mean': -0.000247357512953368, 'proxyInfectionSummaryAbsoluteReward_min': -0.0012849740932642491, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.10177397865837216, 'proxyLowerStageReward_min': -0.11739302719944236, 'proxyLowerStageReward_max': -0.0870828005976138, 'proxySmoothStageChangesReward_mean': -0.06968911917098447, 'proxySmoothStageChangesReward_min': -0.13471502590673576, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.000247357512953368, 'trueInfectionSummaryAbsoluteReward_min': -0.0012849740932642491, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010420725388601036, 'truePoliticalReward_min': -0.03316062176165803, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.10177397865837216, 'trueLowerStageReward_min': -0.11739302719944236, 'trueLowerStageReward_max': -0.0870828005976138, 'trueSmoothStageChangesReward_mean': -0.06968911917098447, 'trueSmoothStageChangesReward_min': -0.13471502590673576, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.770541908575378, 'total_modified_reward_min': -6.294572792281034, 'total_modified_reward_max': -2.9496778234977534}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5342375978633455, 'mean_inference_ms': 1.6944138399944242, 'mean_action_processing_ms': 0.10836996737970236, 'mean_env_wait_ms': 788.7774835674026, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.9496778234977534, 'episode_reward_min': -6.294572792281034, 'episode_reward_mean': -3.770541908575378, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5342375978633455, 'mean_inference_ms': 1.6944138399944242, 'mean_action_processing_ms': 0.10836996737970236, 'mean_env_wait_ms': 788.7774835674026, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 81060, 'num_agent_steps_trained': 81060, 'num_env_steps_sampled': 81060, 'num_env_steps_trained': 81060, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.37270807819118, 'num_env_steps_trained_throughput_per_sec': 12.37270807819118, 'timesteps_total': 81060, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 81060, 'timers': {'training_iteration_time_ms': 311923.661, 'sample_time_ms': 310917.488, 'load_time_ms': 5.719, 'load_throughput': 674963.56, 'learn_time_ms': 982.538, 'learn_throughput': 3928.6, 'synch_weights_time_ms': 16.983}, 'counters': {'num_env_steps_sampled': 81060, 'num_env_steps_trained': 81060, 'num_agent_steps_sampled': 81060, 'num_agent_steps_trained': 81060}, 'done': False, 'episodes_total': 420, 'training_iteration': 21, 'trial_id': 'default', 'date': '2025-11-04_20-44-11', 'timestamp': 1762317851, 'time_this_iter_s': 311.99385261535645, 'time_total_s': 6680.826990365982, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6882fe560>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6882fcb20>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6882febc0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6882fcaf0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 6680.826990365982, 'iterations_since_restore': 21, 'perf': {'cpu_util_percent': 20.292792792792792, 'ram_util_percent': 6.0}}
Iteration 22/100
{'custom_metrics': {'default_policy/true_reward_mean': -21.309621788875457, 'default_policy/true_reward_min': -62.41319805153398, 'default_policy/true_reward_max': -1.960342712474615, 'default_policy/proxy_reward_mean': -2.5416217888754753, 'default_policy/proxy_reward_min': -5.314264068711926, 'default_policy/proxy_reward_max': -1.8635533905932702, 'default_policy/modified_reward_mean': -3.6999743945848036, 'default_policy/modified_reward_min': -6.553538449176523, 'default_policy/modified_reward_max': -2.9316608391630603, 'default_policy/corr_btw_rewards_mean': 0.4187975645322237, 'default_policy/corr_btw_rewards_min': 0.08900477399628184, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -21.309621788875457, 'true_reward_min': -62.41319805153398, 'true_reward_max': -1.960342712474615, 'proxy_reward_mean': -2.5416217888754753, 'proxy_reward_min': -5.314264068711926, 'proxy_reward_max': -1.8635533905932702, 'modified_reward_mean': -3.6999743945848036, 'modified_reward_min': -6.553538449176523, 'modified_reward_max': -2.9316608391630603, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00026196891191709854, 'proxyInfectionSummaryAbsoluteReward_min': -0.0016165803108808296, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0987731496826671, 'proxyLowerStageReward_min': -0.11567226667515973, 'proxyLowerStageReward_max': -0.08654625453236368, 'proxySmoothStageChangesReward_mean': -0.06720207253886011, 'proxySmoothStageChangesReward_min': -0.12435233160621761, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00026196891191709854, 'trueInfectionSummaryAbsoluteReward_min': -0.0016165803108808296, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.009724352331606217, 'truePoliticalReward_min': -0.03129533678756477, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.0987731496826671, 'trueLowerStageReward_min': -0.11567226667515973, 'trueLowerStageReward_max': -0.08654625453236368, 'trueSmoothStageChangesReward_mean': -0.06720207253886011, 'trueSmoothStageChangesReward_min': -0.12435233160621761, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.6999743945848036, 'total_modified_reward_min': -6.553538449176523, 'total_modified_reward_max': -2.9316608391630603}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.8299971914788087, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.028744302025297656, 'policy_loss': -0.004753140592947602, 'vf_loss': 0.022538387390571492, 'vf_explained_var': 0.8304998564720154, 'kl': 0.008595838907984397, 'entropy': 0.4185014130671819, 'entropy_coeff': 0.08540919999999999}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 6450.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 84920, 'num_env_steps_trained': 84920, 'num_agent_steps_sampled': 84920, 'num_agent_steps_trained': 84920}, 'sampler_results': {'episode_reward_max': -2.9316608391630603, 'episode_reward_min': -6.553538449176523, 'episode_reward_mean': -3.6999743945848036, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -21.309621788875457, 'default_policy/true_reward_min': -62.41319805153398, 'default_policy/true_reward_max': -1.960342712474615, 'default_policy/proxy_reward_mean': -2.5416217888754753, 'default_policy/proxy_reward_min': -5.314264068711926, 'default_policy/proxy_reward_max': -1.8635533905932702, 'default_policy/modified_reward_mean': -3.6999743945848036, 'default_policy/modified_reward_min': -6.553538449176523, 'default_policy/modified_reward_max': -2.9316608391630603, 'default_policy/corr_btw_rewards_mean': 0.4187975645322237, 'default_policy/corr_btw_rewards_min': 0.08900477399628184, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -21.309621788875457, 'true_reward_min': -62.41319805153398, 'true_reward_max': -1.960342712474615, 'proxy_reward_mean': -2.5416217888754753, 'proxy_reward_min': -5.314264068711926, 'proxy_reward_max': -1.8635533905932702, 'modified_reward_mean': -3.6999743945848036, 'modified_reward_min': -6.553538449176523, 'modified_reward_max': -2.9316608391630603, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00026196891191709854, 'proxyInfectionSummaryAbsoluteReward_min': -0.0016165803108808296, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0987731496826671, 'proxyLowerStageReward_min': -0.11567226667515973, 'proxyLowerStageReward_max': -0.08654625453236368, 'proxySmoothStageChangesReward_mean': -0.06720207253886011, 'proxySmoothStageChangesReward_min': -0.12435233160621761, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00026196891191709854, 'trueInfectionSummaryAbsoluteReward_min': -0.0016165803108808296, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.009724352331606217, 'truePoliticalReward_min': -0.03129533678756477, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.0987731496826671, 'trueLowerStageReward_min': -0.11567226667515973, 'trueLowerStageReward_max': -0.08654625453236368, 'trueSmoothStageChangesReward_mean': -0.06720207253886011, 'trueSmoothStageChangesReward_min': -0.12435233160621761, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.6999743945848036, 'total_modified_reward_min': -6.553538449176523, 'total_modified_reward_max': -2.9316608391630603}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5356036963381773, 'mean_inference_ms': 1.6933655707299682, 'mean_action_processing_ms': 0.10829368234038231, 'mean_env_wait_ms': 788.4414299239675, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.9316608391630603, 'episode_reward_min': -6.553538449176523, 'episode_reward_mean': -3.6999743945848036, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5356036963381773, 'mean_inference_ms': 1.6933655707299682, 'mean_action_processing_ms': 0.10829368234038231, 'mean_env_wait_ms': 788.4414299239675, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 84920, 'num_agent_steps_trained': 84920, 'num_env_steps_sampled': 84920, 'num_env_steps_trained': 84920, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.637150861023402, 'num_env_steps_trained_throughput_per_sec': 12.637150861023402, 'timesteps_total': 84920, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 84920, 'timers': {'training_iteration_time_ms': 311816.805, 'sample_time_ms': 310828.849, 'load_time_ms': 5.784, 'load_throughput': 667384.483, 'learn_time_ms': 964.083, 'learn_throughput': 4003.804, 'synch_weights_time_ms': 17.145}, 'counters': {'num_env_steps_sampled': 84920, 'num_env_steps_trained': 84920, 'num_agent_steps_sampled': 84920, 'num_agent_steps_trained': 84920}, 'done': False, 'episodes_total': 440, 'training_iteration': 22, 'trial_id': 'default', 'date': '2025-11-04_20-49-16', 'timestamp': 1762318156, 'time_this_iter_s': 305.46546721458435, 'time_total_s': 6986.292457580566, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6a9255c90>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e2512ad0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699562b00>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699563790>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 6986.292457580566, 'iterations_since_restore': 22, 'perf': {'cpu_util_percent': 20.350229357798167, 'ram_util_percent': 6.0}}
Iteration 23/100
{'custom_metrics': {'default_policy/true_reward_mean': -20.22745909050325, 'default_policy/true_reward_min': -62.41319805153398, 'default_policy/true_reward_max': -1.7649873734152879, 'default_policy/proxy_reward_mean': -2.4314590905032665, 'default_policy/proxy_reward_min': -5.314264068711926, 'default_policy/proxy_reward_max': -1.7239213562373057, 'default_policy/modified_reward_mean': -3.5504889426348494, 'default_policy/modified_reward_min': -6.553538449176523, 'default_policy/modified_reward_max': -2.6693984714202594, 'default_policy/corr_btw_rewards_mean': 0.4295287659558165, 'default_policy/corr_btw_rewards_min': 0.08900477399628184, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -20.22745909050325, 'true_reward_min': -62.41319805153398, 'true_reward_max': -1.7649873734152879, 'proxy_reward_mean': -2.4314590905032665, 'proxy_reward_min': -5.314264068711926, 'proxy_reward_max': -1.7239213562373057, 'modified_reward_mean': -3.5504889426348494, 'modified_reward_min': -6.553538449176523, 'modified_reward_max': -2.6693984714202594, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00023906735751295352, 'proxyInfectionSummaryAbsoluteReward_min': -0.0016165803108808296, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09577508240949571, 'proxyLowerStageReward_min': -0.1149134759528451, 'proxyLowerStageReward_max': -0.08310473348379842, 'proxySmoothStageChangesReward_mean': -0.06300518134715027, 'proxySmoothStageChangesReward_min': -0.10362694300518134, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00023906735751295352, 'trueInfectionSummaryAbsoluteReward_min': -0.0016165803108808296, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.009220725388601036, 'truePoliticalReward_min': -0.03129533678756477, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09577508240949571, 'trueLowerStageReward_min': -0.1149134759528451, 'trueLowerStageReward_max': -0.08310473348379842, 'trueSmoothStageChangesReward_mean': -0.06300518134715027, 'trueSmoothStageChangesReward_min': -0.10362694300518134, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.5504889426348494, 'total_modified_reward_min': -6.553538449176523, 'total_modified_reward_max': -2.6693984714202594}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9403264732907216, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.028135050345057002, 'policy_loss': 9.973738187303146e-05, 'vf_loss': 0.007029858792860371, 'vf_explained_var': 0.9116126054525375, 'kl': 0.005519333167431949, 'entropy': 0.3784502254923185, 'entropy_coeff': 0.08471439999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 6750.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 88780, 'num_env_steps_trained': 88780, 'num_agent_steps_sampled': 88780, 'num_agent_steps_trained': 88780}, 'sampler_results': {'episode_reward_max': -2.6693984714202594, 'episode_reward_min': -6.553538449176523, 'episode_reward_mean': -3.5504889426348494, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -20.22745909050325, 'default_policy/true_reward_min': -62.41319805153398, 'default_policy/true_reward_max': -1.7649873734152879, 'default_policy/proxy_reward_mean': -2.4314590905032665, 'default_policy/proxy_reward_min': -5.314264068711926, 'default_policy/proxy_reward_max': -1.7239213562373057, 'default_policy/modified_reward_mean': -3.5504889426348494, 'default_policy/modified_reward_min': -6.553538449176523, 'default_policy/modified_reward_max': -2.6693984714202594, 'default_policy/corr_btw_rewards_mean': 0.4295287659558165, 'default_policy/corr_btw_rewards_min': 0.08900477399628184, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -20.22745909050325, 'true_reward_min': -62.41319805153398, 'true_reward_max': -1.7649873734152879, 'proxy_reward_mean': -2.4314590905032665, 'proxy_reward_min': -5.314264068711926, 'proxy_reward_max': -1.7239213562373057, 'modified_reward_mean': -3.5504889426348494, 'modified_reward_min': -6.553538449176523, 'modified_reward_max': -2.6693984714202594, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00023906735751295352, 'proxyInfectionSummaryAbsoluteReward_min': -0.0016165803108808296, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09577508240949571, 'proxyLowerStageReward_min': -0.1149134759528451, 'proxyLowerStageReward_max': -0.08310473348379842, 'proxySmoothStageChangesReward_mean': -0.06300518134715027, 'proxySmoothStageChangesReward_min': -0.10362694300518134, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00023906735751295352, 'trueInfectionSummaryAbsoluteReward_min': -0.0016165803108808296, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.009220725388601036, 'truePoliticalReward_min': -0.03129533678756477, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09577508240949571, 'trueLowerStageReward_min': -0.1149134759528451, 'trueLowerStageReward_max': -0.08310473348379842, 'trueSmoothStageChangesReward_mean': -0.06300518134715027, 'trueSmoothStageChangesReward_min': -0.10362694300518134, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.5504889426348494, 'total_modified_reward_min': -6.553538449176523, 'total_modified_reward_max': -2.6693984714202594}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5354820283589363, 'mean_inference_ms': 1.6923497510233392, 'mean_action_processing_ms': 0.10821413918073058, 'mean_env_wait_ms': 788.0953190060234, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.6693984714202594, 'episode_reward_min': -6.553538449176523, 'episode_reward_mean': -3.5504889426348494, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5354820283589363, 'mean_inference_ms': 1.6923497510233392, 'mean_action_processing_ms': 0.10821413918073058, 'mean_env_wait_ms': 788.0953190060234, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 88780, 'num_agent_steps_trained': 88780, 'num_env_steps_sampled': 88780, 'num_env_steps_trained': 88780, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.566044582080213, 'num_env_steps_trained_throughput_per_sec': 12.566044582080213, 'timesteps_total': 88780, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 88780, 'timers': {'training_iteration_time_ms': 311828.656, 'sample_time_ms': 310835.498, 'load_time_ms': 5.818, 'load_throughput': 663416.384, 'learn_time_ms': 968.916, 'learn_throughput': 3983.832, 'synch_weights_time_ms': 17.461}, 'counters': {'num_env_steps_sampled': 88780, 'num_env_steps_trained': 88780, 'num_agent_steps_sampled': 88780, 'num_agent_steps_trained': 88780}, 'done': False, 'episodes_total': 460, 'training_iteration': 23, 'trial_id': 'default', 'date': '2025-11-04_20-54-24', 'timestamp': 1762318464, 'time_this_iter_s': 307.1985239982605, 'time_total_s': 7293.490981578827, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e0ffe7a0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e0ffd5a0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2632410>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2632ce0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 7293.490981578827, 'iterations_since_restore': 23, 'perf': {'cpu_util_percent': 19.74771689497717, 'ram_util_percent': 6.0}}
Iteration 24/100
{'custom_metrics': {'default_policy/true_reward_mean': -19.344679905783423, 'default_policy/true_reward_min': -56.076408729652684, 'default_policy/true_reward_max': -1.7649873734152879, 'default_policy/proxy_reward_mean': -2.344679905783438, 'default_policy/proxy_reward_min': -5.314264068711926, 'default_policy/proxy_reward_max': -1.7239213562373057, 'default_policy/modified_reward_mean': -3.4433557632951004, 'default_policy/modified_reward_min': -6.553538449176523, 'default_policy/modified_reward_max': -2.6693984714202594, 'default_policy/corr_btw_rewards_mean': 0.43084187819889214, 'default_policy/corr_btw_rewards_min': 0.08900477399628184, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -19.344679905783423, 'true_reward_min': -56.076408729652684, 'true_reward_max': -1.7649873734152879, 'proxy_reward_mean': -2.344679905783438, 'proxy_reward_min': -5.314264068711926, 'proxy_reward_max': -1.7239213562373057, 'modified_reward_mean': -3.4433557632951004, 'modified_reward_min': -6.553538449176523, 'modified_reward_max': -2.6693984714202594, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00021347150259067366, 'proxyInfectionSummaryAbsoluteReward_min': -0.0016165803108808296, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09385906247582586, 'proxyLowerStageReward_min': -0.10877015900061805, 'proxyLowerStageReward_max': -0.08180939669623366, 'proxySmoothStageChangesReward_mean': -0.06279792746113991, 'proxySmoothStageChangesReward_min': -0.10362694300518134, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00021347150259067366, 'trueInfectionSummaryAbsoluteReward_min': -0.0016165803108808296, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.008808290155440414, 'truePoliticalReward_min': -0.027979274611398965, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09385906247582586, 'trueLowerStageReward_min': -0.10877015900061805, 'trueLowerStageReward_max': -0.08180939669623366, 'trueSmoothStageChangesReward_mean': -0.06279792746113991, 'trueSmoothStageChangesReward_min': -0.10362694300518134, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.4433557632951004, 'total_modified_reward_min': -6.553538449176523, 'total_modified_reward_max': -2.6693984714202594}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9910146228969097, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.03242435236927122, 'policy_loss': -0.0027151557585845393, 'vf_loss': 0.007279407949051043, 'vf_explained_var': 0.9167492683728536, 'kl': 0.012409460363086442, 'entropy': 0.4052261111140251, 'entropy_coeff': 0.08401959999999999}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 7050.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 92640, 'num_env_steps_trained': 92640, 'num_agent_steps_sampled': 92640, 'num_agent_steps_trained': 92640}, 'sampler_results': {'episode_reward_max': -2.6693984714202594, 'episode_reward_min': -6.553538449176523, 'episode_reward_mean': -3.4433557632951004, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -19.344679905783423, 'default_policy/true_reward_min': -56.076408729652684, 'default_policy/true_reward_max': -1.7649873734152879, 'default_policy/proxy_reward_mean': -2.344679905783438, 'default_policy/proxy_reward_min': -5.314264068711926, 'default_policy/proxy_reward_max': -1.7239213562373057, 'default_policy/modified_reward_mean': -3.4433557632951004, 'default_policy/modified_reward_min': -6.553538449176523, 'default_policy/modified_reward_max': -2.6693984714202594, 'default_policy/corr_btw_rewards_mean': 0.43084187819889214, 'default_policy/corr_btw_rewards_min': 0.08900477399628184, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -19.344679905783423, 'true_reward_min': -56.076408729652684, 'true_reward_max': -1.7649873734152879, 'proxy_reward_mean': -2.344679905783438, 'proxy_reward_min': -5.314264068711926, 'proxy_reward_max': -1.7239213562373057, 'modified_reward_mean': -3.4433557632951004, 'modified_reward_min': -6.553538449176523, 'modified_reward_max': -2.6693984714202594, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00021347150259067366, 'proxyInfectionSummaryAbsoluteReward_min': -0.0016165803108808296, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09385906247582586, 'proxyLowerStageReward_min': -0.10877015900061805, 'proxyLowerStageReward_max': -0.08180939669623366, 'proxySmoothStageChangesReward_mean': -0.06279792746113991, 'proxySmoothStageChangesReward_min': -0.10362694300518134, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00021347150259067366, 'trueInfectionSummaryAbsoluteReward_min': -0.0016165803108808296, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.008808290155440414, 'truePoliticalReward_min': -0.027979274611398965, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09385906247582586, 'trueLowerStageReward_min': -0.10877015900061805, 'trueLowerStageReward_max': -0.08180939669623366, 'trueSmoothStageChangesReward_mean': -0.06279792746113991, 'trueSmoothStageChangesReward_min': -0.10362694300518134, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.4433557632951004, 'total_modified_reward_min': -6.553538449176523, 'total_modified_reward_max': -2.6693984714202594}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5351229303171497, 'mean_inference_ms': 1.6911747351081403, 'mean_action_processing_ms': 0.10810760608757064, 'mean_env_wait_ms': 787.7829985904455, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.6693984714202594, 'episode_reward_min': -6.553538449176523, 'episode_reward_mean': -3.4433557632951004, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5351229303171497, 'mean_inference_ms': 1.6911747351081403, 'mean_action_processing_ms': 0.10810760608757064, 'mean_env_wait_ms': 787.7829985904455, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 92640, 'num_agent_steps_trained': 92640, 'num_env_steps_sampled': 92640, 'num_env_steps_trained': 92640, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.532256418262074, 'num_env_steps_trained_throughput_per_sec': 12.532256418262074, 'timesteps_total': 92640, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 92640, 'timers': {'training_iteration_time_ms': 311219.607, 'sample_time_ms': 310226.068, 'load_time_ms': 6.024, 'load_throughput': 640739.499, 'learn_time_ms': 969.934, 'learn_throughput': 3979.652, 'synch_weights_time_ms': 16.604}, 'counters': {'num_env_steps_sampled': 92640, 'num_env_steps_trained': 92640, 'num_agent_steps_sampled': 92640, 'num_agent_steps_trained': 92640}, 'done': False, 'episodes_total': 480, 'training_iteration': 24, 'trial_id': 'default', 'date': '2025-11-04_20-59-32', 'timestamp': 1762318772, 'time_this_iter_s': 308.02289390563965, 'time_total_s': 7601.513875484467, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a699534310>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14cba9d0dcc0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699537df0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699535870>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 7601.513875484467, 'iterations_since_restore': 24, 'perf': {'cpu_util_percent': 20.28997722095672, 'ram_util_percent': 6.0}}
Iteration 25/100
{'custom_metrics': {'default_policy/true_reward_mean': -17.941600847329447, 'default_policy/true_reward_min': -56.076408729652684, 'default_policy/true_reward_max': -1.7649873734152879, 'default_policy/proxy_reward_mean': -2.385600847329456, 'default_policy/proxy_reward_min': -5.314264068711926, 'default_policy/proxy_reward_max': -1.7239213562373057, 'default_policy/modified_reward_mean': -3.471408419000396, 'default_policy/modified_reward_min': -6.553538449176523, 'default_policy/modified_reward_max': -2.6693984714202594, 'default_policy/corr_btw_rewards_mean': 0.43549798121909405, 'default_policy/corr_btw_rewards_min': 0.08900477399628184, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -17.941600847329447, 'true_reward_min': -56.076408729652684, 'true_reward_max': -1.7649873734152879, 'proxy_reward_mean': -2.385600847329456, 'proxy_reward_min': -5.314264068711926, 'proxy_reward_max': -1.7239213562373057, 'modified_reward_mean': -3.471408419000396, 'modified_reward_min': -6.553538449176523, 'modified_reward_max': -2.6693984714202594, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002499481865284975, 'proxyInfectionSummaryAbsoluteReward_min': -0.0016165803108808296, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09198968120878014, 'proxyLowerStageReward_min': -0.10877015900061805, 'proxyLowerStageReward_max': -0.07640580488891005, 'proxySmoothStageChangesReward_mean': -0.06621761658031089, 'proxySmoothStageChangesReward_min': -0.12435233160621761, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002499481865284975, 'trueInfectionSummaryAbsoluteReward_min': -0.0016165803108808296, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.008060103626943005, 'truePoliticalReward_min': -0.027979274611398965, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09198968120878014, 'trueLowerStageReward_min': -0.10877015900061805, 'trueLowerStageReward_max': -0.07640580488891005, 'trueSmoothStageChangesReward_mean': -0.06621761658031089, 'trueSmoothStageChangesReward_min': -0.12435233160621761, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.471408419000396, 'total_modified_reward_min': -6.553538449176523, 'total_modified_reward_max': -2.6693984714202594}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.210697110046943, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.02031533008441329, 'policy_loss': -0.0017117942372957865, 'vf_loss': 0.037655155128450135, 'vf_explained_var': 0.43599202354749045, 'kl': 0.012348556208286406, 'entropy': 0.45755547513564426, 'entropy_coeff': 0.08332479999999999}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 7350.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 96500, 'num_env_steps_trained': 96500, 'num_agent_steps_sampled': 96500, 'num_agent_steps_trained': 96500}, 'sampler_results': {'episode_reward_max': -2.6693984714202594, 'episode_reward_min': -6.553538449176523, 'episode_reward_mean': -3.471408419000396, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -17.941600847329447, 'default_policy/true_reward_min': -56.076408729652684, 'default_policy/true_reward_max': -1.7649873734152879, 'default_policy/proxy_reward_mean': -2.385600847329456, 'default_policy/proxy_reward_min': -5.314264068711926, 'default_policy/proxy_reward_max': -1.7239213562373057, 'default_policy/modified_reward_mean': -3.471408419000396, 'default_policy/modified_reward_min': -6.553538449176523, 'default_policy/modified_reward_max': -2.6693984714202594, 'default_policy/corr_btw_rewards_mean': 0.43549798121909405, 'default_policy/corr_btw_rewards_min': 0.08900477399628184, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -17.941600847329447, 'true_reward_min': -56.076408729652684, 'true_reward_max': -1.7649873734152879, 'proxy_reward_mean': -2.385600847329456, 'proxy_reward_min': -5.314264068711926, 'proxy_reward_max': -1.7239213562373057, 'modified_reward_mean': -3.471408419000396, 'modified_reward_min': -6.553538449176523, 'modified_reward_max': -2.6693984714202594, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002499481865284975, 'proxyInfectionSummaryAbsoluteReward_min': -0.0016165803108808296, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09198968120878014, 'proxyLowerStageReward_min': -0.10877015900061805, 'proxyLowerStageReward_max': -0.07640580488891005, 'proxySmoothStageChangesReward_mean': -0.06621761658031089, 'proxySmoothStageChangesReward_min': -0.12435233160621761, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002499481865284975, 'trueInfectionSummaryAbsoluteReward_min': -0.0016165803108808296, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.008060103626943005, 'truePoliticalReward_min': -0.027979274611398965, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09198968120878014, 'trueLowerStageReward_min': -0.10877015900061805, 'trueLowerStageReward_max': -0.07640580488891005, 'trueSmoothStageChangesReward_mean': -0.06621761658031089, 'trueSmoothStageChangesReward_min': -0.12435233160621761, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.471408419000396, 'total_modified_reward_min': -6.553538449176523, 'total_modified_reward_max': -2.6693984714202594}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5347127604064994, 'mean_inference_ms': 1.6898187411411107, 'mean_action_processing_ms': 0.10801669142406109, 'mean_env_wait_ms': 787.3519222452418, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.6693984714202594, 'episode_reward_min': -6.553538449176523, 'episode_reward_mean': -3.471408419000396, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5347127604064994, 'mean_inference_ms': 1.6898187411411107, 'mean_action_processing_ms': 0.10801669142406109, 'mean_env_wait_ms': 787.3519222452418, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 96500, 'num_agent_steps_trained': 96500, 'num_env_steps_sampled': 96500, 'num_env_steps_trained': 96500, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.37445986368294, 'num_env_steps_trained_throughput_per_sec': 12.37445986368294, 'timesteps_total': 96500, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 96500, 'timers': {'training_iteration_time_ms': 310949.507, 'sample_time_ms': 309956.656, 'load_time_ms': 6.24, 'load_throughput': 618609.999, 'learn_time_ms': 968.854, 'learn_throughput': 3984.089, 'synch_weights_time_ms': 16.782}, 'counters': {'num_env_steps_sampled': 96500, 'num_env_steps_trained': 96500, 'num_agent_steps_sampled': 96500, 'num_agent_steps_trained': 96500}, 'done': False, 'episodes_total': 500, 'training_iteration': 25, 'trial_id': 'default', 'date': '2025-11-04_21-04-44', 'timestamp': 1762319084, 'time_this_iter_s': 311.96299147605896, 'time_total_s': 7913.4768669605255, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a699535cc0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699537730>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e177bfa0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e177ab00>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 7913.4768669605255, 'iterations_since_restore': 25, 'perf': {'cpu_util_percent': 19.81644144144144, 'ram_util_percent': 6.0}}
Iteration 26/100
{'custom_metrics': {'default_policy/true_reward_mean': -20.02000364312496, 'default_policy/true_reward_min': -62.69247474683062, 'default_policy/true_reward_max': -1.7649873734152879, 'default_policy/proxy_reward_mean': -2.3120036431249664, 'default_policy/proxy_reward_min': -5.314264068711926, 'default_policy/proxy_reward_max': -1.7239213562373057, 'default_policy/modified_reward_mean': -3.383517812685663, 'default_policy/modified_reward_min': -6.553538449176523, 'default_policy/modified_reward_max': -2.6693984714202594, 'default_policy/corr_btw_rewards_mean': 0.45520328636321034, 'default_policy/corr_btw_rewards_min': 0.08900477399628184, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -20.02000364312496, 'true_reward_min': -62.69247474683062, 'true_reward_max': -1.7649873734152879, 'proxy_reward_mean': -2.3120036431249664, 'proxy_reward_min': -5.314264068711926, 'proxy_reward_max': -1.7239213562373057, 'modified_reward_mean': -3.383517812685663, 'modified_reward_min': -6.553538449176523, 'modified_reward_max': -2.6693984714202594, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00022943005181347165, 'proxyInfectionSummaryAbsoluteReward_min': -0.0016165803108808296, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0897722094883403, 'proxyLowerStageReward_min': -0.10877015900061805, 'proxyLowerStageReward_max': -0.07640580488891005, 'proxySmoothStageChangesReward_mean': -0.07077720207253886, 'proxySmoothStageChangesReward_min': -0.12435233160621761, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00022943005181347165, 'trueInfectionSummaryAbsoluteReward_min': -0.0016165803108808296, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.009175129533678755, 'truePoliticalReward_min': -0.03129533678756477, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.0897722094883403, 'trueLowerStageReward_min': -0.10877015900061805, 'trueLowerStageReward_max': -0.07640580488891005, 'trueSmoothStageChangesReward_mean': -0.07077720207253886, 'trueSmoothStageChangesReward_min': -0.12435233160621761, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.383517812685663, 'total_modified_reward_min': -6.553538449176523, 'total_modified_reward_max': -2.6693984714202594}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.8726285047084094, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.0346033296493503, 'policy_loss': -0.0020823361289997898, 'vf_loss': 0.007540577175144184, 'vf_explained_var': 0.9114873486757279, 'kl': 0.006619022023971549, 'entropy': 0.44370808482170104, 'entropy_coeff': 0.08263}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 7650.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 100360, 'num_env_steps_trained': 100360, 'num_agent_steps_sampled': 100360, 'num_agent_steps_trained': 100360}, 'sampler_results': {'episode_reward_max': -2.6693984714202594, 'episode_reward_min': -6.553538449176523, 'episode_reward_mean': -3.383517812685663, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -20.02000364312496, 'default_policy/true_reward_min': -62.69247474683062, 'default_policy/true_reward_max': -1.7649873734152879, 'default_policy/proxy_reward_mean': -2.3120036431249664, 'default_policy/proxy_reward_min': -5.314264068711926, 'default_policy/proxy_reward_max': -1.7239213562373057, 'default_policy/modified_reward_mean': -3.383517812685663, 'default_policy/modified_reward_min': -6.553538449176523, 'default_policy/modified_reward_max': -2.6693984714202594, 'default_policy/corr_btw_rewards_mean': 0.45520328636321034, 'default_policy/corr_btw_rewards_min': 0.08900477399628184, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -20.02000364312496, 'true_reward_min': -62.69247474683062, 'true_reward_max': -1.7649873734152879, 'proxy_reward_mean': -2.3120036431249664, 'proxy_reward_min': -5.314264068711926, 'proxy_reward_max': -1.7239213562373057, 'modified_reward_mean': -3.383517812685663, 'modified_reward_min': -6.553538449176523, 'modified_reward_max': -2.6693984714202594, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00022943005181347165, 'proxyInfectionSummaryAbsoluteReward_min': -0.0016165803108808296, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0897722094883403, 'proxyLowerStageReward_min': -0.10877015900061805, 'proxyLowerStageReward_max': -0.07640580488891005, 'proxySmoothStageChangesReward_mean': -0.07077720207253886, 'proxySmoothStageChangesReward_min': -0.12435233160621761, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00022943005181347165, 'trueInfectionSummaryAbsoluteReward_min': -0.0016165803108808296, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.009175129533678755, 'truePoliticalReward_min': -0.03129533678756477, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.0897722094883403, 'trueLowerStageReward_min': -0.10877015900061805, 'trueLowerStageReward_max': -0.07640580488891005, 'trueSmoothStageChangesReward_mean': -0.07077720207253886, 'trueSmoothStageChangesReward_min': -0.12435233160621761, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.383517812685663, 'total_modified_reward_min': -6.553538449176523, 'total_modified_reward_max': -2.6693984714202594}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5335366759441275, 'mean_inference_ms': 1.688467201757195, 'mean_action_processing_ms': 0.10793381213780323, 'mean_env_wait_ms': 786.7964710021373, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.6693984714202594, 'episode_reward_min': -6.553538449176523, 'episode_reward_mean': -3.383517812685663, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5335366759441275, 'mean_inference_ms': 1.688467201757195, 'mean_action_processing_ms': 0.10793381213780323, 'mean_env_wait_ms': 786.7964710021373, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 100360, 'num_agent_steps_trained': 100360, 'num_env_steps_sampled': 100360, 'num_env_steps_trained': 100360, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.571766539457656, 'num_env_steps_trained_throughput_per_sec': 12.571766539457656, 'timesteps_total': 100360, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 100360, 'timers': {'training_iteration_time_ms': 310387.13, 'sample_time_ms': 309413.916, 'load_time_ms': 6.127, 'load_throughput': 629961.612, 'learn_time_ms': 949.166, 'learn_throughput': 4066.727, 'synch_weights_time_ms': 16.993}, 'counters': {'num_env_steps_sampled': 100360, 'num_env_steps_trained': 100360, 'num_agent_steps_sampled': 100360, 'num_agent_steps_trained': 100360}, 'done': False, 'episodes_total': 520, 'training_iteration': 26, 'trial_id': 'default', 'date': '2025-11-04_21-09-51', 'timestamp': 1762319391, 'time_this_iter_s': 307.0585916042328, 'time_total_s': 8220.535458564758, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e0ffc790>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14cba9d0da20>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699562170>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699563c70>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 8220.535458564758, 'iterations_since_restore': 26, 'perf': {'cpu_util_percent': 19.666970387243733, 'ram_util_percent': 6.0}}
Iteration 27/100
{'custom_metrics': {'default_policy/true_reward_mean': -21.826081438920472, 'default_policy/true_reward_min': -63.391764068711964, 'default_policy/true_reward_max': -1.7649873734152879, 'default_policy/proxy_reward_mean': -2.2780814389204767, 'default_policy/proxy_reward_min': -4.401764068711931, 'default_policy/proxy_reward_max': -1.7239213562373057, 'default_policy/modified_reward_mean': -3.3415099648952666, 'default_policy/modified_reward_min': -5.620333368419634, 'default_policy/modified_reward_max': -2.6693984714202594, 'default_policy/corr_btw_rewards_mean': 0.428992382577598, 'default_policy/corr_btw_rewards_min': 0.16660279267482733, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -21.826081438920472, 'true_reward_min': -63.391764068711964, 'true_reward_max': -1.7649873734152879, 'proxy_reward_mean': -2.2780814389204767, 'proxy_reward_min': -4.401764068711931, 'proxy_reward_max': -1.7239213562373057, 'modified_reward_mean': -3.3415099648952666, 'modified_reward_min': -5.620333368419634, 'modified_reward_max': -2.6693984714202594, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00022341968911917108, 'proxyInfectionSummaryAbsoluteReward_min': -0.0011813471502590681, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.08817002274199372, 'proxyLowerStageReward_min': -0.10164580666901184, 'proxyLowerStageReward_max': -0.07499934577281303, 'proxySmoothStageChangesReward_mean': -0.07523316062176166, 'proxySmoothStageChangesReward_min': -0.12435233160621761, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00022341968911917108, 'trueInfectionSummaryAbsoluteReward_min': -0.0011813471502590681, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010128497409326425, 'truePoliticalReward_min': -0.03129533678756477, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.08817002274199372, 'trueLowerStageReward_min': -0.10164580666901184, 'trueLowerStageReward_max': -0.07499934577281303, 'trueSmoothStageChangesReward_mean': -0.07523316062176166, 'trueSmoothStageChangesReward_min': -0.12435233160621761, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.3415099648952666, 'total_modified_reward_min': -5.620333368419634, 'total_modified_reward_max': -2.6693984714202594}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.8592513439804316, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.03808961839686769, 'policy_loss': -0.008832168939212959, 'vf_loss': 0.010839848518759633, 'vf_explained_var': 0.8515741147597631, 'kl': 0.007665363195351169, 'entropy': 0.4284917110204697, 'entropy_coeff': 0.0819352}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 7950.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 104220, 'num_env_steps_trained': 104220, 'num_agent_steps_sampled': 104220, 'num_agent_steps_trained': 104220}, 'sampler_results': {'episode_reward_max': -2.6693984714202594, 'episode_reward_min': -5.620333368419634, 'episode_reward_mean': -3.3415099648952666, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -21.826081438920472, 'default_policy/true_reward_min': -63.391764068711964, 'default_policy/true_reward_max': -1.7649873734152879, 'default_policy/proxy_reward_mean': -2.2780814389204767, 'default_policy/proxy_reward_min': -4.401764068711931, 'default_policy/proxy_reward_max': -1.7239213562373057, 'default_policy/modified_reward_mean': -3.3415099648952666, 'default_policy/modified_reward_min': -5.620333368419634, 'default_policy/modified_reward_max': -2.6693984714202594, 'default_policy/corr_btw_rewards_mean': 0.428992382577598, 'default_policy/corr_btw_rewards_min': 0.16660279267482733, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -21.826081438920472, 'true_reward_min': -63.391764068711964, 'true_reward_max': -1.7649873734152879, 'proxy_reward_mean': -2.2780814389204767, 'proxy_reward_min': -4.401764068711931, 'proxy_reward_max': -1.7239213562373057, 'modified_reward_mean': -3.3415099648952666, 'modified_reward_min': -5.620333368419634, 'modified_reward_max': -2.6693984714202594, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00022341968911917108, 'proxyInfectionSummaryAbsoluteReward_min': -0.0011813471502590681, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.08817002274199372, 'proxyLowerStageReward_min': -0.10164580666901184, 'proxyLowerStageReward_max': -0.07499934577281303, 'proxySmoothStageChangesReward_mean': -0.07523316062176166, 'proxySmoothStageChangesReward_min': -0.12435233160621761, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00022341968911917108, 'trueInfectionSummaryAbsoluteReward_min': -0.0011813471502590681, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010128497409326425, 'truePoliticalReward_min': -0.03129533678756477, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.08817002274199372, 'trueLowerStageReward_min': -0.10164580666901184, 'trueLowerStageReward_max': -0.07499934577281303, 'trueSmoothStageChangesReward_mean': -0.07523316062176166, 'trueSmoothStageChangesReward_min': -0.12435233160621761, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.3415099648952666, 'total_modified_reward_min': -5.620333368419634, 'total_modified_reward_max': -2.6693984714202594}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5324274389230349, 'mean_inference_ms': 1.6872155512080758, 'mean_action_processing_ms': 0.10786083462299707, 'mean_env_wait_ms': 786.2003557737787, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.6693984714202594, 'episode_reward_min': -5.620333368419634, 'episode_reward_mean': -3.3415099648952666, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5324274389230349, 'mean_inference_ms': 1.6872155512080758, 'mean_action_processing_ms': 0.10786083462299707, 'mean_env_wait_ms': 786.2003557737787, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 104220, 'num_agent_steps_trained': 104220, 'num_env_steps_sampled': 104220, 'num_env_steps_trained': 104220, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.618248135540815, 'num_env_steps_trained_throughput_per_sec': 12.618248135540815, 'timesteps_total': 104220, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 104220, 'timers': {'training_iteration_time_ms': 309788.802, 'sample_time_ms': 308815.798, 'load_time_ms': 5.397, 'load_throughput': 715220.328, 'learn_time_ms': 949.495, 'learn_throughput': 4065.321, 'synch_weights_time_ms': 17.156}, 'counters': {'num_env_steps_sampled': 104220, 'num_env_steps_trained': 104220, 'num_agent_steps_sampled': 104220, 'num_agent_steps_trained': 104220}, 'done': False, 'episodes_total': 540, 'training_iteration': 27, 'trial_id': 'default', 'date': '2025-11-04_21-14-57', 'timestamp': 1762319697, 'time_this_iter_s': 305.9265344142914, 'time_total_s': 8526.46199297905, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e177af50>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e1778f40>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e1779120>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e177b820>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 8526.46199297905, 'iterations_since_restore': 27, 'perf': {'cpu_util_percent': 20.32889908256881, 'ram_util_percent': 6.0}}
Iteration 28/100
{'custom_metrics': {'default_policy/true_reward_mean': -21.927427759264027, 'default_policy/true_reward_min': -63.391764068711964, 'default_policy/true_reward_max': -2.0303427124746154, 'default_policy/proxy_reward_mean': -2.3394277592640362, 'default_policy/proxy_reward_min': -4.814974746830586, 'default_policy/proxy_reward_max': -1.7621320343559603, 'default_policy/modified_reward_mean': -3.4057609966427544, 'default_policy/modified_reward_min': -6.1114645522910385, 'default_policy/modified_reward_max': -2.7085525991730677, 'default_policy/corr_btw_rewards_mean': 0.40454694250853457, 'default_policy/corr_btw_rewards_min': 0.10917194670928328, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -21.927427759264027, 'true_reward_min': -63.391764068711964, 'true_reward_max': -2.0303427124746154, 'proxy_reward_mean': -2.3394277592640362, 'proxy_reward_min': -4.814974746830586, 'proxy_reward_max': -1.7621320343559603, 'modified_reward_mean': -3.4057609966427544, 'modified_reward_min': -6.1114645522910385, 'modified_reward_max': -2.7085525991730677, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002547150259067359, 'proxyInfectionSummaryAbsoluteReward_min': -0.0013471502590673584, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.08794962483233357, 'proxyLowerStageReward_min': -0.10336656719329446, 'proxyLowerStageReward_max': -0.07499934577281303, 'proxySmoothStageChangesReward_mean': -0.07792746113989639, 'proxySmoothStageChangesReward_min': -0.12435233160621761, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002547150259067359, 'trueInfectionSummaryAbsoluteReward_min': -0.0013471502590673584, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.01014922279792746, 'truePoliticalReward_min': -0.03129533678756477, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.08794962483233357, 'trueLowerStageReward_min': -0.10336656719329446, 'trueLowerStageReward_max': -0.07499934577281303, 'trueSmoothStageChangesReward_mean': -0.07792746113989639, 'trueSmoothStageChangesReward_min': -0.12435233160621761, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.4057609966427544, 'total_modified_reward_min': -6.1114645522910385, 'total_modified_reward_max': -2.7085525991730677}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9029782740275065, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.030759956103477936, 'policy_loss': -0.002596227996982634, 'vf_loss': 0.015989516023352433, 'vf_explained_var': 0.854732475678126, 'kl': 0.008322443569742462, 'entropy': 0.45084240635236106, 'entropy_coeff': 0.0812404}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 8250.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 108080, 'num_env_steps_trained': 108080, 'num_agent_steps_sampled': 108080, 'num_agent_steps_trained': 108080}, 'sampler_results': {'episode_reward_max': -2.7085525991730677, 'episode_reward_min': -6.1114645522910385, 'episode_reward_mean': -3.4057609966427544, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -21.927427759264027, 'default_policy/true_reward_min': -63.391764068711964, 'default_policy/true_reward_max': -2.0303427124746154, 'default_policy/proxy_reward_mean': -2.3394277592640362, 'default_policy/proxy_reward_min': -4.814974746830586, 'default_policy/proxy_reward_max': -1.7621320343559603, 'default_policy/modified_reward_mean': -3.4057609966427544, 'default_policy/modified_reward_min': -6.1114645522910385, 'default_policy/modified_reward_max': -2.7085525991730677, 'default_policy/corr_btw_rewards_mean': 0.40454694250853457, 'default_policy/corr_btw_rewards_min': 0.10917194670928328, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -21.927427759264027, 'true_reward_min': -63.391764068711964, 'true_reward_max': -2.0303427124746154, 'proxy_reward_mean': -2.3394277592640362, 'proxy_reward_min': -4.814974746830586, 'proxy_reward_max': -1.7621320343559603, 'modified_reward_mean': -3.4057609966427544, 'modified_reward_min': -6.1114645522910385, 'modified_reward_max': -2.7085525991730677, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002547150259067359, 'proxyInfectionSummaryAbsoluteReward_min': -0.0013471502590673584, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.08794962483233357, 'proxyLowerStageReward_min': -0.10336656719329446, 'proxyLowerStageReward_max': -0.07499934577281303, 'proxySmoothStageChangesReward_mean': -0.07792746113989639, 'proxySmoothStageChangesReward_min': -0.12435233160621761, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002547150259067359, 'trueInfectionSummaryAbsoluteReward_min': -0.0013471502590673584, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.01014922279792746, 'truePoliticalReward_min': -0.03129533678756477, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.08794962483233357, 'trueLowerStageReward_min': -0.10336656719329446, 'trueLowerStageReward_max': -0.07499934577281303, 'trueSmoothStageChangesReward_mean': -0.07792746113989639, 'trueSmoothStageChangesReward_min': -0.12435233160621761, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.4057609966427544, 'total_modified_reward_min': -6.1114645522910385, 'total_modified_reward_max': -2.7085525991730677}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5324921716625624, 'mean_inference_ms': 1.6861073628788628, 'mean_action_processing_ms': 0.10780900803285634, 'mean_env_wait_ms': 785.5307635782672, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.7085525991730677, 'episode_reward_min': -6.1114645522910385, 'episode_reward_mean': -3.4057609966427544, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5324921716625624, 'mean_inference_ms': 1.6861073628788628, 'mean_action_processing_ms': 0.10780900803285634, 'mean_env_wait_ms': 785.5307635782672, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 108080, 'num_agent_steps_trained': 108080, 'num_env_steps_sampled': 108080, 'num_env_steps_trained': 108080, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.64438787717421, 'num_env_steps_trained_throughput_per_sec': 12.64438787717421, 'timesteps_total': 108080, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 108080, 'timers': {'training_iteration_time_ms': 309280.402, 'sample_time_ms': 308316.97, 'load_time_ms': 5.323, 'load_throughput': 725151.096, 'learn_time_ms': 940.389, 'learn_throughput': 4104.682, 'synch_weights_time_ms': 16.788}, 'counters': {'num_env_steps_sampled': 108080, 'num_env_steps_trained': 108080, 'num_agent_steps_sampled': 108080, 'num_agent_steps_trained': 108080}, 'done': False, 'episodes_total': 560, 'training_iteration': 28, 'trial_id': 'default', 'date': '2025-11-04_21-20-03', 'timestamp': 1762320003, 'time_this_iter_s': 305.30057168006897, 'time_total_s': 8831.762564659119, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6a9255cc0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699782b00>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e24fad40>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e24f9ba0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 8831.762564659119, 'iterations_since_restore': 28, 'perf': {'cpu_util_percent': 20.33816091954023, 'ram_util_percent': 6.0}}
Iteration 29/100
{'custom_metrics': {'default_policy/true_reward_mean': -22.79035809832336, 'default_policy/true_reward_min': -72.18425144212733, 'default_policy/true_reward_max': -2.025698051533944, 'default_policy/proxy_reward_mean': -2.382358098323364, 'default_policy/proxy_reward_min': -5.373172798364526, 'default_policy/proxy_reward_max': -1.7621320343559603, 'default_policy/modified_reward_mean': -3.4592814343611513, 'default_policy/modified_reward_min': -6.733442357279873, 'default_policy/modified_reward_max': -2.7085525991730677, 'default_policy/corr_btw_rewards_mean': 0.40623783719137996, 'default_policy/corr_btw_rewards_min': 0.10917194670928328, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -22.79035809832336, 'true_reward_min': -72.18425144212733, 'true_reward_max': -2.025698051533944, 'proxy_reward_mean': -2.382358098323364, 'proxy_reward_min': -5.373172798364526, 'proxy_reward_max': -1.7621320343559603, 'modified_reward_mean': -3.4592814343611513, 'modified_reward_min': -6.733442357279873, 'modified_reward_max': -2.7085525991730677, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002689119170984458, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015751295336787576, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0885056009493972, 'proxyLowerStageReward_min': -0.10949081856811031, 'proxyLowerStageReward_max': -0.07499934577281303, 'proxySmoothStageChangesReward_mean': -0.08041450777202072, 'proxySmoothStageChangesReward_min': -0.12435233160621761, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002689119170984458, 'trueInfectionSummaryAbsoluteReward_min': -0.0015751295336787576, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010574093264248706, 'truePoliticalReward_min': -0.03626943005181347, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.0885056009493972, 'trueLowerStageReward_min': -0.10949081856811031, 'trueLowerStageReward_max': -0.07499934577281303, 'trueSmoothStageChangesReward_mean': -0.08041450777202072, 'trueSmoothStageChangesReward_min': -0.12435233160621761, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.4592814343611513, 'total_modified_reward_min': -6.733442357279873, 'total_modified_reward_max': -2.7085525991730677}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9123364657536149, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.03525686426379252, 'policy_loss': -0.005658681097750863, 'vf_loss': 0.021538143950601808, 'vf_explained_var': 0.7701936314503351, 'kl': 0.01138901874976279, 'entropy': 0.5091263242562611, 'entropy_coeff': 0.0805456}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 8550.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 111940, 'num_env_steps_trained': 111940, 'num_agent_steps_sampled': 111940, 'num_agent_steps_trained': 111940}, 'sampler_results': {'episode_reward_max': -2.7085525991730677, 'episode_reward_min': -6.733442357279873, 'episode_reward_mean': -3.4592814343611513, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -22.79035809832336, 'default_policy/true_reward_min': -72.18425144212733, 'default_policy/true_reward_max': -2.025698051533944, 'default_policy/proxy_reward_mean': -2.382358098323364, 'default_policy/proxy_reward_min': -5.373172798364526, 'default_policy/proxy_reward_max': -1.7621320343559603, 'default_policy/modified_reward_mean': -3.4592814343611513, 'default_policy/modified_reward_min': -6.733442357279873, 'default_policy/modified_reward_max': -2.7085525991730677, 'default_policy/corr_btw_rewards_mean': 0.40623783719137996, 'default_policy/corr_btw_rewards_min': 0.10917194670928328, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -22.79035809832336, 'true_reward_min': -72.18425144212733, 'true_reward_max': -2.025698051533944, 'proxy_reward_mean': -2.382358098323364, 'proxy_reward_min': -5.373172798364526, 'proxy_reward_max': -1.7621320343559603, 'modified_reward_mean': -3.4592814343611513, 'modified_reward_min': -6.733442357279873, 'modified_reward_max': -2.7085525991730677, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002689119170984458, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015751295336787576, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0885056009493972, 'proxyLowerStageReward_min': -0.10949081856811031, 'proxyLowerStageReward_max': -0.07499934577281303, 'proxySmoothStageChangesReward_mean': -0.08041450777202072, 'proxySmoothStageChangesReward_min': -0.12435233160621761, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002689119170984458, 'trueInfectionSummaryAbsoluteReward_min': -0.0015751295336787576, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010574093264248706, 'truePoliticalReward_min': -0.03626943005181347, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.0885056009493972, 'trueLowerStageReward_min': -0.10949081856811031, 'trueLowerStageReward_max': -0.07499934577281303, 'trueSmoothStageChangesReward_mean': -0.08041450777202072, 'trueSmoothStageChangesReward_min': -0.12435233160621761, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.4592814343611513, 'total_modified_reward_min': -6.733442357279873, 'total_modified_reward_max': -2.7085525991730677}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5326666308064766, 'mean_inference_ms': 1.6852042251456583, 'mean_action_processing_ms': 0.10776573076876134, 'mean_env_wait_ms': 784.8638733677756, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.7085525991730677, 'episode_reward_min': -6.733442357279873, 'episode_reward_mean': -3.4592814343611513, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5326666308064766, 'mean_inference_ms': 1.6852042251456583, 'mean_action_processing_ms': 0.10776573076876134, 'mean_env_wait_ms': 784.8638733677756, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 111940, 'num_agent_steps_trained': 111940, 'num_env_steps_sampled': 111940, 'num_env_steps_trained': 111940, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.57997148055232, 'num_env_steps_trained_throughput_per_sec': 12.57997148055232, 'timesteps_total': 111940, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 111940, 'timers': {'training_iteration_time_ms': 308333.615, 'sample_time_ms': 307346.93, 'load_time_ms': 5.336, 'load_throughput': 723330.33, 'learn_time_ms': 963.23, 'learn_throughput': 4007.352, 'synch_weights_time_ms': 17.156}, 'counters': {'num_env_steps_sampled': 111940, 'num_env_steps_trained': 111940, 'num_agent_steps_sampled': 111940, 'num_agent_steps_trained': 111940}, 'done': False, 'episodes_total': 580, 'training_iteration': 29, 'trial_id': 'default', 'date': '2025-11-04_21-25-10', 'timestamp': 1762320310, 'time_this_iter_s': 306.86031317710876, 'time_total_s': 9138.622877836227, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6882fdbd0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14cba9d0dcc0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6882ff130>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6882fd510>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 9138.622877836227, 'iterations_since_restore': 29, 'perf': {'cpu_util_percent': 20.211212814645314, 'ram_util_percent': 6.0}}
Iteration 30/100
{'custom_metrics': {'default_policy/true_reward_mean': -24.878372185619888, 'default_policy/true_reward_min': -75.73854076400866, 'default_policy/true_reward_max': -2.025698051533944, 'default_policy/proxy_reward_mean': -2.3783721856198903, 'default_policy/proxy_reward_min': -5.373172798364526, 'default_policy/proxy_reward_max': -1.7621320343559603, 'default_policy/modified_reward_mean': -3.4573219253265113, 'default_policy/modified_reward_min': -6.733442357279873, 'default_policy/modified_reward_max': -2.7085525991730677, 'default_policy/corr_btw_rewards_mean': 0.390012028262155, 'default_policy/corr_btw_rewards_min': 0.10917194670928328, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -24.878372185619888, 'true_reward_min': -75.73854076400866, 'true_reward_max': -2.025698051533944, 'proxy_reward_mean': -2.3783721856198903, 'proxy_reward_min': -5.373172798364526, 'proxy_reward_max': -1.7621320343559603, 'modified_reward_mean': -3.4573219253265113, 'modified_reward_min': -6.733442357279873, 'modified_reward_max': -2.7085525991730677, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00026507772020725403, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015751295336787576, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.08866177127564201, 'proxyLowerStageReward_min': -0.10949081856811031, 'proxyLowerStageReward_max': -0.07499934577281303, 'proxySmoothStageChangesReward_mean': -0.08062176165803109, 'proxySmoothStageChangesReward_min': -0.12435233160621761, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00026507772020725403, 'trueInfectionSummaryAbsoluteReward_min': -0.0015751295336787576, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.011658031088082901, 'truePoliticalReward_min': -0.038134715025906735, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.08866177127564201, 'trueLowerStageReward_min': -0.10949081856811031, 'trueLowerStageReward_max': -0.07499934577281303, 'trueSmoothStageChangesReward_mean': -0.08062176165803109, 'trueSmoothStageChangesReward_min': -0.12435233160621761, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.4573219253265113, 'total_modified_reward_min': -6.733442357279873, 'total_modified_reward_max': -2.7085525991730677}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.1491578864802916, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.027043636984502274, 'policy_loss': -0.0031197949638590216, 'vf_loss': 0.0341080798736463, 'vf_explained_var': 0.5516518187522889, 'kl': 0.005246255319315726, 'entropy': 0.5168762746453285, 'entropy_coeff': 0.0798508}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 8850.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 115800, 'num_env_steps_trained': 115800, 'num_agent_steps_sampled': 115800, 'num_agent_steps_trained': 115800}, 'sampler_results': {'episode_reward_max': -2.7085525991730677, 'episode_reward_min': -6.733442357279873, 'episode_reward_mean': -3.4573219253265113, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -24.878372185619888, 'default_policy/true_reward_min': -75.73854076400866, 'default_policy/true_reward_max': -2.025698051533944, 'default_policy/proxy_reward_mean': -2.3783721856198903, 'default_policy/proxy_reward_min': -5.373172798364526, 'default_policy/proxy_reward_max': -1.7621320343559603, 'default_policy/modified_reward_mean': -3.4573219253265113, 'default_policy/modified_reward_min': -6.733442357279873, 'default_policy/modified_reward_max': -2.7085525991730677, 'default_policy/corr_btw_rewards_mean': 0.390012028262155, 'default_policy/corr_btw_rewards_min': 0.10917194670928328, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -24.878372185619888, 'true_reward_min': -75.73854076400866, 'true_reward_max': -2.025698051533944, 'proxy_reward_mean': -2.3783721856198903, 'proxy_reward_min': -5.373172798364526, 'proxy_reward_max': -1.7621320343559603, 'modified_reward_mean': -3.4573219253265113, 'modified_reward_min': -6.733442357279873, 'modified_reward_max': -2.7085525991730677, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00026507772020725403, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015751295336787576, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.08866177127564201, 'proxyLowerStageReward_min': -0.10949081856811031, 'proxyLowerStageReward_max': -0.07499934577281303, 'proxySmoothStageChangesReward_mean': -0.08062176165803109, 'proxySmoothStageChangesReward_min': -0.12435233160621761, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00026507772020725403, 'trueInfectionSummaryAbsoluteReward_min': -0.0015751295336787576, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.011658031088082901, 'truePoliticalReward_min': -0.038134715025906735, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.08866177127564201, 'trueLowerStageReward_min': -0.10949081856811031, 'trueLowerStageReward_max': -0.07499934577281303, 'trueSmoothStageChangesReward_mean': -0.08062176165803109, 'trueSmoothStageChangesReward_min': -0.12435233160621761, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.4573219253265113, 'total_modified_reward_min': -6.733442357279873, 'total_modified_reward_max': -2.7085525991730677}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5338455600749201, 'mean_inference_ms': 1.6844373533906873, 'mean_action_processing_ms': 0.10771399551052387, 'mean_env_wait_ms': 784.2197218493326, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.7085525991730677, 'episode_reward_min': -6.733442357279873, 'episode_reward_mean': -3.4573219253265113, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5338455600749201, 'mean_inference_ms': 1.6844373533906873, 'mean_action_processing_ms': 0.10771399551052387, 'mean_env_wait_ms': 784.2197218493326, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 115800, 'num_agent_steps_trained': 115800, 'num_env_steps_sampled': 115800, 'num_env_steps_trained': 115800, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.768020340917422, 'num_env_steps_trained_throughput_per_sec': 12.768020340917422, 'timesteps_total': 115800, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 115800, 'timers': {'training_iteration_time_ms': 307191.137, 'sample_time_ms': 306210.393, 'load_time_ms': 5.586, 'load_throughput': 691033.367, 'learn_time_ms': 957.486, 'learn_throughput': 4031.392, 'synch_weights_time_ms': 16.725}, 'counters': {'num_env_steps_sampled': 115800, 'num_env_steps_trained': 115800, 'num_agent_steps_sampled': 115800, 'num_agent_steps_trained': 115800}, 'done': False, 'episodes_total': 600, 'training_iteration': 30, 'trial_id': 'default', 'date': '2025-11-04_21-30-12', 'timestamp': 1762320612, 'time_this_iter_s': 302.3424324989319, 'time_total_s': 9440.96531033516, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e0ffd330>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e153d960>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffc100>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffe4a0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 9440.96531033516, 'iterations_since_restore': 30, 'perf': {'cpu_util_percent': 20.36828703703704, 'ram_util_percent': 6.0}}
Saved checkpoint to TrainingResult(checkpoint=Checkpoint(filesystem=local, path=logs/data/pandemic/20251104_185246/checkpoint_30), metrics={'custom_metrics': {'default_policy/true_reward_mean': -24.878372185619888, 'default_policy/true_reward_min': -75.73854076400866, 'default_policy/true_reward_max': -2.025698051533944, 'default_policy/proxy_reward_mean': -2.3783721856198903, 'default_policy/proxy_reward_min': -5.373172798364526, 'default_policy/proxy_reward_max': -1.7621320343559603, 'default_policy/modified_reward_mean': -3.4573219253265113, 'default_policy/modified_reward_min': -6.733442357279873, 'default_policy/modified_reward_max': -2.7085525991730677, 'default_policy/corr_btw_rewards_mean': 0.390012028262155, 'default_policy/corr_btw_rewards_min': 0.10917194670928328, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -24.878372185619888, 'true_reward_min': -75.73854076400866, 'true_reward_max': -2.025698051533944, 'proxy_reward_mean': -2.3783721856198903, 'proxy_reward_min': -5.373172798364526, 'proxy_reward_max': -1.7621320343559603, 'modified_reward_mean': -3.4573219253265113, 'modified_reward_min': -6.733442357279873, 'modified_reward_max': -2.7085525991730677, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00026507772020725403, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015751295336787576, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.08866177127564201, 'proxyLowerStageReward_min': -0.10949081856811031, 'proxyLowerStageReward_max': -0.07499934577281303, 'proxySmoothStageChangesReward_mean': -0.08062176165803109, 'proxySmoothStageChangesReward_min': -0.12435233160621761, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00026507772020725403, 'trueInfectionSummaryAbsoluteReward_min': -0.0015751295336787576, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.011658031088082901, 'truePoliticalReward_min': -0.038134715025906735, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.08866177127564201, 'trueLowerStageReward_min': -0.10949081856811031, 'trueLowerStageReward_max': -0.07499934577281303, 'trueSmoothStageChangesReward_mean': -0.08062176165803109, 'trueSmoothStageChangesReward_min': -0.12435233160621761, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.4573219253265113, 'total_modified_reward_min': -6.733442357279873, 'total_modified_reward_max': -2.7085525991730677}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.1491578864802916, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.027043636984502274, 'policy_loss': -0.0031197949638590216, 'vf_loss': 0.0341080798736463, 'vf_explained_var': 0.5516518187522889, 'kl': 0.005246255319315726, 'entropy': 0.5168762746453285, 'entropy_coeff': 0.0798508}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 8850.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 115800, 'num_env_steps_trained': 115800, 'num_agent_steps_sampled': 115800, 'num_agent_steps_trained': 115800}, 'sampler_results': {'episode_reward_max': -2.7085525991730677, 'episode_reward_min': -6.733442357279873, 'episode_reward_mean': -3.4573219253265113, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -24.878372185619888, 'default_policy/true_reward_min': -75.73854076400866, 'default_policy/true_reward_max': -2.025698051533944, 'default_policy/proxy_reward_mean': -2.3783721856198903, 'default_policy/proxy_reward_min': -5.373172798364526, 'default_policy/proxy_reward_max': -1.7621320343559603, 'default_policy/modified_reward_mean': -3.4573219253265113, 'default_policy/modified_reward_min': -6.733442357279873, 'default_policy/modified_reward_max': -2.7085525991730677, 'default_policy/corr_btw_rewards_mean': 0.390012028262155, 'default_policy/corr_btw_rewards_min': 0.10917194670928328, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -24.878372185619888, 'true_reward_min': -75.73854076400866, 'true_reward_max': -2.025698051533944, 'proxy_reward_mean': -2.3783721856198903, 'proxy_reward_min': -5.373172798364526, 'proxy_reward_max': -1.7621320343559603, 'modified_reward_mean': -3.4573219253265113, 'modified_reward_min': -6.733442357279873, 'modified_reward_max': -2.7085525991730677, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00026507772020725403, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015751295336787576, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.08866177127564201, 'proxyLowerStageReward_min': -0.10949081856811031, 'proxyLowerStageReward_max': -0.07499934577281303, 'proxySmoothStageChangesReward_mean': -0.08062176165803109, 'proxySmoothStageChangesReward_min': -0.12435233160621761, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00026507772020725403, 'trueInfectionSummaryAbsoluteReward_min': -0.0015751295336787576, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.011658031088082901, 'truePoliticalReward_min': -0.038134715025906735, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.08866177127564201, 'trueLowerStageReward_min': -0.10949081856811031, 'trueLowerStageReward_max': -0.07499934577281303, 'trueSmoothStageChangesReward_mean': -0.08062176165803109, 'trueSmoothStageChangesReward_min': -0.12435233160621761, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.4573219253265113, 'total_modified_reward_min': -6.733442357279873, 'total_modified_reward_max': -2.7085525991730677}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5338455600749201, 'mean_inference_ms': 1.6844373533906873, 'mean_action_processing_ms': 0.10771399551052387, 'mean_env_wait_ms': 784.2197218493326, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.7085525991730677, 'episode_reward_min': -6.733442357279873, 'episode_reward_mean': -3.4573219253265113, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5338455600749201, 'mean_inference_ms': 1.6844373533906873, 'mean_action_processing_ms': 0.10771399551052387, 'mean_env_wait_ms': 784.2197218493326, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 115800, 'num_agent_steps_trained': 115800, 'num_env_steps_sampled': 115800, 'num_env_steps_trained': 115800, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.768020340917422, 'num_env_steps_trained_throughput_per_sec': 12.768020340917422, 'timesteps_total': 115800, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 115800, 'timers': {'training_iteration_time_ms': 307191.137, 'sample_time_ms': 306210.393, 'load_time_ms': 5.586, 'load_throughput': 691033.367, 'learn_time_ms': 957.486, 'learn_throughput': 4031.392, 'synch_weights_time_ms': 16.725}, 'counters': {'num_env_steps_sampled': 115800, 'num_env_steps_trained': 115800, 'num_agent_steps_sampled': 115800, 'num_agent_steps_trained': 115800}, 'done': False, 'episodes_total': 600, 'training_iteration': 30, 'trial_id': 'default', 'date': '2025-11-04_21-30-12', 'timestamp': 1762320612, 'time_this_iter_s': 302.3424324989319, 'time_total_s': 9440.96531033516, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e0ffd330>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e153d960>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffc100>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffe4a0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 9440.96531033516, 'iterations_since_restore': 30, 'perf': {'cpu_util_percent': 20.36828703703704, 'ram_util_percent': 6.0}})
Iteration 31/100
{'custom_metrics': {'default_policy/true_reward_mean': -24.357515078838706, 'default_policy/true_reward_min': -75.73854076400866, 'default_policy/true_reward_max': -1.7906980515339435, 'default_policy/proxy_reward_mean': -2.497515078838704, 'default_policy/proxy_reward_min': -6.949619407771251, 'default_policy/proxy_reward_max': -1.6792766952966336, 'default_policy/modified_reward_mean': -3.5817913756013295, 'default_policy/modified_reward_min': -8.214011482787809, 'default_policy/modified_reward_max': -2.555911433247642, 'default_policy/corr_btw_rewards_mean': 0.3985065716815002, 'default_policy/corr_btw_rewards_min': 0.06427744073808168, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -24.357515078838706, 'true_reward_min': -75.73854076400866, 'true_reward_max': -1.7906980515339435, 'proxy_reward_mean': -2.497515078838704, 'proxy_reward_min': -6.949619407771251, 'proxy_reward_max': -1.6792766952966336, 'modified_reward_mean': -3.5817913756013295, 'modified_reward_min': -8.214011482787809, 'modified_reward_max': -2.555911433247642, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00032010362694300534, 'proxyInfectionSummaryAbsoluteReward_min': -0.0024663212435233174, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.08951891600200543, 'proxyLowerStageReward_min': -0.10949081856811031, 'proxyLowerStageReward_max': -0.07457392203609517, 'proxySmoothStageChangesReward_mean': -0.07875647668393784, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00032010362694300534, 'trueInfectionSummaryAbsoluteReward_min': -0.0024663212435233174, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.011326424870466322, 'truePoliticalReward_min': -0.038134715025906735, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.08951891600200543, 'trueLowerStageReward_min': -0.10949081856811031, 'trueLowerStageReward_max': -0.07457392203609517, 'trueSmoothStageChangesReward_mean': -0.07875647668393784, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.5817913756013295, 'total_modified_reward_min': -8.214011482787809, 'total_modified_reward_max': -2.555911433247642}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.1848315105338891, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.027182368898453813, 'policy_loss': -0.007788485176861286, 'vf_loss': 0.048988664090866225, 'vf_explained_var': 0.5699921218554179, 'kl': 0.01021110396720507, 'entropy': 0.5617084286610285, 'entropy_coeff': 0.079156}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 9150.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 119660, 'num_env_steps_trained': 119660, 'num_agent_steps_sampled': 119660, 'num_agent_steps_trained': 119660}, 'sampler_results': {'episode_reward_max': -2.555911433247642, 'episode_reward_min': -8.214011482787809, 'episode_reward_mean': -3.5817913756013295, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -24.357515078838706, 'default_policy/true_reward_min': -75.73854076400866, 'default_policy/true_reward_max': -1.7906980515339435, 'default_policy/proxy_reward_mean': -2.497515078838704, 'default_policy/proxy_reward_min': -6.949619407771251, 'default_policy/proxy_reward_max': -1.6792766952966336, 'default_policy/modified_reward_mean': -3.5817913756013295, 'default_policy/modified_reward_min': -8.214011482787809, 'default_policy/modified_reward_max': -2.555911433247642, 'default_policy/corr_btw_rewards_mean': 0.3985065716815002, 'default_policy/corr_btw_rewards_min': 0.06427744073808168, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -24.357515078838706, 'true_reward_min': -75.73854076400866, 'true_reward_max': -1.7906980515339435, 'proxy_reward_mean': -2.497515078838704, 'proxy_reward_min': -6.949619407771251, 'proxy_reward_max': -1.6792766952966336, 'modified_reward_mean': -3.5817913756013295, 'modified_reward_min': -8.214011482787809, 'modified_reward_max': -2.555911433247642, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00032010362694300534, 'proxyInfectionSummaryAbsoluteReward_min': -0.0024663212435233174, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.08951891600200543, 'proxyLowerStageReward_min': -0.10949081856811031, 'proxyLowerStageReward_max': -0.07457392203609517, 'proxySmoothStageChangesReward_mean': -0.07875647668393784, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00032010362694300534, 'trueInfectionSummaryAbsoluteReward_min': -0.0024663212435233174, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.011326424870466322, 'truePoliticalReward_min': -0.038134715025906735, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.08951891600200543, 'trueLowerStageReward_min': -0.10949081856811031, 'trueLowerStageReward_max': -0.07457392203609517, 'trueSmoothStageChangesReward_mean': -0.07875647668393784, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.5817913756013295, 'total_modified_reward_min': -8.214011482787809, 'total_modified_reward_max': -2.555911433247642}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.535083410895175, 'mean_inference_ms': 1.683748463069915, 'mean_action_processing_ms': 0.10765107263351302, 'mean_env_wait_ms': 783.6534999352708, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.555911433247642, 'episode_reward_min': -8.214011482787809, 'episode_reward_mean': -3.5817913756013295, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.535083410895175, 'mean_inference_ms': 1.683748463069915, 'mean_action_processing_ms': 0.10765107263351302, 'mean_env_wait_ms': 783.6534999352708, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 119660, 'num_agent_steps_trained': 119660, 'num_env_steps_sampled': 119660, 'num_env_steps_trained': 119660, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.613575140411394, 'num_env_steps_trained_throughput_per_sec': 12.613575140411394, 'timesteps_total': 119660, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 119660, 'timers': {'training_iteration_time_ms': 306595.4, 'sample_time_ms': 305594.786, 'load_time_ms': 5.707, 'load_throughput': 676362.162, 'learn_time_ms': 977.264, 'learn_throughput': 3949.804, 'synch_weights_time_ms': 16.696}, 'counters': {'num_env_steps_sampled': 119660, 'num_env_steps_trained': 119660, 'num_agent_steps_sampled': 119660, 'num_agent_steps_trained': 119660}, 'done': False, 'episodes_total': 620, 'training_iteration': 31, 'trial_id': 'default', 'date': '2025-11-04_21-35-18', 'timestamp': 1762320918, 'time_this_iter_s': 306.0406427383423, 'time_total_s': 9747.005953073502, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a699611ab0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699613f10>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699613b50>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699610ee0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 9747.005953073502, 'iterations_since_restore': 31, 'perf': {'cpu_util_percent': 20.11379310344828, 'ram_util_percent': 6.0}}
Iteration 32/100
{'custom_metrics': {'default_policy/true_reward_mean': -24.810453913603546, 'default_policy/true_reward_min': -75.73854076400866, 'default_policy/true_reward_max': -1.7906980515339435, 'default_policy/proxy_reward_mean': -2.590453913603536, 'default_policy/proxy_reward_min': -6.949619407771251, 'default_policy/proxy_reward_max': -1.6792766952966336, 'default_policy/modified_reward_mean': -3.6849050602052738, 'default_policy/modified_reward_min': -8.214011482787809, 'default_policy/modified_reward_max': -2.555911433247642, 'default_policy/corr_btw_rewards_mean': 0.3960749697632416, 'default_policy/corr_btw_rewards_min': 0.06427744073808168, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -24.810453913603546, 'true_reward_min': -75.73854076400866, 'true_reward_max': -1.7906980515339435, 'proxy_reward_mean': -2.590453913603536, 'proxy_reward_min': -6.949619407771251, 'proxy_reward_max': -1.6792766952966336, 'modified_reward_mean': -3.6849050602052738, 'modified_reward_min': -8.214011482787809, 'modified_reward_max': -2.555911433247642, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003581347150259069, 'proxyInfectionSummaryAbsoluteReward_min': -0.0024663212435233174, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09057274163748896, 'proxyLowerStageReward_min': -0.10949081856811031, 'proxyLowerStageReward_max': -0.07457392203609517, 'proxySmoothStageChangesReward_mean': -0.07834196891191711, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003581347150259069, 'trueInfectionSummaryAbsoluteReward_min': -0.0024663212435233174, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.011512953367875646, 'truePoliticalReward_min': -0.038134715025906735, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09057274163748896, 'trueLowerStageReward_min': -0.10949081856811031, 'trueLowerStageReward_max': -0.07457392203609517, 'trueSmoothStageChangesReward_mean': -0.07834196891191711, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.6849050602052738, 'total_modified_reward_min': -8.214011482787809, 'total_modified_reward_max': -2.555911433247642}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.1691721373051405, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.023734121532179416, 'policy_loss': 8.721258956938981e-05, 'vf_loss': 0.04013320702031099, 'vf_explained_var': 0.5493149487177531, 'kl': 0.006371999225468023, 'entropy': 0.5639266270399094, 'entropy_coeff': 0.07846120000000001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 9450.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 123520, 'num_env_steps_trained': 123520, 'num_agent_steps_sampled': 123520, 'num_agent_steps_trained': 123520}, 'sampler_results': {'episode_reward_max': -2.555911433247642, 'episode_reward_min': -8.214011482787809, 'episode_reward_mean': -3.6849050602052738, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -24.810453913603546, 'default_policy/true_reward_min': -75.73854076400866, 'default_policy/true_reward_max': -1.7906980515339435, 'default_policy/proxy_reward_mean': -2.590453913603536, 'default_policy/proxy_reward_min': -6.949619407771251, 'default_policy/proxy_reward_max': -1.6792766952966336, 'default_policy/modified_reward_mean': -3.6849050602052738, 'default_policy/modified_reward_min': -8.214011482787809, 'default_policy/modified_reward_max': -2.555911433247642, 'default_policy/corr_btw_rewards_mean': 0.3960749697632416, 'default_policy/corr_btw_rewards_min': 0.06427744073808168, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -24.810453913603546, 'true_reward_min': -75.73854076400866, 'true_reward_max': -1.7906980515339435, 'proxy_reward_mean': -2.590453913603536, 'proxy_reward_min': -6.949619407771251, 'proxy_reward_max': -1.6792766952966336, 'modified_reward_mean': -3.6849050602052738, 'modified_reward_min': -8.214011482787809, 'modified_reward_max': -2.555911433247642, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003581347150259069, 'proxyInfectionSummaryAbsoluteReward_min': -0.0024663212435233174, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09057274163748896, 'proxyLowerStageReward_min': -0.10949081856811031, 'proxyLowerStageReward_max': -0.07457392203609517, 'proxySmoothStageChangesReward_mean': -0.07834196891191711, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003581347150259069, 'trueInfectionSummaryAbsoluteReward_min': -0.0024663212435233174, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.011512953367875646, 'truePoliticalReward_min': -0.038134715025906735, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09057274163748896, 'trueLowerStageReward_min': -0.10949081856811031, 'trueLowerStageReward_max': -0.07457392203609517, 'trueSmoothStageChangesReward_mean': -0.07834196891191711, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.6849050602052738, 'total_modified_reward_min': -8.214011482787809, 'total_modified_reward_max': -2.555911433247642}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5370945220903945, 'mean_inference_ms': 1.6831464682963173, 'mean_action_processing_ms': 0.1076010604837878, 'mean_env_wait_ms': 782.9992880305814, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.555911433247642, 'episode_reward_min': -8.214011482787809, 'episode_reward_mean': -3.6849050602052738, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5370945220903945, 'mean_inference_ms': 1.6831464682963173, 'mean_action_processing_ms': 0.1076010604837878, 'mean_env_wait_ms': 782.9992880305814, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 123520, 'num_agent_steps_trained': 123520, 'num_env_steps_sampled': 123520, 'num_env_steps_trained': 123520, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.443178130131757, 'num_env_steps_trained_throughput_per_sec': 12.443178130131757, 'timesteps_total': 123520, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 123520, 'timers': {'training_iteration_time_ms': 307071.554, 'sample_time_ms': 306071.511, 'load_time_ms': 5.718, 'load_throughput': 675050.803, 'learn_time_ms': 976.502, 'learn_throughput': 3952.883, 'synch_weights_time_ms': 16.868}, 'counters': {'num_env_steps_sampled': 123520, 'num_env_steps_trained': 123520, 'num_agent_steps_sampled': 123520, 'num_agent_steps_trained': 123520}, 'done': False, 'episodes_total': 640, 'training_iteration': 32, 'trial_id': 'default', 'date': '2025-11-04_21-40-29', 'timestamp': 1762321229, 'time_this_iter_s': 310.2332057952881, 'time_total_s': 10057.23915886879, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e2631150>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e26312a0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2631360>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2630850>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 10057.23915886879, 'iterations_since_restore': 32, 'perf': {'cpu_util_percent': 19.599097065462757, 'ram_util_percent': 6.0}}
Iteration 33/100
{'custom_metrics': {'default_policy/true_reward_mean': -27.998520417898053, 'default_policy/true_reward_min': -82.73176406871218, 'default_policy/true_reward_max': -1.7906980515339435, 'default_policy/proxy_reward_mean': -2.650520417898032, 'default_policy/proxy_reward_min': -6.949619407771251, 'default_policy/proxy_reward_max': -1.6792766952966336, 'default_policy/modified_reward_mean': -3.7648281833294885, 'default_policy/modified_reward_min': -8.214011482787809, 'default_policy/modified_reward_max': -2.555911433247642, 'default_policy/corr_btw_rewards_mean': 0.4140827118182985, 'default_policy/corr_btw_rewards_min': 0.06427744073808168, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -27.998520417898053, 'true_reward_min': -82.73176406871218, 'true_reward_max': -1.7906980515339435, 'proxy_reward_mean': -2.650520417898032, 'proxy_reward_min': -6.949619407771251, 'proxy_reward_max': -1.6792766952966336, 'modified_reward_mean': -3.7648281833294885, 'modified_reward_min': -8.214011482787809, 'modified_reward_max': -2.555911433247642, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00037461139896373093, 'proxyInfectionSummaryAbsoluteReward_min': -0.0024663212435233174, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09151919263720375, 'proxyLowerStageReward_min': -0.10949081856811031, 'proxyLowerStageReward_max': -0.07457392203609517, 'proxySmoothStageChangesReward_mean': -0.08352331606217617, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00037461139896373093, 'trueInfectionSummaryAbsoluteReward_min': -0.0024663212435233174, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.013133678756476686, 'truePoliticalReward_min': -0.04186528497409327, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09151919263720375, 'trueLowerStageReward_min': -0.10949081856811031, 'trueLowerStageReward_max': -0.07457392203609517, 'trueSmoothStageChangesReward_mean': -0.08352331606217617, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.7648281833294885, 'total_modified_reward_min': -8.214011482787809, 'total_modified_reward_max': -2.555911433247642}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.1150704592714706, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.029906077321405367, 'policy_loss': 0.0020548281368489066, 'vf_loss': 0.03171165709247968, 'vf_explained_var': 0.6094774482647578, 'kl': 0.008745766652296554, 'entropy': 0.621202465792497, 'entropy_coeff': 0.0777664}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 9750.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 127380, 'num_env_steps_trained': 127380, 'num_agent_steps_sampled': 127380, 'num_agent_steps_trained': 127380}, 'sampler_results': {'episode_reward_max': -2.555911433247642, 'episode_reward_min': -8.214011482787809, 'episode_reward_mean': -3.7648281833294885, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -27.998520417898053, 'default_policy/true_reward_min': -82.73176406871218, 'default_policy/true_reward_max': -1.7906980515339435, 'default_policy/proxy_reward_mean': -2.650520417898032, 'default_policy/proxy_reward_min': -6.949619407771251, 'default_policy/proxy_reward_max': -1.6792766952966336, 'default_policy/modified_reward_mean': -3.7648281833294885, 'default_policy/modified_reward_min': -8.214011482787809, 'default_policy/modified_reward_max': -2.555911433247642, 'default_policy/corr_btw_rewards_mean': 0.4140827118182985, 'default_policy/corr_btw_rewards_min': 0.06427744073808168, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -27.998520417898053, 'true_reward_min': -82.73176406871218, 'true_reward_max': -1.7906980515339435, 'proxy_reward_mean': -2.650520417898032, 'proxy_reward_min': -6.949619407771251, 'proxy_reward_max': -1.6792766952966336, 'modified_reward_mean': -3.7648281833294885, 'modified_reward_min': -8.214011482787809, 'modified_reward_max': -2.555911433247642, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00037461139896373093, 'proxyInfectionSummaryAbsoluteReward_min': -0.0024663212435233174, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09151919263720375, 'proxyLowerStageReward_min': -0.10949081856811031, 'proxyLowerStageReward_max': -0.07457392203609517, 'proxySmoothStageChangesReward_mean': -0.08352331606217617, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00037461139896373093, 'trueInfectionSummaryAbsoluteReward_min': -0.0024663212435233174, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.013133678756476686, 'truePoliticalReward_min': -0.04186528497409327, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09151919263720375, 'trueLowerStageReward_min': -0.10949081856811031, 'trueLowerStageReward_max': -0.07457392203609517, 'trueSmoothStageChangesReward_mean': -0.08352331606217617, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.7648281833294885, 'total_modified_reward_min': -8.214011482787809, 'total_modified_reward_max': -2.555911433247642}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5380691509375165, 'mean_inference_ms': 1.6827088911085506, 'mean_action_processing_ms': 0.10755915006261968, 'mean_env_wait_ms': 782.3581557817772, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.555911433247642, 'episode_reward_min': -8.214011482787809, 'episode_reward_mean': -3.7648281833294885, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5380691509375165, 'mean_inference_ms': 1.6827088911085506, 'mean_action_processing_ms': 0.10755915006261968, 'mean_env_wait_ms': 782.3581557817772, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 127380, 'num_agent_steps_trained': 127380, 'num_env_steps_sampled': 127380, 'num_env_steps_trained': 127380, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.575914301903168, 'num_env_steps_trained_throughput_per_sec': 12.575914301903168, 'timesteps_total': 127380, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 127380, 'timers': {'training_iteration_time_ms': 307047.451, 'sample_time_ms': 306032.479, 'load_time_ms': 5.709, 'load_throughput': 676105.13, 'learn_time_ms': 991.968, 'learn_throughput': 3891.256, 'synch_weights_time_ms': 16.34}, 'counters': {'num_env_steps_sampled': 127380, 'num_env_steps_trained': 127380, 'num_agent_steps_sampled': 127380, 'num_agent_steps_trained': 127380}, 'done': False, 'episodes_total': 660, 'training_iteration': 33, 'trial_id': 'default', 'date': '2025-11-04_21-45-36', 'timestamp': 1762321536, 'time_this_iter_s': 306.9607651233673, 'time_total_s': 10364.199923992157, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e153e200>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e153c7f0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e153d360>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e153f370>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 10364.199923992157, 'iterations_since_restore': 33, 'perf': {'cpu_util_percent': 20.091762013729976, 'ram_util_percent': 6.0}}
Iteration 34/100
{'custom_metrics': {'default_policy/true_reward_mean': -33.717181456867394, 'default_policy/true_reward_min': -112.41247474683077, 'default_policy/true_reward_max': -1.7906980515339435, 'default_policy/proxy_reward_mean': -2.729181456867354, 'default_policy/proxy_reward_min': -6.949619407771251, 'default_policy/proxy_reward_max': -1.6792766952966336, 'default_policy/modified_reward_mean': -3.8558340719356488, 'default_policy/modified_reward_min': -8.214011482787809, 'default_policy/modified_reward_max': -2.555911433247642, 'default_policy/corr_btw_rewards_mean': 0.4282813059756144, 'default_policy/corr_btw_rewards_min': 0.06427744073808168, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -33.717181456867394, 'true_reward_min': -112.41247474683077, 'true_reward_max': -1.7906980515339435, 'proxy_reward_mean': -2.729181456867354, 'proxy_reward_min': -6.949619407771251, 'proxy_reward_max': -1.6792766952966336, 'modified_reward_mean': -3.8558340719356488, 'modified_reward_min': -8.214011482787809, 'modified_reward_max': -2.555911433247642, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00041129533678756507, 'proxyInfectionSummaryAbsoluteReward_min': -0.0024663212435233174, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09101458325737583, 'proxyLowerStageReward_min': -0.10734463430710983, 'proxyLowerStageReward_max': -0.07457392203609517, 'proxySmoothStageChangesReward_mean': -0.09264248704663214, 'proxySmoothStageChangesReward_min': -0.20725388601036268, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00041129533678756507, 'trueInfectionSummaryAbsoluteReward_min': -0.0024663212435233174, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.016055958549222798, 'truePoliticalReward_min': -0.0572020725388601, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09101458325737583, 'trueLowerStageReward_min': -0.10734463430710983, 'trueLowerStageReward_max': -0.07457392203609517, 'trueSmoothStageChangesReward_mean': -0.09264248704663214, 'trueSmoothStageChangesReward_min': -0.20725388601036268, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.8558340719356488, 'total_modified_reward_min': -8.214011482787809, 'total_modified_reward_max': -2.555911433247642}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.2915965758264065, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.029919758432855208, 'policy_loss': -0.0012392579205334187, 'vf_loss': 0.044720861271489415, 'vf_explained_var': 0.5389017405112585, 'kl': 0.01045785137169672, 'entropy': 0.6698859870433808, 'entropy_coeff': 0.0770716}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 10050.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 131240, 'num_env_steps_trained': 131240, 'num_agent_steps_sampled': 131240, 'num_agent_steps_trained': 131240}, 'sampler_results': {'episode_reward_max': -2.555911433247642, 'episode_reward_min': -8.214011482787809, 'episode_reward_mean': -3.8558340719356488, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -33.717181456867394, 'default_policy/true_reward_min': -112.41247474683077, 'default_policy/true_reward_max': -1.7906980515339435, 'default_policy/proxy_reward_mean': -2.729181456867354, 'default_policy/proxy_reward_min': -6.949619407771251, 'default_policy/proxy_reward_max': -1.6792766952966336, 'default_policy/modified_reward_mean': -3.8558340719356488, 'default_policy/modified_reward_min': -8.214011482787809, 'default_policy/modified_reward_max': -2.555911433247642, 'default_policy/corr_btw_rewards_mean': 0.4282813059756144, 'default_policy/corr_btw_rewards_min': 0.06427744073808168, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -33.717181456867394, 'true_reward_min': -112.41247474683077, 'true_reward_max': -1.7906980515339435, 'proxy_reward_mean': -2.729181456867354, 'proxy_reward_min': -6.949619407771251, 'proxy_reward_max': -1.6792766952966336, 'modified_reward_mean': -3.8558340719356488, 'modified_reward_min': -8.214011482787809, 'modified_reward_max': -2.555911433247642, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00041129533678756507, 'proxyInfectionSummaryAbsoluteReward_min': -0.0024663212435233174, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09101458325737583, 'proxyLowerStageReward_min': -0.10734463430710983, 'proxyLowerStageReward_max': -0.07457392203609517, 'proxySmoothStageChangesReward_mean': -0.09264248704663214, 'proxySmoothStageChangesReward_min': -0.20725388601036268, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00041129533678756507, 'trueInfectionSummaryAbsoluteReward_min': -0.0024663212435233174, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.016055958549222798, 'truePoliticalReward_min': -0.0572020725388601, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09101458325737583, 'trueLowerStageReward_min': -0.10734463430710983, 'trueLowerStageReward_max': -0.07457392203609517, 'trueSmoothStageChangesReward_mean': -0.09264248704663214, 'trueSmoothStageChangesReward_min': -0.20725388601036268, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.8558340719356488, 'total_modified_reward_min': -8.214011482787809, 'total_modified_reward_max': -2.555911433247642}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5389642457065488, 'mean_inference_ms': 1.6823486318812122, 'mean_action_processing_ms': 0.10751260813496182, 'mean_env_wait_ms': 781.5810804144337, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.555911433247642, 'episode_reward_min': -8.214011482787809, 'episode_reward_mean': -3.8558340719356488, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5389642457065488, 'mean_inference_ms': 1.6823486318812122, 'mean_action_processing_ms': 0.10751260813496182, 'mean_env_wait_ms': 781.5810804144337, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 131240, 'num_agent_steps_trained': 131240, 'num_env_steps_sampled': 131240, 'num_env_steps_trained': 131240, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 11.709391960391963, 'num_env_steps_trained_throughput_per_sec': 11.709391960391963, 'timesteps_total': 131240, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 131240, 'timers': {'training_iteration_time_ms': 309211.936, 'sample_time_ms': 308177.859, 'load_time_ms': 5.464, 'load_throughput': 706469.203, 'learn_time_ms': 1011.562, 'learn_throughput': 3815.881, 'synch_weights_time_ms': 16.14}, 'counters': {'num_env_steps_sampled': 131240, 'num_env_steps_trained': 131240, 'num_agent_steps_sampled': 131240, 'num_agent_steps_trained': 131240}, 'done': False, 'episodes_total': 680, 'training_iteration': 34, 'trial_id': 'default', 'date': '2025-11-04_21-51-06', 'timestamp': 1762321866, 'time_this_iter_s': 329.6685252189636, 'time_total_s': 10693.86844921112, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e1778100>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6a9255cc0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6882ff490>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6882fe110>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 10693.86844921112, 'iterations_since_restore': 34, 'perf': {'cpu_util_percent': 18.742340425531918, 'ram_util_percent': 6.0}}
Iteration 35/100
{'custom_metrics': {'default_policy/true_reward_mean': -39.68465811627029, 'default_policy/true_reward_min': -132.15639610306758, 'default_policy/true_reward_max': -1.7906980515339435, 'default_policy/proxy_reward_mean': -2.7326581162702404, 'default_policy/proxy_reward_min': -6.949619407771251, 'default_policy/proxy_reward_max': -1.6792766952966336, 'default_policy/modified_reward_mean': -3.8847451421193733, 'default_policy/modified_reward_min': -8.214011482787809, 'default_policy/modified_reward_max': -2.555911433247642, 'default_policy/corr_btw_rewards_mean': 0.44706530526012606, 'default_policy/corr_btw_rewards_min': 0.06427744073808168, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -39.68465811627029, 'true_reward_min': -132.15639610306758, 'true_reward_max': -1.7906980515339435, 'proxy_reward_mean': -2.7326581162702404, 'proxy_reward_min': -6.949619407771251, 'proxy_reward_max': -1.6792766952966336, 'modified_reward_mean': -3.8847451421193733, 'modified_reward_min': -8.214011482787809, 'modified_reward_max': -2.555911433247642, 'proxyInfectionSummaryAbsoluteReward_mean': -0.000398134715025907, 'proxyInfectionSummaryAbsoluteReward_min': -0.0024663212435233174, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09140197493628188, 'proxyLowerStageReward_min': -0.10830660410907779, 'proxyLowerStageReward_max': -0.07457392203609517, 'proxySmoothStageChangesReward_mean': -0.10373056994818654, 'proxySmoothStageChangesReward_min': -0.23834196891191708, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.000398134715025907, 'trueInfectionSummaryAbsoluteReward_min': -0.0024663212435233174, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.01914611398963731, 'truePoliticalReward_min': -0.06735751295336788, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09140197493628188, 'trueLowerStageReward_min': -0.10830660410907779, 'trueLowerStageReward_max': -0.07457392203609517, 'trueSmoothStageChangesReward_mean': -0.10373056994818654, 'trueSmoothStageChangesReward_min': -0.23834196891191708, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.8847451421193733, 'total_modified_reward_min': -8.214011482787809, 'total_modified_reward_max': -2.555911433247642}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0745524735252063, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.044818335925228894, 'policy_loss': -0.012116555413231254, 'vf_loss': 0.028152870531970013, 'vf_explained_var': 0.7254872093598048, 'kl': 0.013252510954078863, 'entropy': 0.6222264937559764, 'entropy_coeff': 0.07637680000000001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 10350.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 135100, 'num_env_steps_trained': 135100, 'num_agent_steps_sampled': 135100, 'num_agent_steps_trained': 135100}, 'sampler_results': {'episode_reward_max': -2.555911433247642, 'episode_reward_min': -8.214011482787809, 'episode_reward_mean': -3.8847451421193733, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -39.68465811627029, 'default_policy/true_reward_min': -132.15639610306758, 'default_policy/true_reward_max': -1.7906980515339435, 'default_policy/proxy_reward_mean': -2.7326581162702404, 'default_policy/proxy_reward_min': -6.949619407771251, 'default_policy/proxy_reward_max': -1.6792766952966336, 'default_policy/modified_reward_mean': -3.8847451421193733, 'default_policy/modified_reward_min': -8.214011482787809, 'default_policy/modified_reward_max': -2.555911433247642, 'default_policy/corr_btw_rewards_mean': 0.44706530526012606, 'default_policy/corr_btw_rewards_min': 0.06427744073808168, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -39.68465811627029, 'true_reward_min': -132.15639610306758, 'true_reward_max': -1.7906980515339435, 'proxy_reward_mean': -2.7326581162702404, 'proxy_reward_min': -6.949619407771251, 'proxy_reward_max': -1.6792766952966336, 'modified_reward_mean': -3.8847451421193733, 'modified_reward_min': -8.214011482787809, 'modified_reward_max': -2.555911433247642, 'proxyInfectionSummaryAbsoluteReward_mean': -0.000398134715025907, 'proxyInfectionSummaryAbsoluteReward_min': -0.0024663212435233174, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09140197493628188, 'proxyLowerStageReward_min': -0.10830660410907779, 'proxyLowerStageReward_max': -0.07457392203609517, 'proxySmoothStageChangesReward_mean': -0.10373056994818654, 'proxySmoothStageChangesReward_min': -0.23834196891191708, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.000398134715025907, 'trueInfectionSummaryAbsoluteReward_min': -0.0024663212435233174, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.01914611398963731, 'truePoliticalReward_min': -0.06735751295336788, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09140197493628188, 'trueLowerStageReward_min': -0.10830660410907779, 'trueLowerStageReward_max': -0.07457392203609517, 'trueSmoothStageChangesReward_mean': -0.10373056994818654, 'trueSmoothStageChangesReward_min': -0.23834196891191708, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.8847451421193733, 'total_modified_reward_min': -8.214011482787809, 'total_modified_reward_max': -2.555911433247642}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5388203772998679, 'mean_inference_ms': 1.6819008055835465, 'mean_action_processing_ms': 0.1074786302086088, 'mean_env_wait_ms': 780.6196179902411, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.555911433247642, 'episode_reward_min': -8.214011482787809, 'episode_reward_mean': -3.8847451421193733, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5388203772998679, 'mean_inference_ms': 1.6819008055835465, 'mean_action_processing_ms': 0.1074786302086088, 'mean_env_wait_ms': 780.6196179902411, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 135100, 'num_agent_steps_trained': 135100, 'num_env_steps_sampled': 135100, 'num_env_steps_trained': 135100, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 11.614420181817277, 'num_env_steps_trained_throughput_per_sec': 11.614420181817277, 'timesteps_total': 135100, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 135100, 'timers': {'training_iteration_time_ms': 311253.204, 'sample_time_ms': 310240.632, 'load_time_ms': 5.453, 'load_throughput': 707899.409, 'learn_time_ms': 990.421, 'learn_throughput': 3897.331, 'synch_weights_time_ms': 15.809}, 'counters': {'num_env_steps_sampled': 135100, 'num_env_steps_trained': 135100, 'num_agent_steps_sampled': 135100, 'num_agent_steps_trained': 135100}, 'done': False, 'episodes_total': 700, 'training_iteration': 35, 'trial_id': 'default', 'date': '2025-11-04_21-56-38', 'timestamp': 1762322198, 'time_this_iter_s': 332.3630986213684, 'time_total_s': 11026.231547832489, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6a92055a0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6a92067d0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6995615a0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699561e70>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 11026.231547832489, 'iterations_since_restore': 35, 'perf': {'cpu_util_percent': 18.507383966244724, 'ram_util_percent': 6.0}}
Iteration 36/100
{'custom_metrics': {'default_policy/true_reward_mean': -43.398870183313264, 'default_policy/true_reward_min': -132.15639610306758, 'default_policy/true_reward_max': -3.0256980515339555, 'default_policy/proxy_reward_mean': -2.7668701833132126, 'default_policy/proxy_reward_min': -6.251396103067888, 'default_policy/proxy_reward_max': -1.7721194077712528, 'default_policy/modified_reward_mean': -3.9400310745175475, 'default_policy/modified_reward_min': -7.448826740574088, 'default_policy/modified_reward_max': -2.7773253234050173, 'default_policy/corr_btw_rewards_mean': 0.4138668014413408, 'default_policy/corr_btw_rewards_min': 0.10653534764896759, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -43.398870183313264, 'true_reward_min': -132.15639610306758, 'true_reward_max': -3.0256980515339555, 'proxy_reward_mean': -2.7668701833132126, 'proxy_reward_min': -6.251396103067888, 'proxy_reward_max': -1.7721194077712528, 'modified_reward_mean': -3.9400310745175475, 'modified_reward_min': -7.448826740574088, 'modified_reward_max': -2.7773253234050173, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00040694300518134737, 'proxyInfectionSummaryAbsoluteReward_min': -0.0021865284974093282, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09096736701104734, 'proxyLowerStageReward_min': -0.10830660410907779, 'proxyLowerStageReward_max': -0.07044660143892517, 'proxySmoothStageChangesReward_mean': -0.11699481865284976, 'proxySmoothStageChangesReward_min': -0.23834196891191708, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.00040694300518134737, 'trueInfectionSummaryAbsoluteReward_min': -0.0021865284974093282, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.021052849740932644, 'truePoliticalReward_min': -0.06735751295336788, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09096736701104734, 'trueLowerStageReward_min': -0.10830660410907779, 'trueLowerStageReward_max': -0.07044660143892517, 'trueSmoothStageChangesReward_mean': -0.11699481865284976, 'trueSmoothStageChangesReward_min': -0.23834196891191708, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -3.9400310745175475, 'total_modified_reward_min': -7.448826740574088, 'total_modified_reward_max': -2.7773253234050173}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.2943835481007895, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.023486688965931535, 'policy_loss': -0.0028295923334856828, 'vf_loss': 0.05420799922508498, 'vf_explained_var': 0.5157089646657308, 'kl': 0.005745269404211381, 'entropy': 0.6353461683789889, 'entropy_coeff': 0.07568200000000001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 10650.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 138960, 'num_env_steps_trained': 138960, 'num_agent_steps_sampled': 138960, 'num_agent_steps_trained': 138960}, 'sampler_results': {'episode_reward_max': -2.7773253234050173, 'episode_reward_min': -7.448826740574088, 'episode_reward_mean': -3.9400310745175475, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -43.398870183313264, 'default_policy/true_reward_min': -132.15639610306758, 'default_policy/true_reward_max': -3.0256980515339555, 'default_policy/proxy_reward_mean': -2.7668701833132126, 'default_policy/proxy_reward_min': -6.251396103067888, 'default_policy/proxy_reward_max': -1.7721194077712528, 'default_policy/modified_reward_mean': -3.9400310745175475, 'default_policy/modified_reward_min': -7.448826740574088, 'default_policy/modified_reward_max': -2.7773253234050173, 'default_policy/corr_btw_rewards_mean': 0.4138668014413408, 'default_policy/corr_btw_rewards_min': 0.10653534764896759, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -43.398870183313264, 'true_reward_min': -132.15639610306758, 'true_reward_max': -3.0256980515339555, 'proxy_reward_mean': -2.7668701833132126, 'proxy_reward_min': -6.251396103067888, 'proxy_reward_max': -1.7721194077712528, 'modified_reward_mean': -3.9400310745175475, 'modified_reward_min': -7.448826740574088, 'modified_reward_max': -2.7773253234050173, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00040694300518134737, 'proxyInfectionSummaryAbsoluteReward_min': -0.0021865284974093282, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09096736701104734, 'proxyLowerStageReward_min': -0.10830660410907779, 'proxyLowerStageReward_max': -0.07044660143892517, 'proxySmoothStageChangesReward_mean': -0.11699481865284976, 'proxySmoothStageChangesReward_min': -0.23834196891191708, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.00040694300518134737, 'trueInfectionSummaryAbsoluteReward_min': -0.0021865284974093282, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.021052849740932644, 'truePoliticalReward_min': -0.06735751295336788, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09096736701104734, 'trueLowerStageReward_min': -0.10830660410907779, 'trueLowerStageReward_max': -0.07044660143892517, 'trueSmoothStageChangesReward_mean': -0.11699481865284976, 'trueSmoothStageChangesReward_min': -0.23834196891191708, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -3.9400310745175475, 'total_modified_reward_min': -7.448826740574088, 'total_modified_reward_max': -2.7773253234050173}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5387559634108753, 'mean_inference_ms': 1.681523621753039, 'mean_action_processing_ms': 0.10745102495535114, 'mean_env_wait_ms': 779.5501783892385, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.7773253234050173, 'episode_reward_min': -7.448826740574088, 'episode_reward_mean': -3.9400310745175475, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5387559634108753, 'mean_inference_ms': 1.681523621753039, 'mean_action_processing_ms': 0.10745102495535114, 'mean_env_wait_ms': 779.5501783892385, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 138960, 'num_agent_steps_trained': 138960, 'num_env_steps_sampled': 138960, 'num_env_steps_trained': 138960, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 11.616001088915612, 'num_env_steps_trained_throughput_per_sec': 11.616001088915612, 'timesteps_total': 138960, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 138960, 'timers': {'training_iteration_time_ms': 313779.512, 'sample_time_ms': 312747.733, 'load_time_ms': 5.448, 'load_throughput': 708556.211, 'learn_time_ms': 1010.231, 'learn_throughput': 3820.91, 'synch_weights_time_ms': 15.209}, 'counters': {'num_env_steps_sampled': 138960, 'num_env_steps_trained': 138960, 'num_agent_steps_sampled': 138960, 'num_agent_steps_trained': 138960}, 'done': False, 'episodes_total': 720, 'training_iteration': 36, 'trial_id': 'default', 'date': '2025-11-04_22-02-11', 'timestamp': 1762322531, 'time_this_iter_s': 332.32664465904236, 'time_total_s': 11358.558192491531, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e1779630>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e177b2b0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e1778280>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e177acb0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 11358.558192491531, 'iterations_since_restore': 36, 'perf': {'cpu_util_percent': 18.87995780590718, 'ram_util_percent': 6.0}}
Iteration 37/100
{'custom_metrics': {'default_policy/true_reward_mean': -46.06580788168549, 'default_policy/true_reward_min': -132.15639610306758, 'default_policy/true_reward_max': -3.0256980515339555, 'default_policy/proxy_reward_mean': -2.7778078816854213, 'default_policy/proxy_reward_min': -6.251396103067888, 'default_policy/proxy_reward_max': -1.6035533905932713, 'default_policy/modified_reward_mean': -3.9584956196684904, 'default_policy/modified_reward_min': -7.448826740574088, 'default_policy/modified_reward_max': -2.5409118076827633, 'default_policy/corr_btw_rewards_mean': 0.4087656162323728, 'default_policy/corr_btw_rewards_min': 0.1114130729140158, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -46.06580788168549, 'true_reward_min': -132.15639610306758, 'true_reward_max': -3.0256980515339555, 'proxy_reward_mean': -2.7778078816854213, 'proxy_reward_min': -6.251396103067888, 'proxy_reward_max': -1.6035533905932713, 'modified_reward_mean': -3.9584956196684904, 'modified_reward_min': -7.448826740574088, 'modified_reward_max': -2.5409118076827633, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004137823834196895, 'proxyInfectionSummaryAbsoluteReward_min': -0.0021865284974093282, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.08986569335157622, 'proxyLowerStageReward_min': -0.10830660410907779, 'proxyLowerStageReward_max': -0.06754162645561004, 'proxySmoothStageChangesReward_mean': -0.126839378238342, 'proxySmoothStageChangesReward_min': -0.23834196891191708, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004137823834196895, 'trueInfectionSummaryAbsoluteReward_min': -0.0021865284974093282, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.02242901554404146, 'truePoliticalReward_min': -0.06735751295336788, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.08986569335157622, 'trueLowerStageReward_min': -0.10830660410907779, 'trueLowerStageReward_max': -0.06754162645561004, 'trueSmoothStageChangesReward_mean': -0.126839378238342, 'trueSmoothStageChangesReward_min': -0.23834196891191708, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -3.9584956196684904, 'total_modified_reward_min': -7.448826740574088, 'total_modified_reward_max': -2.5409118076827633}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.112986013541619, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.030288507929071784, 'policy_loss': -0.0023959023350228867, 'vf_loss': 0.035027920719003305, 'vf_explained_var': 0.6114929020404816, 'kl': 0.0054384517566177714, 'entropy': 0.6096037614345551, 'entropy_coeff': 0.07498720000000002}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 10950.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 142820, 'num_env_steps_trained': 142820, 'num_agent_steps_sampled': 142820, 'num_agent_steps_trained': 142820}, 'sampler_results': {'episode_reward_max': -2.5409118076827633, 'episode_reward_min': -7.448826740574088, 'episode_reward_mean': -3.9584956196684904, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -46.06580788168549, 'default_policy/true_reward_min': -132.15639610306758, 'default_policy/true_reward_max': -3.0256980515339555, 'default_policy/proxy_reward_mean': -2.7778078816854213, 'default_policy/proxy_reward_min': -6.251396103067888, 'default_policy/proxy_reward_max': -1.6035533905932713, 'default_policy/modified_reward_mean': -3.9584956196684904, 'default_policy/modified_reward_min': -7.448826740574088, 'default_policy/modified_reward_max': -2.5409118076827633, 'default_policy/corr_btw_rewards_mean': 0.4087656162323728, 'default_policy/corr_btw_rewards_min': 0.1114130729140158, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -46.06580788168549, 'true_reward_min': -132.15639610306758, 'true_reward_max': -3.0256980515339555, 'proxy_reward_mean': -2.7778078816854213, 'proxy_reward_min': -6.251396103067888, 'proxy_reward_max': -1.6035533905932713, 'modified_reward_mean': -3.9584956196684904, 'modified_reward_min': -7.448826740574088, 'modified_reward_max': -2.5409118076827633, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004137823834196895, 'proxyInfectionSummaryAbsoluteReward_min': -0.0021865284974093282, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.08986569335157622, 'proxyLowerStageReward_min': -0.10830660410907779, 'proxyLowerStageReward_max': -0.06754162645561004, 'proxySmoothStageChangesReward_mean': -0.126839378238342, 'proxySmoothStageChangesReward_min': -0.23834196891191708, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004137823834196895, 'trueInfectionSummaryAbsoluteReward_min': -0.0021865284974093282, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.02242901554404146, 'truePoliticalReward_min': -0.06735751295336788, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.08986569335157622, 'trueLowerStageReward_min': -0.10830660410907779, 'trueLowerStageReward_max': -0.06754162645561004, 'trueSmoothStageChangesReward_mean': -0.126839378238342, 'trueSmoothStageChangesReward_min': -0.23834196891191708, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -3.9584956196684904, 'total_modified_reward_min': -7.448826740574088, 'total_modified_reward_max': -2.5409118076827633}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5379986281525849, 'mean_inference_ms': 1.6813496954691494, 'mean_action_processing_ms': 0.10742348016158534, 'mean_env_wait_ms': 778.5434580016148, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.5409118076827633, 'episode_reward_min': -7.448826740574088, 'episode_reward_mean': -3.9584956196684904, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5379986281525849, 'mean_inference_ms': 1.6813496954691494, 'mean_action_processing_ms': 0.10742348016158534, 'mean_env_wait_ms': 778.5434580016148, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 142820, 'num_agent_steps_trained': 142820, 'num_env_steps_sampled': 142820, 'num_env_steps_trained': 142820, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 11.132343688604019, 'num_env_steps_trained_throughput_per_sec': 11.132343688604019, 'timesteps_total': 142820, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 142820, 'timers': {'training_iteration_time_ms': 317862.636, 'sample_time_ms': 316831.289, 'load_time_ms': 5.559, 'load_throughput': 694430.128, 'learn_time_ms': 1009.839, 'learn_throughput': 3822.39, 'synch_weights_time_ms': 15.094}, 'counters': {'num_env_steps_sampled': 142820, 'num_env_steps_trained': 142820, 'num_agent_steps_sampled': 142820, 'num_agent_steps_trained': 142820}, 'done': False, 'episodes_total': 740, 'training_iteration': 37, 'trial_id': 'default', 'date': '2025-11-04_22-07-58', 'timestamp': 1762322878, 'time_this_iter_s': 346.7672200202942, 'time_total_s': 11705.325412511826, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6a9255cc0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e153d030>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e24fa710>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e24f8100>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 11705.325412511826, 'iterations_since_restore': 37, 'perf': {'cpu_util_percent': 18.612121212121213, 'ram_util_percent': 6.0}}
Iteration 38/100
{'custom_metrics': {'default_policy/true_reward_mean': -50.1568634732765, 'default_policy/true_reward_min': -132.15639610306758, 'default_policy/true_reward_max': -3.0256980515339555, 'default_policy/proxy_reward_mean': -2.820863473276443, 'default_policy/proxy_reward_min': -6.823172798364522, 'default_policy/proxy_reward_max': -1.6035533905932713, 'default_policy/modified_reward_mean': -4.000554551724502, 'default_policy/modified_reward_min': -8.168542177820125, 'default_policy/modified_reward_max': -2.5409118076827633, 'default_policy/corr_btw_rewards_mean': 0.4088123027936503, 'default_policy/corr_btw_rewards_min': 0.10628945587045867, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -50.1568634732765, 'true_reward_min': -132.15639610306758, 'true_reward_max': -3.0256980515339555, 'proxy_reward_mean': -2.820863473276443, 'proxy_reward_min': -6.823172798364522, 'proxy_reward_max': -1.6035533905932713, 'modified_reward_mean': -4.000554551724502, 'modified_reward_min': -8.168542177820125, 'modified_reward_max': -2.5409118076827633, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00044217616580310905, 'proxyInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.08865613851173278, 'proxyLowerStageReward_min': -0.10830660410907779, 'proxyLowerStageReward_max': -0.06754162645561004, 'proxySmoothStageChangesReward_mean': -0.13284974093264248, 'proxySmoothStageChangesReward_min': -0.23834196891191708, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.00044217616580310905, 'trueInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.02452642487046632, 'truePoliticalReward_min': -0.06735751295336788, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.08865613851173278, 'trueLowerStageReward_min': -0.10830660410907779, 'trueLowerStageReward_max': -0.06754162645561004, 'trueSmoothStageChangesReward_mean': -0.13284974093264248, 'trueSmoothStageChangesReward_min': -0.23834196891191708, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -4.000554551724502, 'total_modified_reward_min': -8.168542177820125, 'total_modified_reward_max': -2.5409118076827633}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.2312449044982592, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.019682354664740463, 'policy_loss': -0.00038813577964901924, 'vf_loss': 0.05743369239498861, 'vf_explained_var': 0.6128079265356063, 'kl': 0.006081385041123036, 'entropy': 0.6508490779002507, 'entropy_coeff': 0.07429240000000002}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 11250.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 146680, 'num_env_steps_trained': 146680, 'num_agent_steps_sampled': 146680, 'num_agent_steps_trained': 146680}, 'sampler_results': {'episode_reward_max': -2.5409118076827633, 'episode_reward_min': -8.168542177820125, 'episode_reward_mean': -4.000554551724502, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -50.1568634732765, 'default_policy/true_reward_min': -132.15639610306758, 'default_policy/true_reward_max': -3.0256980515339555, 'default_policy/proxy_reward_mean': -2.820863473276443, 'default_policy/proxy_reward_min': -6.823172798364522, 'default_policy/proxy_reward_max': -1.6035533905932713, 'default_policy/modified_reward_mean': -4.000554551724502, 'default_policy/modified_reward_min': -8.168542177820125, 'default_policy/modified_reward_max': -2.5409118076827633, 'default_policy/corr_btw_rewards_mean': 0.4088123027936503, 'default_policy/corr_btw_rewards_min': 0.10628945587045867, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -50.1568634732765, 'true_reward_min': -132.15639610306758, 'true_reward_max': -3.0256980515339555, 'proxy_reward_mean': -2.820863473276443, 'proxy_reward_min': -6.823172798364522, 'proxy_reward_max': -1.6035533905932713, 'modified_reward_mean': -4.000554551724502, 'modified_reward_min': -8.168542177820125, 'modified_reward_max': -2.5409118076827633, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00044217616580310905, 'proxyInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.08865613851173278, 'proxyLowerStageReward_min': -0.10830660410907779, 'proxyLowerStageReward_max': -0.06754162645561004, 'proxySmoothStageChangesReward_mean': -0.13284974093264248, 'proxySmoothStageChangesReward_min': -0.23834196891191708, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.00044217616580310905, 'trueInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.02452642487046632, 'truePoliticalReward_min': -0.06735751295336788, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.08865613851173278, 'trueLowerStageReward_min': -0.10830660410907779, 'trueLowerStageReward_max': -0.06754162645561004, 'trueSmoothStageChangesReward_mean': -0.13284974093264248, 'trueSmoothStageChangesReward_min': -0.23834196891191708, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -4.000554551724502, 'total_modified_reward_min': -8.168542177820125, 'total_modified_reward_max': -2.5409118076827633}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5370557934292751, 'mean_inference_ms': 1.681168305221682, 'mean_action_processing_ms': 0.1074099428399184, 'mean_env_wait_ms': 777.4045287163121, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.5409118076827633, 'episode_reward_min': -8.168542177820125, 'episode_reward_mean': -4.000554551724502, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5370557934292751, 'mean_inference_ms': 1.681168305221682, 'mean_action_processing_ms': 0.1074099428399184, 'mean_env_wait_ms': 777.4045287163121, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 146680, 'num_agent_steps_trained': 146680, 'num_env_steps_sampled': 146680, 'num_env_steps_trained': 146680, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 10.717734861590406, 'num_env_steps_trained_throughput_per_sec': 10.717734861590406, 'timesteps_total': 146680, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 146680, 'timers': {'training_iteration_time_ms': 323350.334, 'sample_time_ms': 322323.666, 'load_time_ms': 5.584, 'load_throughput': 691225.139, 'learn_time_ms': 1005.26, 'learn_throughput': 3839.802, 'synch_weights_time_ms': 14.994}, 'counters': {'num_env_steps_sampled': 146680, 'num_env_steps_trained': 146680, 'num_agent_steps_sampled': 146680, 'num_agent_steps_trained': 146680}, 'done': False, 'episodes_total': 760, 'training_iteration': 38, 'trial_id': 'default', 'date': '2025-11-04_22-13-58', 'timestamp': 1762323238, 'time_this_iter_s': 360.16812467575073, 'time_total_s': 12065.493537187576, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e17799c0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e177ac80>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e177a6e0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e177a980>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 12065.493537187576, 'iterations_since_restore': 38, 'perf': {'cpu_util_percent': 17.4220703125, 'ram_util_percent': 6.0}}
Iteration 39/100
{'custom_metrics': {'default_policy/true_reward_mean': -50.51685548263439, 'default_policy/true_reward_min': -132.15639610306758, 'default_policy/true_reward_max': -5.255685424949247, 'default_policy/proxy_reward_mean': -2.8008554826343266, 'default_policy/proxy_reward_min': -6.823172798364522, 'default_policy/proxy_reward_max': -1.6035533905932713, 'default_policy/modified_reward_mean': -3.983644245736968, 'default_policy/modified_reward_min': -8.168542177820125, 'default_policy/modified_reward_max': -2.5409118076827633, 'default_policy/corr_btw_rewards_mean': 0.3963972078600866, 'default_policy/corr_btw_rewards_min': 0.10628945587045867, 'default_policy/corr_btw_rewards_max': 0.7250903237635894, 'true_reward_mean': -50.51685548263439, 'true_reward_min': -132.15639610306758, 'true_reward_max': -5.255685424949247, 'proxy_reward_mean': -2.8008554826343266, 'proxy_reward_min': -6.823172798364522, 'proxy_reward_max': -1.6035533905932713, 'modified_reward_mean': -3.983644245736968, 'modified_reward_min': -8.168542177820125, 'modified_reward_max': -2.5409118076827633, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004313989637305702, 'proxyInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.08839665713131226, 'proxyLowerStageReward_min': -0.10830660410907779, 'proxyLowerStageReward_max': -0.06754162645561004, 'proxySmoothStageChangesReward_mean': -0.13585492227979276, 'proxySmoothStageChangesReward_min': -0.23834196891191708, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004313989637305702, 'trueInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.024723316062176162, 'truePoliticalReward_min': -0.06735751295336788, 'truePoliticalReward_max': -0.0012435233160621765, 'trueLowerStageReward_mean': -0.08839665713131226, 'trueLowerStageReward_min': -0.10830660410907779, 'trueLowerStageReward_max': -0.06754162645561004, 'trueSmoothStageChangesReward_mean': -0.13585492227979276, 'trueSmoothStageChangesReward_min': -0.23834196891191708, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -3.983644245736968, 'total_modified_reward_min': -8.168542177820125, 'total_modified_reward_max': -2.5409118076827633}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.1534737562388182, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.03367331085416178, 'policy_loss': -0.005438845197980603, 'vf_loss': 0.041921550524032986, 'vf_explained_var': 0.5271145461002985, 'kl': 0.008119979014104679, 'entropy': 0.6746413920323054, 'entropy_coeff': 0.07359760000000001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 11550.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 150540, 'num_env_steps_trained': 150540, 'num_agent_steps_sampled': 150540, 'num_agent_steps_trained': 150540}, 'sampler_results': {'episode_reward_max': -2.5409118076827633, 'episode_reward_min': -8.168542177820125, 'episode_reward_mean': -3.983644245736968, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -50.51685548263439, 'default_policy/true_reward_min': -132.15639610306758, 'default_policy/true_reward_max': -5.255685424949247, 'default_policy/proxy_reward_mean': -2.8008554826343266, 'default_policy/proxy_reward_min': -6.823172798364522, 'default_policy/proxy_reward_max': -1.6035533905932713, 'default_policy/modified_reward_mean': -3.983644245736968, 'default_policy/modified_reward_min': -8.168542177820125, 'default_policy/modified_reward_max': -2.5409118076827633, 'default_policy/corr_btw_rewards_mean': 0.3963972078600866, 'default_policy/corr_btw_rewards_min': 0.10628945587045867, 'default_policy/corr_btw_rewards_max': 0.7250903237635894, 'true_reward_mean': -50.51685548263439, 'true_reward_min': -132.15639610306758, 'true_reward_max': -5.255685424949247, 'proxy_reward_mean': -2.8008554826343266, 'proxy_reward_min': -6.823172798364522, 'proxy_reward_max': -1.6035533905932713, 'modified_reward_mean': -3.983644245736968, 'modified_reward_min': -8.168542177820125, 'modified_reward_max': -2.5409118076827633, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004313989637305702, 'proxyInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.08839665713131226, 'proxyLowerStageReward_min': -0.10830660410907779, 'proxyLowerStageReward_max': -0.06754162645561004, 'proxySmoothStageChangesReward_mean': -0.13585492227979276, 'proxySmoothStageChangesReward_min': -0.23834196891191708, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004313989637305702, 'trueInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.024723316062176162, 'truePoliticalReward_min': -0.06735751295336788, 'truePoliticalReward_max': -0.0012435233160621765, 'trueLowerStageReward_mean': -0.08839665713131226, 'trueLowerStageReward_min': -0.10830660410907779, 'trueLowerStageReward_max': -0.06754162645561004, 'trueSmoothStageChangesReward_mean': -0.13585492227979276, 'trueSmoothStageChangesReward_min': -0.23834196891191708, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -3.983644245736968, 'total_modified_reward_min': -8.168542177820125, 'total_modified_reward_max': -2.5409118076827633}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.536127961813189, 'mean_inference_ms': 1.6809448623373187, 'mean_action_processing_ms': 0.10739615419998583, 'mean_env_wait_ms': 776.2560905912495, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.5409118076827633, 'episode_reward_min': -8.168542177820125, 'episode_reward_mean': -3.983644245736968, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.536127961813189, 'mean_inference_ms': 1.6809448623373187, 'mean_action_processing_ms': 0.10739615419998583, 'mean_env_wait_ms': 776.2560905912495, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 150540, 'num_agent_steps_trained': 150540, 'num_env_steps_sampled': 150540, 'num_env_steps_trained': 150540, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 11.173152179001374, 'num_env_steps_trained_throughput_per_sec': 11.173152179001374, 'timesteps_total': 150540, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 150540, 'timers': {'training_iteration_time_ms': 327213.753, 'sample_time_ms': 326187.953, 'load_time_ms': 5.754, 'load_throughput': 670855.057, 'learn_time_ms': 1004.184, 'learn_throughput': 3843.916, 'synch_weights_time_ms': 15.075}, 'counters': {'num_env_steps_sampled': 150540, 'num_env_steps_trained': 150540, 'num_agent_steps_sampled': 150540, 'num_agent_steps_trained': 150540}, 'done': False, 'episodes_total': 780, 'training_iteration': 39, 'trial_id': 'default', 'date': '2025-11-04_22-19-44', 'timestamp': 1762323584, 'time_this_iter_s': 345.50890040397644, 'time_total_s': 12411.002437591553, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e2511a50>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6995378b0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2511db0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e25103a0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 12411.002437591553, 'iterations_since_restore': 39, 'perf': {'cpu_util_percent': 17.750912778904667, 'ram_util_percent': 6.0}}
Iteration 40/100
{'custom_metrics': {'default_policy/true_reward_mean': -55.06166855980414, 'default_policy/true_reward_min': -156.1399621202457, 'default_policy/true_reward_max': -5.6471067811865545, 'default_policy/proxy_reward_mean': -2.7856685598040754, 'default_policy/proxy_reward_min': -6.823172798364522, 'default_policy/proxy_reward_max': -1.6035533905932713, 'default_policy/modified_reward_mean': -3.9810316678274025, 'default_policy/modified_reward_min': -8.168542177820125, 'default_policy/modified_reward_max': -2.5409118076827633, 'default_policy/corr_btw_rewards_mean': 0.40700410225674766, 'default_policy/corr_btw_rewards_min': 0.10628945587045867, 'default_policy/corr_btw_rewards_max': 0.7399894488596913, 'true_reward_mean': -55.06166855980414, 'true_reward_min': -156.1399621202457, 'true_reward_max': -5.6471067811865545, 'proxy_reward_mean': -2.7856685598040754, 'proxy_reward_min': -6.823172798364522, 'proxy_reward_max': -1.6035533905932713, 'modified_reward_mean': -3.9810316678274025, 'modified_reward_min': -8.168542177820125, 'modified_reward_max': -2.5409118076827633, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004141968911917101, 'proxyInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.089008733668605, 'proxyLowerStageReward_min': -0.10937969623957805, 'proxyLowerStageReward_max': -0.06754162645561004, 'proxySmoothStageChangesReward_mean': -0.1390673575129534, 'proxySmoothStageChangesReward_min': -0.20725388601036268, 'proxySmoothStageChangesReward_max': -0.07253886010362694, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004141968911917101, 'trueInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.027086010362694302, 'truePoliticalReward_min': -0.07958549222797927, 'truePoliticalReward_max': -0.0012435233160621765, 'trueLowerStageReward_mean': -0.089008733668605, 'trueLowerStageReward_min': -0.10937969623957805, 'trueLowerStageReward_max': -0.06754162645561004, 'trueSmoothStageChangesReward_mean': -0.1390673575129534, 'trueSmoothStageChangesReward_min': -0.20725388601036268, 'trueSmoothStageChangesReward_max': -0.07253886010362694, 'total_modified_reward_mean': -3.9810316678274025, 'total_modified_reward_min': -8.168542177820125, 'total_modified_reward_max': -2.5409118076827633}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9589451331396898, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.043228100322400376, 'policy_loss': -0.0069385299024482565, 'vf_loss': 0.025547028496318187, 'vf_explained_var': 0.667730049888293, 'kl': 0.008143860595161504, 'entropy': 0.6792767443259558, 'entropy_coeff': 0.0729028}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 11850.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 154400, 'num_env_steps_trained': 154400, 'num_agent_steps_sampled': 154400, 'num_agent_steps_trained': 154400}, 'sampler_results': {'episode_reward_max': -2.5409118076827633, 'episode_reward_min': -8.168542177820125, 'episode_reward_mean': -3.9810316678274025, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -55.06166855980414, 'default_policy/true_reward_min': -156.1399621202457, 'default_policy/true_reward_max': -5.6471067811865545, 'default_policy/proxy_reward_mean': -2.7856685598040754, 'default_policy/proxy_reward_min': -6.823172798364522, 'default_policy/proxy_reward_max': -1.6035533905932713, 'default_policy/modified_reward_mean': -3.9810316678274025, 'default_policy/modified_reward_min': -8.168542177820125, 'default_policy/modified_reward_max': -2.5409118076827633, 'default_policy/corr_btw_rewards_mean': 0.40700410225674766, 'default_policy/corr_btw_rewards_min': 0.10628945587045867, 'default_policy/corr_btw_rewards_max': 0.7399894488596913, 'true_reward_mean': -55.06166855980414, 'true_reward_min': -156.1399621202457, 'true_reward_max': -5.6471067811865545, 'proxy_reward_mean': -2.7856685598040754, 'proxy_reward_min': -6.823172798364522, 'proxy_reward_max': -1.6035533905932713, 'modified_reward_mean': -3.9810316678274025, 'modified_reward_min': -8.168542177820125, 'modified_reward_max': -2.5409118076827633, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004141968911917101, 'proxyInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.089008733668605, 'proxyLowerStageReward_min': -0.10937969623957805, 'proxyLowerStageReward_max': -0.06754162645561004, 'proxySmoothStageChangesReward_mean': -0.1390673575129534, 'proxySmoothStageChangesReward_min': -0.20725388601036268, 'proxySmoothStageChangesReward_max': -0.07253886010362694, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004141968911917101, 'trueInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.027086010362694302, 'truePoliticalReward_min': -0.07958549222797927, 'truePoliticalReward_max': -0.0012435233160621765, 'trueLowerStageReward_mean': -0.089008733668605, 'trueLowerStageReward_min': -0.10937969623957805, 'trueLowerStageReward_max': -0.06754162645561004, 'trueSmoothStageChangesReward_mean': -0.1390673575129534, 'trueSmoothStageChangesReward_min': -0.20725388601036268, 'trueSmoothStageChangesReward_max': -0.07253886010362694, 'total_modified_reward_mean': -3.9810316678274025, 'total_modified_reward_min': -8.168542177820125, 'total_modified_reward_max': -2.5409118076827633}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5353370304077864, 'mean_inference_ms': 1.681037194457665, 'mean_action_processing_ms': 0.10740321563043491, 'mean_env_wait_ms': 775.2920463436699, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.5409118076827633, 'episode_reward_min': -8.168542177820125, 'episode_reward_mean': -3.9810316678274025, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5353370304077864, 'mean_inference_ms': 1.681037194457665, 'mean_action_processing_ms': 0.10740321563043491, 'mean_env_wait_ms': 775.2920463436699, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 154400, 'num_agent_steps_trained': 154400, 'num_env_steps_sampled': 154400, 'num_env_steps_trained': 154400, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 11.177368407993061, 'num_env_steps_trained_throughput_per_sec': 11.177368407993061, 'timesteps_total': 154400, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 154400, 'timers': {'training_iteration_time_ms': 331516.038, 'sample_time_ms': 330510.715, 'load_time_ms': 5.424, 'load_throughput': 711705.253, 'learn_time_ms': 984.101, 'learn_throughput': 3922.362, 'synch_weights_time_ms': 15.027}, 'counters': {'num_env_steps_sampled': 154400, 'num_env_steps_trained': 154400, 'num_agent_steps_sampled': 154400, 'num_agent_steps_trained': 154400}, 'done': False, 'episodes_total': 800, 'training_iteration': 40, 'trial_id': 'default', 'date': '2025-11-04_22-25-29', 'timestamp': 1762323929, 'time_this_iter_s': 345.35941195487976, 'time_total_s': 12756.361849546432, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6a92057b0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6a9205ae0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6a92051e0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6a9206410>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 12756.361849546432, 'iterations_since_restore': 40, 'perf': {'cpu_util_percent': 18.399593495934962, 'ram_util_percent': 6.048983739837398}}
Saved checkpoint to TrainingResult(checkpoint=Checkpoint(filesystem=local, path=logs/data/pandemic/20251104_185246/checkpoint_40), metrics={'custom_metrics': {'default_policy/true_reward_mean': -55.06166855980414, 'default_policy/true_reward_min': -156.1399621202457, 'default_policy/true_reward_max': -5.6471067811865545, 'default_policy/proxy_reward_mean': -2.7856685598040754, 'default_policy/proxy_reward_min': -6.823172798364522, 'default_policy/proxy_reward_max': -1.6035533905932713, 'default_policy/modified_reward_mean': -3.9810316678274025, 'default_policy/modified_reward_min': -8.168542177820125, 'default_policy/modified_reward_max': -2.5409118076827633, 'default_policy/corr_btw_rewards_mean': 0.40700410225674766, 'default_policy/corr_btw_rewards_min': 0.10628945587045867, 'default_policy/corr_btw_rewards_max': 0.7399894488596913, 'true_reward_mean': -55.06166855980414, 'true_reward_min': -156.1399621202457, 'true_reward_max': -5.6471067811865545, 'proxy_reward_mean': -2.7856685598040754, 'proxy_reward_min': -6.823172798364522, 'proxy_reward_max': -1.6035533905932713, 'modified_reward_mean': -3.9810316678274025, 'modified_reward_min': -8.168542177820125, 'modified_reward_max': -2.5409118076827633, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004141968911917101, 'proxyInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.089008733668605, 'proxyLowerStageReward_min': -0.10937969623957805, 'proxyLowerStageReward_max': -0.06754162645561004, 'proxySmoothStageChangesReward_mean': -0.1390673575129534, 'proxySmoothStageChangesReward_min': -0.20725388601036268, 'proxySmoothStageChangesReward_max': -0.07253886010362694, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004141968911917101, 'trueInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.027086010362694302, 'truePoliticalReward_min': -0.07958549222797927, 'truePoliticalReward_max': -0.0012435233160621765, 'trueLowerStageReward_mean': -0.089008733668605, 'trueLowerStageReward_min': -0.10937969623957805, 'trueLowerStageReward_max': -0.06754162645561004, 'trueSmoothStageChangesReward_mean': -0.1390673575129534, 'trueSmoothStageChangesReward_min': -0.20725388601036268, 'trueSmoothStageChangesReward_max': -0.07253886010362694, 'total_modified_reward_mean': -3.9810316678274025, 'total_modified_reward_min': -8.168542177820125, 'total_modified_reward_max': -2.5409118076827633}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9589451331396898, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.043228100322400376, 'policy_loss': -0.0069385299024482565, 'vf_loss': 0.025547028496318187, 'vf_explained_var': 0.667730049888293, 'kl': 0.008143860595161504, 'entropy': 0.6792767443259558, 'entropy_coeff': 0.0729028}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 11850.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 154400, 'num_env_steps_trained': 154400, 'num_agent_steps_sampled': 154400, 'num_agent_steps_trained': 154400}, 'sampler_results': {'episode_reward_max': -2.5409118076827633, 'episode_reward_min': -8.168542177820125, 'episode_reward_mean': -3.9810316678274025, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -55.06166855980414, 'default_policy/true_reward_min': -156.1399621202457, 'default_policy/true_reward_max': -5.6471067811865545, 'default_policy/proxy_reward_mean': -2.7856685598040754, 'default_policy/proxy_reward_min': -6.823172798364522, 'default_policy/proxy_reward_max': -1.6035533905932713, 'default_policy/modified_reward_mean': -3.9810316678274025, 'default_policy/modified_reward_min': -8.168542177820125, 'default_policy/modified_reward_max': -2.5409118076827633, 'default_policy/corr_btw_rewards_mean': 0.40700410225674766, 'default_policy/corr_btw_rewards_min': 0.10628945587045867, 'default_policy/corr_btw_rewards_max': 0.7399894488596913, 'true_reward_mean': -55.06166855980414, 'true_reward_min': -156.1399621202457, 'true_reward_max': -5.6471067811865545, 'proxy_reward_mean': -2.7856685598040754, 'proxy_reward_min': -6.823172798364522, 'proxy_reward_max': -1.6035533905932713, 'modified_reward_mean': -3.9810316678274025, 'modified_reward_min': -8.168542177820125, 'modified_reward_max': -2.5409118076827633, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004141968911917101, 'proxyInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.089008733668605, 'proxyLowerStageReward_min': -0.10937969623957805, 'proxyLowerStageReward_max': -0.06754162645561004, 'proxySmoothStageChangesReward_mean': -0.1390673575129534, 'proxySmoothStageChangesReward_min': -0.20725388601036268, 'proxySmoothStageChangesReward_max': -0.07253886010362694, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004141968911917101, 'trueInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.027086010362694302, 'truePoliticalReward_min': -0.07958549222797927, 'truePoliticalReward_max': -0.0012435233160621765, 'trueLowerStageReward_mean': -0.089008733668605, 'trueLowerStageReward_min': -0.10937969623957805, 'trueLowerStageReward_max': -0.06754162645561004, 'trueSmoothStageChangesReward_mean': -0.1390673575129534, 'trueSmoothStageChangesReward_min': -0.20725388601036268, 'trueSmoothStageChangesReward_max': -0.07253886010362694, 'total_modified_reward_mean': -3.9810316678274025, 'total_modified_reward_min': -8.168542177820125, 'total_modified_reward_max': -2.5409118076827633}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5353370304077864, 'mean_inference_ms': 1.681037194457665, 'mean_action_processing_ms': 0.10740321563043491, 'mean_env_wait_ms': 775.2920463436699, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.5409118076827633, 'episode_reward_min': -8.168542177820125, 'episode_reward_mean': -3.9810316678274025, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5353370304077864, 'mean_inference_ms': 1.681037194457665, 'mean_action_processing_ms': 0.10740321563043491, 'mean_env_wait_ms': 775.2920463436699, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 154400, 'num_agent_steps_trained': 154400, 'num_env_steps_sampled': 154400, 'num_env_steps_trained': 154400, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 11.177368407993061, 'num_env_steps_trained_throughput_per_sec': 11.177368407993061, 'timesteps_total': 154400, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 154400, 'timers': {'training_iteration_time_ms': 331516.038, 'sample_time_ms': 330510.715, 'load_time_ms': 5.424, 'load_throughput': 711705.253, 'learn_time_ms': 984.101, 'learn_throughput': 3922.362, 'synch_weights_time_ms': 15.027}, 'counters': {'num_env_steps_sampled': 154400, 'num_env_steps_trained': 154400, 'num_agent_steps_sampled': 154400, 'num_agent_steps_trained': 154400}, 'done': False, 'episodes_total': 800, 'training_iteration': 40, 'trial_id': 'default', 'date': '2025-11-04_22-25-29', 'timestamp': 1762323929, 'time_this_iter_s': 345.35941195487976, 'time_total_s': 12756.361849546432, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6a92057b0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6a9205ae0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6a92051e0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6a9206410>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 12756.361849546432, 'iterations_since_restore': 40, 'perf': {'cpu_util_percent': 18.399593495934962, 'ram_util_percent': 6.048983739837398}})
Iteration 41/100
{'custom_metrics': {'default_policy/true_reward_mean': -61.069311200491256, 'default_policy/true_reward_min': -170.68031745930475, 'default_policy/true_reward_max': -2.58283008588991, 'default_policy/proxy_reward_mean': -2.7533112004911953, 'default_policy/proxy_reward_min': -6.823172798364522, 'default_policy/proxy_reward_max': -1.6035533905932713, 'default_policy/modified_reward_mean': -3.969755654831604, 'default_policy/modified_reward_min': -8.168542177820125, 'default_policy/modified_reward_max': -2.5409118076827633, 'default_policy/corr_btw_rewards_mean': 0.44009975630812775, 'default_policy/corr_btw_rewards_min': 0.10628945587045867, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -61.069311200491256, 'true_reward_min': -170.68031745930475, 'true_reward_max': -2.58283008588991, 'proxy_reward_mean': -2.7533112004911953, 'proxy_reward_min': -6.823172798364522, 'proxy_reward_max': -1.6035533905932713, 'modified_reward_mean': -3.969755654831604, 'modified_reward_min': -8.168542177820125, 'modified_reward_max': -2.5409118076827633, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003807253886010365, 'proxyInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09026482904099456, 'proxyLowerStageReward_min': -0.11013848696189268, 'proxyLowerStageReward_max': -0.06754162645561004, 'proxySmoothStageChangesReward_mean': -0.14321243523316066, 'proxySmoothStageChangesReward_min': -0.21761658031088082, 'proxySmoothStageChangesReward_max': -0.08290155440414508, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003807253886010365, 'trueInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.03021554404145078, 'truePoliticalReward_min': -0.08704663212435232, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09026482904099456, 'trueLowerStageReward_min': -0.11013848696189268, 'trueLowerStageReward_max': -0.06754162645561004, 'trueSmoothStageChangesReward_mean': -0.14321243523316066, 'trueSmoothStageChangesReward_min': -0.21761658031088082, 'trueSmoothStageChangesReward_max': -0.08290155440414508, 'total_modified_reward_mean': -3.969755654831604, 'total_modified_reward_min': -8.168542177820125, 'total_modified_reward_max': -2.5409118076827633}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0070588798324267, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.04026744657972207, 'policy_loss': -0.003599646089908977, 'vf_loss': 0.02155708610235403, 'vf_explained_var': 0.7602671813964844, 'kl': 0.006247278335102749, 'entropy': 0.6619452826182047, 'entropy_coeff': 0.072208}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 12150.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 158260, 'num_env_steps_trained': 158260, 'num_agent_steps_sampled': 158260, 'num_agent_steps_trained': 158260}, 'sampler_results': {'episode_reward_max': -2.5409118076827633, 'episode_reward_min': -8.168542177820125, 'episode_reward_mean': -3.969755654831604, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -61.069311200491256, 'default_policy/true_reward_min': -170.68031745930475, 'default_policy/true_reward_max': -2.58283008588991, 'default_policy/proxy_reward_mean': -2.7533112004911953, 'default_policy/proxy_reward_min': -6.823172798364522, 'default_policy/proxy_reward_max': -1.6035533905932713, 'default_policy/modified_reward_mean': -3.969755654831604, 'default_policy/modified_reward_min': -8.168542177820125, 'default_policy/modified_reward_max': -2.5409118076827633, 'default_policy/corr_btw_rewards_mean': 0.44009975630812775, 'default_policy/corr_btw_rewards_min': 0.10628945587045867, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -61.069311200491256, 'true_reward_min': -170.68031745930475, 'true_reward_max': -2.58283008588991, 'proxy_reward_mean': -2.7533112004911953, 'proxy_reward_min': -6.823172798364522, 'proxy_reward_max': -1.6035533905932713, 'modified_reward_mean': -3.969755654831604, 'modified_reward_min': -8.168542177820125, 'modified_reward_max': -2.5409118076827633, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003807253886010365, 'proxyInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09026482904099456, 'proxyLowerStageReward_min': -0.11013848696189268, 'proxyLowerStageReward_max': -0.06754162645561004, 'proxySmoothStageChangesReward_mean': -0.14321243523316066, 'proxySmoothStageChangesReward_min': -0.21761658031088082, 'proxySmoothStageChangesReward_max': -0.08290155440414508, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003807253886010365, 'trueInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.03021554404145078, 'truePoliticalReward_min': -0.08704663212435232, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09026482904099456, 'trueLowerStageReward_min': -0.11013848696189268, 'trueLowerStageReward_max': -0.06754162645561004, 'trueSmoothStageChangesReward_mean': -0.14321243523316066, 'trueSmoothStageChangesReward_min': -0.21761658031088082, 'trueSmoothStageChangesReward_max': -0.08290155440414508, 'total_modified_reward_mean': -3.969755654831604, 'total_modified_reward_min': -8.168542177820125, 'total_modified_reward_max': -2.5409118076827633}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5347501880661228, 'mean_inference_ms': 1.6810365048709328, 'mean_action_processing_ms': 0.10740106362684976, 'mean_env_wait_ms': 774.3329207245652, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.5409118076827633, 'episode_reward_min': -8.168542177820125, 'episode_reward_mean': -3.969755654831604, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5347501880661228, 'mean_inference_ms': 1.6810365048709328, 'mean_action_processing_ms': 0.10740106362684976, 'mean_env_wait_ms': 774.3329207245652, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 158260, 'num_agent_steps_trained': 158260, 'num_env_steps_sampled': 158260, 'num_env_steps_trained': 158260, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 11.896413104220139, 'num_env_steps_trained_throughput_per_sec': 11.896413104220139, 'timesteps_total': 158260, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 158260, 'timers': {'training_iteration_time_ms': 333360.842, 'sample_time_ms': 332353.67, 'load_time_ms': 5.341, 'load_throughput': 722665.219, 'learn_time_ms': 986.028, 'learn_throughput': 3914.697, 'synch_weights_time_ms': 15.028}, 'counters': {'num_env_steps_sampled': 158260, 'num_env_steps_trained': 158260, 'num_agent_steps_sampled': 158260, 'num_agent_steps_trained': 158260}, 'done': False, 'episodes_total': 820, 'training_iteration': 41, 'trial_id': 'default', 'date': '2025-11-04_22-30-54', 'timestamp': 1762324254, 'time_this_iter_s': 324.492636680603, 'time_total_s': 13080.854486227036, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a699536620>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699537c10>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e25104f0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e25125c0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 13080.854486227036, 'iterations_since_restore': 41, 'perf': {'cpu_util_percent': 18.91857451403888, 'ram_util_percent': 6.021166306695465}}
Iteration 42/100
{'custom_metrics': {'default_policy/true_reward_mean': -59.58856944366506, 'default_policy/true_reward_min': -170.68031745930475, 'default_policy/true_reward_max': -2.58283008588991, 'default_policy/proxy_reward_mean': -2.732569443665006, 'default_policy/proxy_reward_min': -6.823172798364522, 'default_policy/proxy_reward_max': -1.6167640687119262, 'default_policy/modified_reward_mean': -3.955414545445464, 'default_policy/modified_reward_min': -8.168542177820125, 'default_policy/modified_reward_max': -2.5720429915541647, 'default_policy/corr_btw_rewards_mean': 0.4527747910129267, 'default_policy/corr_btw_rewards_min': 0.10628945587045867, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -59.58856944366506, 'true_reward_min': -170.68031745930475, 'true_reward_max': -2.58283008588991, 'proxy_reward_mean': -2.732569443665006, 'proxy_reward_min': -6.823172798364522, 'proxy_reward_max': -1.6167640687119262, 'modified_reward_mean': -3.955414545445464, 'modified_reward_min': -8.168542177820125, 'modified_reward_max': -2.5720429915541647, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00036020725388601055, 'proxyInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09166681055259092, 'proxyLowerStageReward_min': -0.11574525784886962, 'proxyLowerStageReward_max': -0.07120539216123982, 'proxySmoothStageChangesReward_mean': -0.13896373056994818, 'proxySmoothStageChangesReward_min': -0.21761658031088082, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.00036020725388601055, 'trueInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.02945906735751295, 'truePoliticalReward_min': -0.08704663212435232, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09166681055259092, 'trueLowerStageReward_min': -0.11574525784886962, 'trueLowerStageReward_max': -0.07120539216123982, 'trueSmoothStageChangesReward_mean': -0.13896373056994818, 'trueSmoothStageChangesReward_min': -0.21761658031088082, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -3.955414545445464, 'total_modified_reward_min': -8.168542177820125, 'total_modified_reward_max': -2.5720429915541647}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9123538802564144, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.04898375399721166, 'policy_loss': -0.013565430718784532, 'vf_loss': 0.01949053987385317, 'vf_explained_var': 0.8328160472710927, 'kl': 0.010715302169272368, 'entropy': 0.6399703774849573, 'entropy_coeff': 0.07151320000000001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 12450.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 162120, 'num_env_steps_trained': 162120, 'num_agent_steps_sampled': 162120, 'num_agent_steps_trained': 162120}, 'sampler_results': {'episode_reward_max': -2.5720429915541647, 'episode_reward_min': -8.168542177820125, 'episode_reward_mean': -3.955414545445464, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -59.58856944366506, 'default_policy/true_reward_min': -170.68031745930475, 'default_policy/true_reward_max': -2.58283008588991, 'default_policy/proxy_reward_mean': -2.732569443665006, 'default_policy/proxy_reward_min': -6.823172798364522, 'default_policy/proxy_reward_max': -1.6167640687119262, 'default_policy/modified_reward_mean': -3.955414545445464, 'default_policy/modified_reward_min': -8.168542177820125, 'default_policy/modified_reward_max': -2.5720429915541647, 'default_policy/corr_btw_rewards_mean': 0.4527747910129267, 'default_policy/corr_btw_rewards_min': 0.10628945587045867, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -59.58856944366506, 'true_reward_min': -170.68031745930475, 'true_reward_max': -2.58283008588991, 'proxy_reward_mean': -2.732569443665006, 'proxy_reward_min': -6.823172798364522, 'proxy_reward_max': -1.6167640687119262, 'modified_reward_mean': -3.955414545445464, 'modified_reward_min': -8.168542177820125, 'modified_reward_max': -2.5720429915541647, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00036020725388601055, 'proxyInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09166681055259092, 'proxyLowerStageReward_min': -0.11574525784886962, 'proxyLowerStageReward_max': -0.07120539216123982, 'proxySmoothStageChangesReward_mean': -0.13896373056994818, 'proxySmoothStageChangesReward_min': -0.21761658031088082, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.00036020725388601055, 'trueInfectionSummaryAbsoluteReward_min': -0.0023937823834196906, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.02945906735751295, 'truePoliticalReward_min': -0.08704663212435232, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09166681055259092, 'trueLowerStageReward_min': -0.11574525784886962, 'trueLowerStageReward_max': -0.07120539216123982, 'trueSmoothStageChangesReward_mean': -0.13896373056994818, 'trueSmoothStageChangesReward_min': -0.21761658031088082, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -3.955414545445464, 'total_modified_reward_min': -8.168542177820125, 'total_modified_reward_max': -2.5720429915541647}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5341095887676356, 'mean_inference_ms': 1.6807959103359764, 'mean_action_processing_ms': 0.10739387743248269, 'mean_env_wait_ms': 773.3338160431899, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.5720429915541647, 'episode_reward_min': -8.168542177820125, 'episode_reward_mean': -3.955414545445464, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5341095887676356, 'mean_inference_ms': 1.6807959103359764, 'mean_action_processing_ms': 0.10739387743248269, 'mean_env_wait_ms': 773.3338160431899, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 162120, 'num_agent_steps_trained': 162120, 'num_env_steps_sampled': 162120, 'num_env_steps_trained': 162120, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 11.902493653131023, 'num_env_steps_trained_throughput_per_sec': 11.902493653131023, 'timesteps_total': 162120, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 162120, 'timers': {'training_iteration_time_ms': 334770.011, 'sample_time_ms': 333764.722, 'load_time_ms': 5.168, 'load_throughput': 746885.524, 'learn_time_ms': 984.555, 'learn_throughput': 3920.554, 'synch_weights_time_ms': 14.83}, 'counters': {'num_env_steps_sampled': 162120, 'num_env_steps_trained': 162120, 'num_agent_steps_sampled': 162120, 'num_agent_steps_trained': 162120}, 'done': False, 'episodes_total': 840, 'training_iteration': 42, 'trial_id': 'default', 'date': '2025-11-04_22-36-18', 'timestamp': 1762324578, 'time_this_iter_s': 324.3203673362732, 'time_total_s': 13405.174853563309, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6995600d0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699562500>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699562620>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699561d20>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 13405.174853563309, 'iterations_since_restore': 42, 'perf': {'cpu_util_percent': 18.43311688311688, 'ram_util_percent': 6.0242424242424235}}
Iteration 43/100
{'custom_metrics': {'default_policy/true_reward_mean': -57.17921284194726, 'default_policy/true_reward_min': -170.68031745930475, 'default_policy/true_reward_max': -2.58283008588991, 'default_policy/proxy_reward_mean': -2.6992128419472086, 'default_policy/proxy_reward_min': -4.6321067811865575, 'default_policy/proxy_reward_max': -1.7803427124746158, 'default_policy/modified_reward_mean': -3.9362575355415395, 'default_policy/modified_reward_min': -5.904578751827746, 'default_policy/modified_reward_max': -2.7946808032711115, 'default_policy/corr_btw_rewards_mean': 0.45320462695144315, 'default_policy/corr_btw_rewards_min': 0.12628299343681942, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -57.17921284194726, 'true_reward_min': -170.68031745930475, 'true_reward_max': -2.58283008588991, 'proxy_reward_mean': -2.6992128419472086, 'proxy_reward_min': -4.6321067811865575, 'proxy_reward_max': -1.7803427124746158, 'modified_reward_mean': -3.9362575355415395, 'modified_reward_min': -5.904578751827746, 'modified_reward_max': -2.7946808032711115, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003308808290155443, 'proxyInfectionSummaryAbsoluteReward_min': -0.0013160621761658037, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09268460320969985, 'proxyLowerStageReward_min': -0.11574525784886962, 'proxyLowerStageReward_max': -0.07120539216123982, 'proxySmoothStageChangesReward_mean': -0.14082901554404145, 'proxySmoothStageChangesReward_min': -0.21761658031088082, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003308808290155443, 'trueInfectionSummaryAbsoluteReward_min': -0.0013160621761658037, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.0282279792746114, 'truePoliticalReward_min': -0.08704663212435232, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09268460320969985, 'trueLowerStageReward_min': -0.11574525784886962, 'trueLowerStageReward_max': -0.07120539216123982, 'trueSmoothStageChangesReward_mean': -0.14082901554404145, 'trueSmoothStageChangesReward_min': -0.21761658031088082, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -3.9362575355415395, 'total_modified_reward_min': -5.904578751827746, 'total_modified_reward_max': -2.7946808032711115}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.09547523299853, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.03943334935232997, 'policy_loss': -0.00615376361956199, 'vf_loss': 0.02490850241893592, 'vf_explained_var': 0.6554271487394968, 'kl': 0.009036618930552028, 'entropy': 0.6529679679870606, 'entropy_coeff': 0.07081840000000002}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 12750.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 165980, 'num_env_steps_trained': 165980, 'num_agent_steps_sampled': 165980, 'num_agent_steps_trained': 165980}, 'sampler_results': {'episode_reward_max': -2.7946808032711115, 'episode_reward_min': -5.904578751827746, 'episode_reward_mean': -3.9362575355415395, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -57.17921284194726, 'default_policy/true_reward_min': -170.68031745930475, 'default_policy/true_reward_max': -2.58283008588991, 'default_policy/proxy_reward_mean': -2.6992128419472086, 'default_policy/proxy_reward_min': -4.6321067811865575, 'default_policy/proxy_reward_max': -1.7803427124746158, 'default_policy/modified_reward_mean': -3.9362575355415395, 'default_policy/modified_reward_min': -5.904578751827746, 'default_policy/modified_reward_max': -2.7946808032711115, 'default_policy/corr_btw_rewards_mean': 0.45320462695144315, 'default_policy/corr_btw_rewards_min': 0.12628299343681942, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -57.17921284194726, 'true_reward_min': -170.68031745930475, 'true_reward_max': -2.58283008588991, 'proxy_reward_mean': -2.6992128419472086, 'proxy_reward_min': -4.6321067811865575, 'proxy_reward_max': -1.7803427124746158, 'modified_reward_mean': -3.9362575355415395, 'modified_reward_min': -5.904578751827746, 'modified_reward_max': -2.7946808032711115, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003308808290155443, 'proxyInfectionSummaryAbsoluteReward_min': -0.0013160621761658037, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09268460320969985, 'proxyLowerStageReward_min': -0.11574525784886962, 'proxyLowerStageReward_max': -0.07120539216123982, 'proxySmoothStageChangesReward_mean': -0.14082901554404145, 'proxySmoothStageChangesReward_min': -0.21761658031088082, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003308808290155443, 'trueInfectionSummaryAbsoluteReward_min': -0.0013160621761658037, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.0282279792746114, 'truePoliticalReward_min': -0.08704663212435232, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09268460320969985, 'trueLowerStageReward_min': -0.11574525784886962, 'trueLowerStageReward_max': -0.07120539216123982, 'trueSmoothStageChangesReward_mean': -0.14082901554404145, 'trueSmoothStageChangesReward_min': -0.21761658031088082, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -3.9362575355415395, 'total_modified_reward_min': -5.904578751827746, 'total_modified_reward_max': -2.7946808032711115}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5335855374755959, 'mean_inference_ms': 1.68059315291382, 'mean_action_processing_ms': 0.10738703188101098, 'mean_env_wait_ms': 772.3818120464232, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.7946808032711115, 'episode_reward_min': -5.904578751827746, 'episode_reward_mean': -3.9362575355415395, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5335855374755959, 'mean_inference_ms': 1.68059315291382, 'mean_action_processing_ms': 0.10738703188101098, 'mean_env_wait_ms': 772.3818120464232, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 165980, 'num_agent_steps_trained': 165980, 'num_env_steps_sampled': 165980, 'num_env_steps_trained': 165980, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 11.746616214244595, 'num_env_steps_trained_throughput_per_sec': 11.746616214244595, 'timesteps_total': 165980, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 165980, 'timers': {'training_iteration_time_ms': 336936.941, 'sample_time_ms': 335953.462, 'load_time_ms': 5.174, 'load_throughput': 746004.499, 'learn_time_ms': 962.609, 'learn_throughput': 4009.935, 'synch_weights_time_ms': 14.955}, 'counters': {'num_env_steps_sampled': 165980, 'num_env_steps_trained': 165980, 'num_agent_steps_sampled': 165980, 'num_agent_steps_trained': 165980}, 'done': False, 'episodes_total': 860, 'training_iteration': 43, 'trial_id': 'default', 'date': '2025-11-04_22-41-47', 'timestamp': 1762324907, 'time_this_iter_s': 328.6274313926697, 'time_total_s': 13733.802284955978, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14cba9d0da20>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14cba9d0f700>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffd5d0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffed10>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 13733.802284955978, 'iterations_since_restore': 43, 'perf': {'cpu_util_percent': 18.819189765458425, 'ram_util_percent': 6.0}}
Iteration 44/100
{'custom_metrics': {'default_policy/true_reward_mean': -54.17122058005768, 'default_policy/true_reward_min': -170.68031745930475, 'default_policy/true_reward_max': -2.58283008588991, 'default_policy/proxy_reward_mean': -2.6592205800576307, 'default_policy/proxy_reward_min': -4.094962120245874, 'default_policy/proxy_reward_max': -1.7803427124746158, 'default_policy/modified_reward_mean': -3.895852577899536, 'default_policy/modified_reward_min': -5.489861083678602, 'default_policy/modified_reward_max': -2.7946808032711115, 'default_policy/corr_btw_rewards_mean': 0.44599286482877126, 'default_policy/corr_btw_rewards_min': 0.1606156498089577, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -54.17122058005768, 'true_reward_min': -170.68031745930475, 'true_reward_max': -2.58283008588991, 'proxy_reward_mean': -2.6592205800576307, 'proxy_reward_min': -4.094962120245874, 'proxy_reward_max': -1.7803427124746158, 'modified_reward_mean': -3.895852577899536, 'modified_reward_min': -5.489861083678602, 'modified_reward_max': -2.7946808032711115, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003074611398963732, 'proxyInfectionSummaryAbsoluteReward_min': -0.0010155440414507779, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0933171285003953, 'proxyLowerStageReward_min': -0.11574525784886962, 'proxyLowerStageReward_max': -0.07940283662334627, 'proxySmoothStageChangesReward_mean': -0.1372020725388601, 'proxySmoothStageChangesReward_min': -0.21761658031088082, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003074611398963732, 'trueInfectionSummaryAbsoluteReward_min': -0.0010155440414507779, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.02669015544041451, 'truePoliticalReward_min': -0.08704663212435232, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.0933171285003953, 'trueLowerStageReward_min': -0.11574525784886962, 'trueLowerStageReward_max': -0.07940283662334627, 'trueSmoothStageChangesReward_mean': -0.1372020725388601, 'trueSmoothStageChangesReward_min': -0.21761658031088082, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -3.895852577899536, 'total_modified_reward_min': -5.489861083678602, 'total_modified_reward_max': -2.7946808032711115}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9550905782481035, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.04455114688113099, 'policy_loss': -0.009436643772448102, 'vf_loss': 0.017997370550098517, 'vf_explained_var': 0.747730523943901, 'kl': 0.010596434039103098, 'entropy': 0.6375776384274164, 'entropy_coeff': 0.07012360000000001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 13050.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 169840, 'num_env_steps_trained': 169840, 'num_agent_steps_sampled': 169840, 'num_agent_steps_trained': 169840}, 'sampler_results': {'episode_reward_max': -2.7946808032711115, 'episode_reward_min': -5.489861083678602, 'episode_reward_mean': -3.895852577899536, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -54.17122058005768, 'default_policy/true_reward_min': -170.68031745930475, 'default_policy/true_reward_max': -2.58283008588991, 'default_policy/proxy_reward_mean': -2.6592205800576307, 'default_policy/proxy_reward_min': -4.094962120245874, 'default_policy/proxy_reward_max': -1.7803427124746158, 'default_policy/modified_reward_mean': -3.895852577899536, 'default_policy/modified_reward_min': -5.489861083678602, 'default_policy/modified_reward_max': -2.7946808032711115, 'default_policy/corr_btw_rewards_mean': 0.44599286482877126, 'default_policy/corr_btw_rewards_min': 0.1606156498089577, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -54.17122058005768, 'true_reward_min': -170.68031745930475, 'true_reward_max': -2.58283008588991, 'proxy_reward_mean': -2.6592205800576307, 'proxy_reward_min': -4.094962120245874, 'proxy_reward_max': -1.7803427124746158, 'modified_reward_mean': -3.895852577899536, 'modified_reward_min': -5.489861083678602, 'modified_reward_max': -2.7946808032711115, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003074611398963732, 'proxyInfectionSummaryAbsoluteReward_min': -0.0010155440414507779, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0933171285003953, 'proxyLowerStageReward_min': -0.11574525784886962, 'proxyLowerStageReward_max': -0.07940283662334627, 'proxySmoothStageChangesReward_mean': -0.1372020725388601, 'proxySmoothStageChangesReward_min': -0.21761658031088082, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003074611398963732, 'trueInfectionSummaryAbsoluteReward_min': -0.0010155440414507779, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.02669015544041451, 'truePoliticalReward_min': -0.08704663212435232, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.0933171285003953, 'trueLowerStageReward_min': -0.11574525784886962, 'trueLowerStageReward_max': -0.07940283662334627, 'trueSmoothStageChangesReward_mean': -0.1372020725388601, 'trueSmoothStageChangesReward_min': -0.21761658031088082, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -3.895852577899536, 'total_modified_reward_min': -5.489861083678602, 'total_modified_reward_max': -2.7946808032711115}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5331622120143731, 'mean_inference_ms': 1.681805831861717, 'mean_action_processing_ms': 0.10738734254894615, 'mean_env_wait_ms': 771.4966304469081, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.7946808032711115, 'episode_reward_min': -5.489861083678602, 'episode_reward_mean': -3.895852577899536, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5331622120143731, 'mean_inference_ms': 1.681805831861717, 'mean_action_processing_ms': 0.10738734254894615, 'mean_env_wait_ms': 771.4966304469081, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 169840, 'num_agent_steps_trained': 169840, 'num_env_steps_sampled': 169840, 'num_env_steps_trained': 169840, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 11.568733857351239, 'num_env_steps_trained_throughput_per_sec': 11.568733857351239, 'timesteps_total': 169840, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 169840, 'timers': {'training_iteration_time_ms': 337337.735, 'sample_time_ms': 336354.435, 'load_time_ms': 5.422, 'load_throughput': 711933.716, 'learn_time_ms': 961.913, 'learn_throughput': 4012.839, 'synch_weights_time_ms': 15.145}, 'counters': {'num_env_steps_sampled': 169840, 'num_env_steps_trained': 169840, 'num_agent_steps_sampled': 169840, 'num_agent_steps_trained': 169840}, 'done': False, 'episodes_total': 880, 'training_iteration': 44, 'trial_id': 'default', 'date': '2025-11-04_22-47-21', 'timestamp': 1762325241, 'time_this_iter_s': 333.678838968277, 'time_total_s': 14067.481123924255, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6996114b0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699611510>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffe200>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffe050>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 14067.481123924255, 'iterations_since_restore': 44, 'perf': {'cpu_util_percent': 18.66757894736842, 'ram_util_percent': 6.0}}
Iteration 45/100
{'custom_metrics': {'default_policy/true_reward_mean': -49.69013338674887, 'default_policy/true_reward_min': -170.68031745930475, 'default_policy/true_reward_max': -2.58283008588991, 'default_policy/proxy_reward_mean': -2.6501333867488115, 'default_policy/proxy_reward_min': -4.079606781186551, 'default_policy/proxy_reward_max': -1.7803427124746158, 'default_policy/modified_reward_mean': -3.864373841523312, 'default_policy/modified_reward_min': -5.517972303441946, 'default_policy/modified_reward_max': -2.7345899220509327, 'default_policy/corr_btw_rewards_mean': 0.43431547688467276, 'default_policy/corr_btw_rewards_min': 0.1522365001340478, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -49.69013338674887, 'true_reward_min': -170.68031745930475, 'true_reward_max': -2.58283008588991, 'proxy_reward_mean': -2.6501333867488115, 'proxy_reward_min': -4.079606781186551, 'proxy_reward_max': -1.7803427124746158, 'modified_reward_mean': -3.864373841523312, 'modified_reward_min': -5.517972303441946, 'modified_reward_max': -2.7345899220509327, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003188601036269431, 'proxyInfectionSummaryAbsoluteReward_min': -0.0010155440414507779, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09233851744812485, 'proxyLowerStageReward_min': -0.11574525784886962, 'proxyLowerStageReward_max': -0.07520252485246638, 'proxySmoothStageChangesReward_mean': -0.13088082901554404, 'proxySmoothStageChangesReward_min': -0.21761658031088082, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003188601036269431, 'trueInfectionSummaryAbsoluteReward_min': -0.0010155440414507779, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.02437305699481865, 'truePoliticalReward_min': -0.08704663212435232, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09233851744812485, 'trueLowerStageReward_min': -0.11574525784886962, 'trueLowerStageReward_max': -0.07520252485246638, 'trueSmoothStageChangesReward_mean': -0.13088082901554404, 'trueSmoothStageChangesReward_min': -0.21761658031088082, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -3.864373841523312, 'total_modified_reward_min': -5.517972303441946, 'total_modified_reward_max': -2.7345899220509327}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9467503043760856, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.039201809383230285, 'policy_loss': -0.004021825377518932, 'vf_loss': 0.016563923987948027, 'vf_explained_var': 0.6654937342802684, 'kl': 0.010046180726798078, 'entropy': 0.6341322596867879, 'entropy_coeff': 0.06942879999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 13350.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 173700, 'num_env_steps_trained': 173700, 'num_agent_steps_sampled': 173700, 'num_agent_steps_trained': 173700}, 'sampler_results': {'episode_reward_max': -2.7345899220509327, 'episode_reward_min': -5.517972303441946, 'episode_reward_mean': -3.864373841523312, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -49.69013338674887, 'default_policy/true_reward_min': -170.68031745930475, 'default_policy/true_reward_max': -2.58283008588991, 'default_policy/proxy_reward_mean': -2.6501333867488115, 'default_policy/proxy_reward_min': -4.079606781186551, 'default_policy/proxy_reward_max': -1.7803427124746158, 'default_policy/modified_reward_mean': -3.864373841523312, 'default_policy/modified_reward_min': -5.517972303441946, 'default_policy/modified_reward_max': -2.7345899220509327, 'default_policy/corr_btw_rewards_mean': 0.43431547688467276, 'default_policy/corr_btw_rewards_min': 0.1522365001340478, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -49.69013338674887, 'true_reward_min': -170.68031745930475, 'true_reward_max': -2.58283008588991, 'proxy_reward_mean': -2.6501333867488115, 'proxy_reward_min': -4.079606781186551, 'proxy_reward_max': -1.7803427124746158, 'modified_reward_mean': -3.864373841523312, 'modified_reward_min': -5.517972303441946, 'modified_reward_max': -2.7345899220509327, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003188601036269431, 'proxyInfectionSummaryAbsoluteReward_min': -0.0010155440414507779, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.09233851744812485, 'proxyLowerStageReward_min': -0.11574525784886962, 'proxyLowerStageReward_max': -0.07520252485246638, 'proxySmoothStageChangesReward_mean': -0.13088082901554404, 'proxySmoothStageChangesReward_min': -0.21761658031088082, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003188601036269431, 'trueInfectionSummaryAbsoluteReward_min': -0.0010155440414507779, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.02437305699481865, 'truePoliticalReward_min': -0.08704663212435232, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.09233851744812485, 'trueLowerStageReward_min': -0.11574525784886962, 'trueLowerStageReward_max': -0.07520252485246638, 'trueSmoothStageChangesReward_mean': -0.13088082901554404, 'trueSmoothStageChangesReward_min': -0.21761658031088082, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -3.864373841523312, 'total_modified_reward_min': -5.517972303441946, 'total_modified_reward_max': -2.7345899220509327}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5327790304572451, 'mean_inference_ms': 1.6827858571367957, 'mean_action_processing_ms': 0.10737324503866154, 'mean_env_wait_ms': 770.5413048781973, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.7345899220509327, 'episode_reward_min': -5.517972303441946, 'episode_reward_mean': -3.864373841523312, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5327790304572451, 'mean_inference_ms': 1.6827858571367957, 'mean_action_processing_ms': 0.10737324503866154, 'mean_env_wait_ms': 770.5413048781973, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 173700, 'num_agent_steps_trained': 173700, 'num_env_steps_sampled': 173700, 'num_env_steps_trained': 173700, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.013960780740314, 'num_env_steps_trained_throughput_per_sec': 12.013960780740314, 'timesteps_total': 173700, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 173700, 'timers': {'training_iteration_time_ms': 336232.476, 'sample_time_ms': 335249.488, 'load_time_ms': 5.247, 'load_throughput': 735678.966, 'learn_time_ms': 961.446, 'learn_throughput': 4014.787, 'synch_weights_time_ms': 15.473}, 'counters': {'num_env_steps_sampled': 173700, 'num_env_steps_trained': 173700, 'num_agent_steps_sampled': 173700, 'num_agent_steps_trained': 173700}, 'done': False, 'episodes_total': 900, 'training_iteration': 45, 'trial_id': 'default', 'date': '2025-11-04_22-52-42', 'timestamp': 1762325562, 'time_this_iter_s': 321.3109178543091, 'time_total_s': 14388.792041778564, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e0ffc670>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14cba9d0d9f0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2632500>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e26309d0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 14388.792041778564, 'iterations_since_restore': 45, 'perf': {'cpu_util_percent': 19.020742358078603, 'ram_util_percent': 6.0}}
Iteration 46/100
{'custom_metrics': {'default_policy/true_reward_mean': -47.71365229009445, 'default_policy/true_reward_min': -105.19210678118651, 'default_policy/true_reward_max': -2.7739087296526077, 'default_policy/proxy_reward_mean': -2.5656522900944, 'default_policy/proxy_reward_min': -5.192106781186535, 'default_policy/proxy_reward_max': -1.529619407771254, 'default_policy/modified_reward_mean': -3.7379016606935185, 'default_policy/modified_reward_min': -6.526752843688607, 'default_policy/modified_reward_max': -2.45629098030051, 'default_policy/corr_btw_rewards_mean': 0.4285613881943822, 'default_policy/corr_btw_rewards_min': 0.14879985731363538, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -47.71365229009445, 'true_reward_min': -105.19210678118651, 'true_reward_max': -2.7739087296526077, 'proxy_reward_mean': -2.5656522900944, 'proxy_reward_min': -5.192106781186535, 'proxy_reward_max': -1.529619407771254, 'modified_reward_mean': -3.7379016606935185, 'modified_reward_min': -6.526752843688607, 'modified_reward_max': -2.45629098030051, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003116062176165805, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.08913224301007253, 'proxyLowerStageReward_min': -0.11574525784886962, 'proxyLowerStageReward_max': -0.06483983055194824, 'proxySmoothStageChangesReward_mean': -0.12642487046632125, 'proxySmoothStageChangesReward_min': -0.21761658031088082, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003116062176165805, 'trueInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.02339274611398964, 'truePoliticalReward_min': -0.05202072538860103, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.08913224301007253, 'trueLowerStageReward_min': -0.11574525784886962, 'trueLowerStageReward_max': -0.06483983055194824, 'trueSmoothStageChangesReward_mean': -0.12642487046632125, 'trueSmoothStageChangesReward_min': -0.21761658031088082, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -3.7379016606935185, 'total_modified_reward_min': -6.526752843688607, 'total_modified_reward_max': -2.45629098030051}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9049124915897846, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.039170888770992555, 'policy_loss': -0.009463083694378534, 'vf_loss': 0.022887776724916573, 'vf_explained_var': 0.6911170081297556, 'kl': 0.010384462099959961, 'entropy': 0.6072077255447705, 'entropy_coeff': 0.068734}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 13650.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 177560, 'num_env_steps_trained': 177560, 'num_agent_steps_sampled': 177560, 'num_agent_steps_trained': 177560}, 'sampler_results': {'episode_reward_max': -2.45629098030051, 'episode_reward_min': -6.526752843688607, 'episode_reward_mean': -3.7379016606935185, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -47.71365229009445, 'default_policy/true_reward_min': -105.19210678118651, 'default_policy/true_reward_max': -2.7739087296526077, 'default_policy/proxy_reward_mean': -2.5656522900944, 'default_policy/proxy_reward_min': -5.192106781186535, 'default_policy/proxy_reward_max': -1.529619407771254, 'default_policy/modified_reward_mean': -3.7379016606935185, 'default_policy/modified_reward_min': -6.526752843688607, 'default_policy/modified_reward_max': -2.45629098030051, 'default_policy/corr_btw_rewards_mean': 0.4285613881943822, 'default_policy/corr_btw_rewards_min': 0.14879985731363538, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -47.71365229009445, 'true_reward_min': -105.19210678118651, 'true_reward_max': -2.7739087296526077, 'proxy_reward_mean': -2.5656522900944, 'proxy_reward_min': -5.192106781186535, 'proxy_reward_max': -1.529619407771254, 'modified_reward_mean': -3.7379016606935185, 'modified_reward_min': -6.526752843688607, 'modified_reward_max': -2.45629098030051, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003116062176165805, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.08913224301007253, 'proxyLowerStageReward_min': -0.11574525784886962, 'proxyLowerStageReward_max': -0.06483983055194824, 'proxySmoothStageChangesReward_mean': -0.12642487046632125, 'proxySmoothStageChangesReward_min': -0.21761658031088082, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003116062176165805, 'trueInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.02339274611398964, 'truePoliticalReward_min': -0.05202072538860103, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.08913224301007253, 'trueLowerStageReward_min': -0.11574525784886962, 'trueLowerStageReward_max': -0.06483983055194824, 'trueSmoothStageChangesReward_mean': -0.12642487046632125, 'trueSmoothStageChangesReward_min': -0.21761658031088082, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -3.7379016606935185, 'total_modified_reward_min': -6.526752843688607, 'total_modified_reward_max': -2.45629098030051}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5322420443500282, 'mean_inference_ms': 1.6838571607541104, 'mean_action_processing_ms': 0.10736604110378002, 'mean_env_wait_ms': 769.5280495924536, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.45629098030051, 'episode_reward_min': -6.526752843688607, 'episode_reward_mean': -3.7379016606935185, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5322420443500282, 'mean_inference_ms': 1.6838571607541104, 'mean_action_processing_ms': 0.10736604110378002, 'mean_env_wait_ms': 769.5280495924536, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 177560, 'num_agent_steps_trained': 177560, 'num_env_steps_sampled': 177560, 'num_env_steps_trained': 177560, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.064629431455153, 'num_env_steps_trained_throughput_per_sec': 12.064629431455153, 'timesteps_total': 177560, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 177560, 'timers': {'training_iteration_time_ms': 334996.801, 'sample_time_ms': 334012.347, 'load_time_ms': 5.711, 'load_throughput': 675904.724, 'learn_time_ms': 962.183, 'learn_throughput': 4011.711, 'synch_weights_time_ms': 15.674}, 'counters': {'num_env_steps_sampled': 177560, 'num_env_steps_trained': 177560, 'num_agent_steps_sampled': 177560, 'num_agent_steps_trained': 177560}, 'done': False, 'episodes_total': 920, 'training_iteration': 46, 'trial_id': 'default', 'date': '2025-11-04_22-58-03', 'timestamp': 1762325883, 'time_this_iter_s': 319.9623568058014, 'time_total_s': 14708.754398584366, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e2632d40>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e26301c0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699535cc0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699536440>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 14708.754398584366, 'iterations_since_restore': 46, 'perf': {'cpu_util_percent': 18.754166666666666, 'ram_util_percent': 6.0}}
Iteration 47/100
{'custom_metrics': {'default_policy/true_reward_mean': -50.529581096016756, 'default_policy/true_reward_min': -105.19210678118651, 'default_policy/true_reward_max': -6.452830085889916, 'default_policy/proxy_reward_mean': -2.4895810960166878, 'default_policy/proxy_reward_min': -5.192106781186535, 'default_policy/proxy_reward_max': -1.317842712474618, 'default_policy/modified_reward_mean': -3.6206913467833988, 'default_policy/modified_reward_min': -6.526752843688607, 'default_policy/modified_reward_max': -2.0486553994866776, 'default_policy/corr_btw_rewards_mean': 0.4331912532841518, 'default_policy/corr_btw_rewards_min': 0.14879985731363538, 'default_policy/corr_btw_rewards_max': 0.6970466490275576, 'true_reward_mean': -50.529581096016756, 'true_reward_min': -105.19210678118651, 'true_reward_max': -6.452830085889916, 'proxy_reward_mean': -2.4895810960166878, 'proxy_reward_min': -5.192106781186535, 'proxy_reward_max': -1.317842712474618, 'modified_reward_mean': -3.6206913467833988, 'modified_reward_min': -6.526752843688607, 'modified_reward_max': -2.0486553994866776, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003146113989637307, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.08454824331692677, 'proxyLowerStageReward_min': -0.10723351197857756, 'proxyLowerStageReward_max': -0.05481050323702689, 'proxySmoothStageChangesReward_mean': -0.12984455958549224, 'proxySmoothStageChangesReward_min': -0.21761658031088082, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003146113989637307, 'trueInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.024891191709844555, 'truePoliticalReward_min': -0.05181347150259067, 'truePoliticalReward_max': -0.0022797927461139906, 'trueLowerStageReward_mean': -0.08454824331692677, 'trueLowerStageReward_min': -0.10723351197857756, 'trueLowerStageReward_max': -0.05481050323702689, 'trueSmoothStageChangesReward_mean': -0.12984455958549224, 'trueSmoothStageChangesReward_min': -0.21761658031088082, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -3.6206913467833988, 'total_modified_reward_min': -6.526752843688607, 'total_modified_reward_max': -2.0486553994866776}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9631436525781949, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.03381133748538559, 'policy_loss': -0.00796895707026124, 'vf_loss': 0.02439238116882431, 'vf_explained_var': 0.7354320726792017, 'kl': 0.00982578629334142, 'entropy': 0.5671916309992472, 'entropy_coeff': 0.06803919999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 13950.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 181420, 'num_env_steps_trained': 181420, 'num_agent_steps_sampled': 181420, 'num_agent_steps_trained': 181420}, 'sampler_results': {'episode_reward_max': -2.0486553994866776, 'episode_reward_min': -6.526752843688607, 'episode_reward_mean': -3.6206913467833988, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -50.529581096016756, 'default_policy/true_reward_min': -105.19210678118651, 'default_policy/true_reward_max': -6.452830085889916, 'default_policy/proxy_reward_mean': -2.4895810960166878, 'default_policy/proxy_reward_min': -5.192106781186535, 'default_policy/proxy_reward_max': -1.317842712474618, 'default_policy/modified_reward_mean': -3.6206913467833988, 'default_policy/modified_reward_min': -6.526752843688607, 'default_policy/modified_reward_max': -2.0486553994866776, 'default_policy/corr_btw_rewards_mean': 0.4331912532841518, 'default_policy/corr_btw_rewards_min': 0.14879985731363538, 'default_policy/corr_btw_rewards_max': 0.6970466490275576, 'true_reward_mean': -50.529581096016756, 'true_reward_min': -105.19210678118651, 'true_reward_max': -6.452830085889916, 'proxy_reward_mean': -2.4895810960166878, 'proxy_reward_min': -5.192106781186535, 'proxy_reward_max': -1.317842712474618, 'modified_reward_mean': -3.6206913467833988, 'modified_reward_min': -6.526752843688607, 'modified_reward_max': -2.0486553994866776, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003146113989637307, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.08454824331692677, 'proxyLowerStageReward_min': -0.10723351197857756, 'proxyLowerStageReward_max': -0.05481050323702689, 'proxySmoothStageChangesReward_mean': -0.12984455958549224, 'proxySmoothStageChangesReward_min': -0.21761658031088082, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003146113989637307, 'trueInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.024891191709844555, 'truePoliticalReward_min': -0.05181347150259067, 'truePoliticalReward_max': -0.0022797927461139906, 'trueLowerStageReward_mean': -0.08454824331692677, 'trueLowerStageReward_min': -0.10723351197857756, 'trueLowerStageReward_max': -0.05481050323702689, 'trueSmoothStageChangesReward_mean': -0.12984455958549224, 'trueSmoothStageChangesReward_min': -0.21761658031088082, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -3.6206913467833988, 'total_modified_reward_min': -6.526752843688607, 'total_modified_reward_max': -2.0486553994866776}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5317244136257449, 'mean_inference_ms': 1.6848141343284657, 'mean_action_processing_ms': 0.10736263802319325, 'mean_env_wait_ms': 768.3928433483593, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -2.0486553994866776, 'episode_reward_min': -6.526752843688607, 'episode_reward_mean': -3.6206913467833988, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5317244136257449, 'mean_inference_ms': 1.6848141343284657, 'mean_action_processing_ms': 0.10736263802319325, 'mean_env_wait_ms': 768.3928433483593, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 181420, 'num_agent_steps_trained': 181420, 'num_env_steps_sampled': 181420, 'num_env_steps_trained': 181420, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.716935123654178, 'num_env_steps_trained_throughput_per_sec': 12.716935123654178, 'timesteps_total': 181420, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 181420, 'timers': {'training_iteration_time_ms': 330676.284, 'sample_time_ms': 329672.128, 'load_time_ms': 5.551, 'load_throughput': 695375.625, 'learn_time_ms': 982.085, 'learn_throughput': 3930.414, 'synch_weights_time_ms': 15.639}, 'counters': {'num_env_steps_sampled': 181420, 'num_env_steps_trained': 181420, 'num_agent_steps_sampled': 181420, 'num_agent_steps_trained': 181420}, 'done': False, 'episodes_total': 940, 'training_iteration': 47, 'trial_id': 'default', 'date': '2025-11-04_23-03-06', 'timestamp': 1762326186, 'time_this_iter_s': 303.5525007247925, 'time_total_s': 15012.306899309158, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e177a9e0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e1778f40>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e1779ba0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e17794e0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 15012.306899309158, 'iterations_since_restore': 47, 'perf': {'cpu_util_percent': 19.07523148148148, 'ram_util_percent': 6.0}}
Iteration 48/100
{'custom_metrics': {'default_policy/true_reward_mean': -50.857195435844986, 'default_policy/true_reward_min': -105.19210678118651, 'default_policy/true_reward_max': -5.044974746830588, 'default_policy/proxy_reward_mean': -2.4451954358449073, 'default_policy/proxy_reward_min': -5.192106781186535, 'default_policy/proxy_reward_max': -1.0356980515339458, 'default_policy/modified_reward_mean': -3.536905250770647, 'default_policy/modified_reward_min': -6.526752843688607, 'default_policy/modified_reward_max': -1.677433334395097, 'default_policy/corr_btw_rewards_mean': 0.4271100909026197, 'default_policy/corr_btw_rewards_min': 0.1468912844405157, 'default_policy/corr_btw_rewards_max': 0.6970466490275576, 'true_reward_mean': -50.857195435844986, 'true_reward_min': -105.19210678118651, 'true_reward_max': -5.044974746830588, 'proxy_reward_mean': -2.4451954358449073, 'proxy_reward_min': -5.192106781186535, 'proxy_reward_max': -1.0356980515339458, 'modified_reward_mean': -3.536905250770647, 'modified_reward_min': -6.526752843688607, 'modified_reward_max': -1.677433334395097, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00032984455958549235, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0806785199919641, 'proxyLowerStageReward_min': -0.10723351197857756, 'proxyLowerStageReward_max': -0.0443366866079765, 'proxySmoothStageChangesReward_mean': -0.13031088082901554, 'proxySmoothStageChangesReward_min': -0.21761658031088082, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.00032984455958549235, 'trueInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.025083937823834196, 'truePoliticalReward_min': -0.05181347150259067, 'truePoliticalReward_max': -0.0016580310880829018, 'trueLowerStageReward_mean': -0.0806785199919641, 'trueLowerStageReward_min': -0.10723351197857756, 'trueLowerStageReward_max': -0.0443366866079765, 'trueSmoothStageChangesReward_mean': -0.13031088082901554, 'trueSmoothStageChangesReward_min': -0.21761658031088082, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -3.536905250770647, 'total_modified_reward_min': -6.526752843688607, 'total_modified_reward_max': -1.677433334395097}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.230209159006675, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.025038316675151388, 'policy_loss': -0.00350261677056551, 'vf_loss': 0.03646922003555422, 'vf_explained_var': 0.45565224905808765, 'kl': 0.01059898021152429, 'entropy': 0.5994039731224378, 'entropy_coeff': 0.06734439999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 14250.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 185280, 'num_env_steps_trained': 185280, 'num_agent_steps_sampled': 185280, 'num_agent_steps_trained': 185280}, 'sampler_results': {'episode_reward_max': -1.677433334395097, 'episode_reward_min': -6.526752843688607, 'episode_reward_mean': -3.536905250770647, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -50.857195435844986, 'default_policy/true_reward_min': -105.19210678118651, 'default_policy/true_reward_max': -5.044974746830588, 'default_policy/proxy_reward_mean': -2.4451954358449073, 'default_policy/proxy_reward_min': -5.192106781186535, 'default_policy/proxy_reward_max': -1.0356980515339458, 'default_policy/modified_reward_mean': -3.536905250770647, 'default_policy/modified_reward_min': -6.526752843688607, 'default_policy/modified_reward_max': -1.677433334395097, 'default_policy/corr_btw_rewards_mean': 0.4271100909026197, 'default_policy/corr_btw_rewards_min': 0.1468912844405157, 'default_policy/corr_btw_rewards_max': 0.6970466490275576, 'true_reward_mean': -50.857195435844986, 'true_reward_min': -105.19210678118651, 'true_reward_max': -5.044974746830588, 'proxy_reward_mean': -2.4451954358449073, 'proxy_reward_min': -5.192106781186535, 'proxy_reward_max': -1.0356980515339458, 'modified_reward_mean': -3.536905250770647, 'modified_reward_min': -6.526752843688607, 'modified_reward_max': -1.677433334395097, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00032984455958549235, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0806785199919641, 'proxyLowerStageReward_min': -0.10723351197857756, 'proxyLowerStageReward_max': -0.0443366866079765, 'proxySmoothStageChangesReward_mean': -0.13031088082901554, 'proxySmoothStageChangesReward_min': -0.21761658031088082, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.00032984455958549235, 'trueInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.025083937823834196, 'truePoliticalReward_min': -0.05181347150259067, 'truePoliticalReward_max': -0.0016580310880829018, 'trueLowerStageReward_mean': -0.0806785199919641, 'trueLowerStageReward_min': -0.10723351197857756, 'trueLowerStageReward_max': -0.0443366866079765, 'trueSmoothStageChangesReward_mean': -0.13031088082901554, 'trueSmoothStageChangesReward_min': -0.21761658031088082, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -3.536905250770647, 'total_modified_reward_min': -6.526752843688607, 'total_modified_reward_max': -1.677433334395097}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5312702712246393, 'mean_inference_ms': 1.6856858316814347, 'mean_action_processing_ms': 0.10734094808205008, 'mean_env_wait_ms': 767.1907272232743, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.677433334395097, 'episode_reward_min': -6.526752843688607, 'episode_reward_mean': -3.536905250770647, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5312702712246393, 'mean_inference_ms': 1.6856858316814347, 'mean_action_processing_ms': 0.10734094808205008, 'mean_env_wait_ms': 767.1907272232743, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 185280, 'num_agent_steps_trained': 185280, 'num_env_steps_sampled': 185280, 'num_env_steps_trained': 185280, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.520222290136918, 'num_env_steps_trained_throughput_per_sec': 12.520222290136918, 'timesteps_total': 185280, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 185280, 'timers': {'training_iteration_time_ms': 325491.337, 'sample_time_ms': 324494.852, 'load_time_ms': 5.297, 'load_throughput': 728652.981, 'learn_time_ms': 974.861, 'learn_throughput': 3959.538, 'synch_weights_time_ms': 15.456}, 'counters': {'num_env_steps_sampled': 185280, 'num_env_steps_trained': 185280, 'num_agent_steps_sampled': 185280, 'num_agent_steps_trained': 185280}, 'done': False, 'episodes_total': 960, 'training_iteration': 48, 'trial_id': 'default', 'date': '2025-11-04_23-08-15', 'timestamp': 1762326495, 'time_this_iter_s': 308.31810903549194, 'time_total_s': 15320.62500834465, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e24facb0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e2402890>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6882fe830>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6882ffa00>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 15320.62500834465, 'iterations_since_restore': 48, 'perf': {'cpu_util_percent': 18.785000000000004, 'ram_util_percent': 6.0}}
Iteration 49/100
{'custom_metrics': {'default_policy/true_reward_mean': -57.455216124859305, 'default_policy/true_reward_min': -115.61854076400876, 'default_policy/true_reward_max': -5.044974746830588, 'default_policy/proxy_reward_mean': -2.387216124859231, 'default_policy/proxy_reward_min': -5.192106781186535, 'default_policy/proxy_reward_max': -1.0356980515339458, 'default_policy/modified_reward_mean': -3.466364022387994, 'default_policy/modified_reward_min': -6.526752843688607, 'default_policy/modified_reward_max': -1.677433334395097, 'default_policy/corr_btw_rewards_mean': 0.4581379719957179, 'default_policy/corr_btw_rewards_min': 0.1468912844405157, 'default_policy/corr_btw_rewards_max': 0.6970466490275576, 'true_reward_mean': -57.455216124859305, 'true_reward_min': -115.61854076400876, 'true_reward_max': -5.044974746830588, 'proxy_reward_mean': -2.387216124859231, 'proxy_reward_min': -5.192106781186535, 'proxy_reward_max': -1.0356980515339458, 'modified_reward_mean': -3.466364022387994, 'modified_reward_min': -6.526752843688607, 'modified_reward_max': -1.677433334395097, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003200000000000002, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0777054986973695, 'proxyLowerStageReward_min': -0.10560480820541601, 'proxyLowerStageReward_max': -0.0443366866079765, 'proxySmoothStageChangesReward_mean': -0.13984455958549225, 'proxySmoothStageChangesReward_min': -0.21761658031088082, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003200000000000002, 'trueInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.028532642487046633, 'truePoliticalReward_min': -0.058860103626943, 'truePoliticalReward_max': -0.0016580310880829018, 'trueLowerStageReward_mean': -0.0777054986973695, 'trueLowerStageReward_min': -0.10560480820541601, 'trueLowerStageReward_max': -0.0443366866079765, 'trueSmoothStageChangesReward_mean': -0.13984455958549225, 'trueSmoothStageChangesReward_min': -0.21761658031088082, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -3.466364022387994, 'total_modified_reward_min': -6.526752843688607, 'total_modified_reward_max': -1.677433334395097}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9446644183496634, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.04007300662885731, 'policy_loss': -0.008268756121397018, 'vf_loss': 0.017288034217393337, 'vf_explained_var': 0.6907371548811595, 'kl': 0.00942447506522824, 'entropy': 0.6148333153128624, 'entropy_coeff': 0.06664959999999999}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 14550.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 189140, 'num_env_steps_trained': 189140, 'num_agent_steps_sampled': 189140, 'num_agent_steps_trained': 189140}, 'sampler_results': {'episode_reward_max': -1.677433334395097, 'episode_reward_min': -6.526752843688607, 'episode_reward_mean': -3.466364022387994, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -57.455216124859305, 'default_policy/true_reward_min': -115.61854076400876, 'default_policy/true_reward_max': -5.044974746830588, 'default_policy/proxy_reward_mean': -2.387216124859231, 'default_policy/proxy_reward_min': -5.192106781186535, 'default_policy/proxy_reward_max': -1.0356980515339458, 'default_policy/modified_reward_mean': -3.466364022387994, 'default_policy/modified_reward_min': -6.526752843688607, 'default_policy/modified_reward_max': -1.677433334395097, 'default_policy/corr_btw_rewards_mean': 0.4581379719957179, 'default_policy/corr_btw_rewards_min': 0.1468912844405157, 'default_policy/corr_btw_rewards_max': 0.6970466490275576, 'true_reward_mean': -57.455216124859305, 'true_reward_min': -115.61854076400876, 'true_reward_max': -5.044974746830588, 'proxy_reward_mean': -2.387216124859231, 'proxy_reward_min': -5.192106781186535, 'proxy_reward_max': -1.0356980515339458, 'modified_reward_mean': -3.466364022387994, 'modified_reward_min': -6.526752843688607, 'modified_reward_max': -1.677433334395097, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003200000000000002, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0777054986973695, 'proxyLowerStageReward_min': -0.10560480820541601, 'proxyLowerStageReward_max': -0.0443366866079765, 'proxySmoothStageChangesReward_mean': -0.13984455958549225, 'proxySmoothStageChangesReward_min': -0.21761658031088082, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003200000000000002, 'trueInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.028532642487046633, 'truePoliticalReward_min': -0.058860103626943, 'truePoliticalReward_max': -0.0016580310880829018, 'trueLowerStageReward_mean': -0.0777054986973695, 'trueLowerStageReward_min': -0.10560480820541601, 'trueLowerStageReward_max': -0.0443366866079765, 'trueSmoothStageChangesReward_mean': -0.13984455958549225, 'trueSmoothStageChangesReward_min': -0.21761658031088082, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -3.466364022387994, 'total_modified_reward_min': -6.526752843688607, 'total_modified_reward_max': -1.677433334395097}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5307911814653679, 'mean_inference_ms': 1.6851179264580562, 'mean_action_processing_ms': 0.10731358392149647, 'mean_env_wait_ms': 765.8818773963001, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.677433334395097, 'episode_reward_min': -6.526752843688607, 'episode_reward_mean': -3.466364022387994, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5307911814653679, 'mean_inference_ms': 1.6851179264580562, 'mean_action_processing_ms': 0.10731358392149647, 'mean_env_wait_ms': 765.8818773963001, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 189140, 'num_agent_steps_trained': 189140, 'num_env_steps_sampled': 189140, 'num_env_steps_trained': 189140, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 11.7833608446681, 'num_env_steps_trained_throughput_per_sec': 11.7833608446681, 'timesteps_total': 189140, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 189140, 'timers': {'training_iteration_time_ms': 323702.288, 'sample_time_ms': 322704.416, 'load_time_ms': 5.044, 'load_throughput': 765336.906, 'learn_time_ms': 976.399, 'learn_throughput': 3953.301, 'synch_weights_time_ms': 15.518}, 'counters': {'num_env_steps_sampled': 189140, 'num_env_steps_trained': 189140, 'num_agent_steps_sampled': 189140, 'num_agent_steps_trained': 189140}, 'done': False, 'episodes_total': 980, 'training_iteration': 49, 'trial_id': 'default', 'date': '2025-11-04_23-13-43', 'timestamp': 1762326823, 'time_this_iter_s': 327.610445022583, 'time_total_s': 15648.235453367233, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6882fc550>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699534a60>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6882ffd90>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6882ffdf0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 15648.235453367233, 'iterations_since_restore': 49, 'perf': {'cpu_util_percent': 18.21156316916488, 'ram_util_percent': 6.0}}
Iteration 50/100
{'custom_metrics': {'default_policy/true_reward_mean': -59.876876406233535, 'default_policy/true_reward_min': -142.44104076400856, 'default_policy/true_reward_max': -3.939264068711935, 'default_policy/proxy_reward_mean': -2.3528764062334697, 'default_policy/proxy_reward_min': -5.192106781186535, 'default_policy/proxy_reward_max': -1.0356980515339458, 'default_policy/modified_reward_mean': -3.4033694565767934, 'default_policy/modified_reward_min': -6.526752843688607, 'default_policy/modified_reward_max': -1.677433334395097, 'default_policy/corr_btw_rewards_mean': 0.47744198887773664, 'default_policy/corr_btw_rewards_min': 0.1468912844405157, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -59.876876406233535, 'true_reward_min': -142.44104076400856, 'true_reward_max': -3.939264068711935, 'proxy_reward_mean': -2.3528764062334697, 'proxy_reward_min': -5.192106781186535, 'proxy_reward_max': -1.0356980515339458, 'modified_reward_mean': -3.4033694565767934, 'modified_reward_min': -6.526752843688607, 'modified_reward_max': -1.677433334395097, 'proxyInfectionSummaryAbsoluteReward_mean': -0.000335336787564767, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.07373452882038706, 'proxyLowerStageReward_min': -0.09805503213709192, 'proxyLowerStageReward_max': -0.0443366866079765, 'proxySmoothStageChangesReward_mean': -0.14642487046632127, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.000335336787564767, 'trueInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.029805181347150256, 'truePoliticalReward_min': -0.07295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.07373452882038706, 'trueLowerStageReward_min': -0.09805503213709192, 'trueLowerStageReward_max': -0.0443366866079765, 'trueSmoothStageChangesReward_mean': -0.14642487046632127, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -3.4033694565767934, 'total_modified_reward_min': -6.526752843688607, 'total_modified_reward_max': -1.677433334395097}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.1208454080422718, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.03438035148506363, 'policy_loss': -0.01056152392178774, 'vf_loss': 0.03218659573855499, 'vf_explained_var': 0.6140035635232926, 'kl': 0.010234281184693094, 'entropy': 0.6138719826936722, 'entropy_coeff': 0.0659548}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 14850.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 193000, 'num_env_steps_trained': 193000, 'num_agent_steps_sampled': 193000, 'num_agent_steps_trained': 193000}, 'sampler_results': {'episode_reward_max': -1.677433334395097, 'episode_reward_min': -6.526752843688607, 'episode_reward_mean': -3.4033694565767934, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -59.876876406233535, 'default_policy/true_reward_min': -142.44104076400856, 'default_policy/true_reward_max': -3.939264068711935, 'default_policy/proxy_reward_mean': -2.3528764062334697, 'default_policy/proxy_reward_min': -5.192106781186535, 'default_policy/proxy_reward_max': -1.0356980515339458, 'default_policy/modified_reward_mean': -3.4033694565767934, 'default_policy/modified_reward_min': -6.526752843688607, 'default_policy/modified_reward_max': -1.677433334395097, 'default_policy/corr_btw_rewards_mean': 0.47744198887773664, 'default_policy/corr_btw_rewards_min': 0.1468912844405157, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -59.876876406233535, 'true_reward_min': -142.44104076400856, 'true_reward_max': -3.939264068711935, 'proxy_reward_mean': -2.3528764062334697, 'proxy_reward_min': -5.192106781186535, 'proxy_reward_max': -1.0356980515339458, 'modified_reward_mean': -3.4033694565767934, 'modified_reward_min': -6.526752843688607, 'modified_reward_max': -1.677433334395097, 'proxyInfectionSummaryAbsoluteReward_mean': -0.000335336787564767, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.07373452882038706, 'proxyLowerStageReward_min': -0.09805503213709192, 'proxyLowerStageReward_max': -0.0443366866079765, 'proxySmoothStageChangesReward_mean': -0.14642487046632127, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.000335336787564767, 'trueInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.029805181347150256, 'truePoliticalReward_min': -0.07295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.07373452882038706, 'trueLowerStageReward_min': -0.09805503213709192, 'trueLowerStageReward_max': -0.0443366866079765, 'trueSmoothStageChangesReward_mean': -0.14642487046632127, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -3.4033694565767934, 'total_modified_reward_min': -6.526752843688607, 'total_modified_reward_max': -1.677433334395097}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5304791165419158, 'mean_inference_ms': 1.6845642350384447, 'mean_action_processing_ms': 0.10726766398369335, 'mean_env_wait_ms': 764.4679012215162, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.677433334395097, 'episode_reward_min': -6.526752843688607, 'episode_reward_mean': -3.4033694565767934, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5304791165419158, 'mean_inference_ms': 1.6845642350384447, 'mean_action_processing_ms': 0.10726766398369335, 'mean_env_wait_ms': 764.4679012215162, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 193000, 'num_agent_steps_trained': 193000, 'num_env_steps_sampled': 193000, 'num_env_steps_trained': 193000, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.432347240530131, 'num_env_steps_trained_throughput_per_sec': 12.432347240530131, 'timesteps_total': 193000, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 193000, 'timers': {'training_iteration_time_ms': 320216.25, 'sample_time_ms': 319195.489, 'load_time_ms': 5.442, 'load_throughput': 709354.065, 'learn_time_ms': 998.514, 'learn_throughput': 3865.746, 'synch_weights_time_ms': 15.864}, 'counters': {'num_env_steps_sampled': 193000, 'num_env_steps_trained': 193000, 'num_agent_steps_sampled': 193000, 'num_agent_steps_trained': 193000}, 'done': False, 'episodes_total': 1000, 'training_iteration': 50, 'trial_id': 'default', 'date': '2025-11-04_23-18-53', 'timestamp': 1762327133, 'time_this_iter_s': 310.49965357780457, 'time_total_s': 15958.735106945038, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e0f44c10>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14cba9d0da20>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699563af0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699562200>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 15958.735106945038, 'iterations_since_restore': 50, 'perf': {'cpu_util_percent': 18.803160270880365, 'ram_util_percent': 6.0}}
Saved checkpoint to TrainingResult(checkpoint=Checkpoint(filesystem=local, path=logs/data/pandemic/20251104_185246/checkpoint_50), metrics={'custom_metrics': {'default_policy/true_reward_mean': -59.876876406233535, 'default_policy/true_reward_min': -142.44104076400856, 'default_policy/true_reward_max': -3.939264068711935, 'default_policy/proxy_reward_mean': -2.3528764062334697, 'default_policy/proxy_reward_min': -5.192106781186535, 'default_policy/proxy_reward_max': -1.0356980515339458, 'default_policy/modified_reward_mean': -3.4033694565767934, 'default_policy/modified_reward_min': -6.526752843688607, 'default_policy/modified_reward_max': -1.677433334395097, 'default_policy/corr_btw_rewards_mean': 0.47744198887773664, 'default_policy/corr_btw_rewards_min': 0.1468912844405157, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -59.876876406233535, 'true_reward_min': -142.44104076400856, 'true_reward_max': -3.939264068711935, 'proxy_reward_mean': -2.3528764062334697, 'proxy_reward_min': -5.192106781186535, 'proxy_reward_max': -1.0356980515339458, 'modified_reward_mean': -3.4033694565767934, 'modified_reward_min': -6.526752843688607, 'modified_reward_max': -1.677433334395097, 'proxyInfectionSummaryAbsoluteReward_mean': -0.000335336787564767, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.07373452882038706, 'proxyLowerStageReward_min': -0.09805503213709192, 'proxyLowerStageReward_max': -0.0443366866079765, 'proxySmoothStageChangesReward_mean': -0.14642487046632127, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.000335336787564767, 'trueInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.029805181347150256, 'truePoliticalReward_min': -0.07295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.07373452882038706, 'trueLowerStageReward_min': -0.09805503213709192, 'trueLowerStageReward_max': -0.0443366866079765, 'trueSmoothStageChangesReward_mean': -0.14642487046632127, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -3.4033694565767934, 'total_modified_reward_min': -6.526752843688607, 'total_modified_reward_max': -1.677433334395097}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.1208454080422718, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.03438035148506363, 'policy_loss': -0.01056152392178774, 'vf_loss': 0.03218659573855499, 'vf_explained_var': 0.6140035635232926, 'kl': 0.010234281184693094, 'entropy': 0.6138719826936722, 'entropy_coeff': 0.0659548}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 14850.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 193000, 'num_env_steps_trained': 193000, 'num_agent_steps_sampled': 193000, 'num_agent_steps_trained': 193000}, 'sampler_results': {'episode_reward_max': -1.677433334395097, 'episode_reward_min': -6.526752843688607, 'episode_reward_mean': -3.4033694565767934, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -59.876876406233535, 'default_policy/true_reward_min': -142.44104076400856, 'default_policy/true_reward_max': -3.939264068711935, 'default_policy/proxy_reward_mean': -2.3528764062334697, 'default_policy/proxy_reward_min': -5.192106781186535, 'default_policy/proxy_reward_max': -1.0356980515339458, 'default_policy/modified_reward_mean': -3.4033694565767934, 'default_policy/modified_reward_min': -6.526752843688607, 'default_policy/modified_reward_max': -1.677433334395097, 'default_policy/corr_btw_rewards_mean': 0.47744198887773664, 'default_policy/corr_btw_rewards_min': 0.1468912844405157, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -59.876876406233535, 'true_reward_min': -142.44104076400856, 'true_reward_max': -3.939264068711935, 'proxy_reward_mean': -2.3528764062334697, 'proxy_reward_min': -5.192106781186535, 'proxy_reward_max': -1.0356980515339458, 'modified_reward_mean': -3.4033694565767934, 'modified_reward_min': -6.526752843688607, 'modified_reward_max': -1.677433334395097, 'proxyInfectionSummaryAbsoluteReward_mean': -0.000335336787564767, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.07373452882038706, 'proxyLowerStageReward_min': -0.09805503213709192, 'proxyLowerStageReward_max': -0.0443366866079765, 'proxySmoothStageChangesReward_mean': -0.14642487046632127, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.000335336787564767, 'trueInfectionSummaryAbsoluteReward_min': -0.0015854922279792754, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.029805181347150256, 'truePoliticalReward_min': -0.07295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.07373452882038706, 'trueLowerStageReward_min': -0.09805503213709192, 'trueLowerStageReward_max': -0.0443366866079765, 'trueSmoothStageChangesReward_mean': -0.14642487046632127, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -3.4033694565767934, 'total_modified_reward_min': -6.526752843688607, 'total_modified_reward_max': -1.677433334395097}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5304791165419158, 'mean_inference_ms': 1.6845642350384447, 'mean_action_processing_ms': 0.10726766398369335, 'mean_env_wait_ms': 764.4679012215162, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.677433334395097, 'episode_reward_min': -6.526752843688607, 'episode_reward_mean': -3.4033694565767934, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5304791165419158, 'mean_inference_ms': 1.6845642350384447, 'mean_action_processing_ms': 0.10726766398369335, 'mean_env_wait_ms': 764.4679012215162, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 193000, 'num_agent_steps_trained': 193000, 'num_env_steps_sampled': 193000, 'num_env_steps_trained': 193000, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.432347240530131, 'num_env_steps_trained_throughput_per_sec': 12.432347240530131, 'timesteps_total': 193000, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 193000, 'timers': {'training_iteration_time_ms': 320216.25, 'sample_time_ms': 319195.489, 'load_time_ms': 5.442, 'load_throughput': 709354.065, 'learn_time_ms': 998.514, 'learn_throughput': 3865.746, 'synch_weights_time_ms': 15.864}, 'counters': {'num_env_steps_sampled': 193000, 'num_env_steps_trained': 193000, 'num_agent_steps_sampled': 193000, 'num_agent_steps_trained': 193000}, 'done': False, 'episodes_total': 1000, 'training_iteration': 50, 'trial_id': 'default', 'date': '2025-11-04_23-18-53', 'timestamp': 1762327133, 'time_this_iter_s': 310.49965357780457, 'time_total_s': 15958.735106945038, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e0f44c10>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14cba9d0da20>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699563af0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699562200>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 15958.735106945038, 'iterations_since_restore': 50, 'perf': {'cpu_util_percent': 18.803160270880365, 'ram_util_percent': 6.0}})
Iteration 51/100
{'custom_metrics': {'default_policy/true_reward_mean': -58.80419480451573, 'default_policy/true_reward_min': -142.44104076400856, 'default_policy/true_reward_max': -3.939264068711935, 'default_policy/proxy_reward_mean': -2.2921948045156713, 'default_policy/proxy_reward_min': -4.4067514421272165, 'default_policy/proxy_reward_max': -1.0356980515339458, 'default_policy/modified_reward_mean': -3.305474734131147, 'default_policy/modified_reward_min': -5.655339702401468, 'default_policy/modified_reward_max': -1.677433334395097, 'default_policy/corr_btw_rewards_mean': 0.4828665151600171, 'default_policy/corr_btw_rewards_min': 0.1468912844405157, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -58.80419480451573, 'true_reward_min': -142.44104076400856, 'true_reward_max': -3.939264068711935, 'proxy_reward_mean': -2.2921948045156713, 'proxy_reward_min': -4.4067514421272165, 'proxy_reward_max': -1.0356980515339458, 'modified_reward_mean': -3.305474734131147, 'modified_reward_min': -5.655339702401468, 'modified_reward_max': -1.677433334395097, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00033927461139896393, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015440414507772028, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.07023807277283274, 'proxyLowerStageReward_min': -0.093410231052083, 'proxyLowerStageReward_max': -0.0443366866079765, 'proxySmoothStageChangesReward_mean': -0.14601036269430054, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.00033927461139896393, 'trueInfectionSummaryAbsoluteReward_min': -0.0015440414507772028, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.029280829015544043, 'truePoliticalReward_min': -0.07295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.07023807277283274, 'trueLowerStageReward_min': -0.093410231052083, 'trueLowerStageReward_max': -0.0443366866079765, 'trueSmoothStageChangesReward_mean': -0.14601036269430054, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -3.305474734131147, 'total_modified_reward_min': -5.655339702401468, 'total_modified_reward_max': -1.677433334395097}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.8312108375132083, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.04656824495730689, 'policy_loss': -0.019368161683281263, 'vf_loss': 0.015088219019817188, 'vf_explained_var': 0.7352568423748016, 'kl': 0.009763808516830794, 'entropy': 0.540812265475591, 'entropy_coeff': 0.06526}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 15150.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 196860, 'num_env_steps_trained': 196860, 'num_agent_steps_sampled': 196860, 'num_agent_steps_trained': 196860}, 'sampler_results': {'episode_reward_max': -1.677433334395097, 'episode_reward_min': -5.655339702401468, 'episode_reward_mean': -3.305474734131147, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -58.80419480451573, 'default_policy/true_reward_min': -142.44104076400856, 'default_policy/true_reward_max': -3.939264068711935, 'default_policy/proxy_reward_mean': -2.2921948045156713, 'default_policy/proxy_reward_min': -4.4067514421272165, 'default_policy/proxy_reward_max': -1.0356980515339458, 'default_policy/modified_reward_mean': -3.305474734131147, 'default_policy/modified_reward_min': -5.655339702401468, 'default_policy/modified_reward_max': -1.677433334395097, 'default_policy/corr_btw_rewards_mean': 0.4828665151600171, 'default_policy/corr_btw_rewards_min': 0.1468912844405157, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -58.80419480451573, 'true_reward_min': -142.44104076400856, 'true_reward_max': -3.939264068711935, 'proxy_reward_mean': -2.2921948045156713, 'proxy_reward_min': -4.4067514421272165, 'proxy_reward_max': -1.0356980515339458, 'modified_reward_mean': -3.305474734131147, 'modified_reward_min': -5.655339702401468, 'modified_reward_max': -1.677433334395097, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00033927461139896393, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015440414507772028, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.07023807277283274, 'proxyLowerStageReward_min': -0.093410231052083, 'proxyLowerStageReward_max': -0.0443366866079765, 'proxySmoothStageChangesReward_mean': -0.14601036269430054, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.00033927461139896393, 'trueInfectionSummaryAbsoluteReward_min': -0.0015440414507772028, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.029280829015544043, 'truePoliticalReward_min': -0.07295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.07023807277283274, 'trueLowerStageReward_min': -0.093410231052083, 'trueLowerStageReward_max': -0.0443366866079765, 'trueSmoothStageChangesReward_mean': -0.14601036269430054, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -3.305474734131147, 'total_modified_reward_min': -5.655339702401468, 'total_modified_reward_max': -1.677433334395097}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5301994557668958, 'mean_inference_ms': 1.6840449676230462, 'mean_action_processing_ms': 0.10721198033444213, 'mean_env_wait_ms': 763.0920669779717, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.677433334395097, 'episode_reward_min': -5.655339702401468, 'episode_reward_mean': -3.305474734131147, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5301994557668958, 'mean_inference_ms': 1.6840449676230462, 'mean_action_processing_ms': 0.10721198033444213, 'mean_env_wait_ms': 763.0920669779717, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 196860, 'num_agent_steps_trained': 196860, 'num_env_steps_sampled': 196860, 'num_env_steps_trained': 196860, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.103713291305299, 'num_env_steps_trained_throughput_per_sec': 12.103713291305299, 'timesteps_total': 196860, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 196860, 'timers': {'training_iteration_time_ms': 319660.534, 'sample_time_ms': 318641.923, 'load_time_ms': 5.462, 'load_throughput': 706697.401, 'learn_time_ms': 996.121, 'learn_throughput': 3875.03, 'synch_weights_time_ms': 16.088}, 'counters': {'num_env_steps_sampled': 196860, 'num_env_steps_trained': 196860, 'num_agent_steps_sampled': 196860, 'num_agent_steps_trained': 196860}, 'done': False, 'episodes_total': 1020, 'training_iteration': 51, 'trial_id': 'default', 'date': '2025-11-04_23-24-12', 'timestamp': 1762327452, 'time_this_iter_s': 318.92875146865845, 'time_total_s': 16277.663858413696, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e2510df0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e2513610>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2512380>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2510e50>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 16277.663858413696, 'iterations_since_restore': 51, 'perf': {'cpu_util_percent': 18.607912087912087, 'ram_util_percent': 6.0}}
Iteration 52/100
{'custom_metrics': {'default_policy/true_reward_mean': -57.11943477567318, 'default_policy/true_reward_min': -142.44104076400856, 'default_policy/true_reward_max': -3.939264068711935, 'default_policy/proxy_reward_mean': -2.2634347756731272, 'default_policy/proxy_reward_min': -4.709264068711925, 'default_policy/proxy_reward_max': -1.0356980515339458, 'default_policy/modified_reward_mean': -3.2471492831739166, 'default_policy/modified_reward_min': -5.569407785175448, 'default_policy/modified_reward_max': -1.677433334395097, 'default_policy/corr_btw_rewards_mean': 0.47690537273978106, 'default_policy/corr_btw_rewards_min': 0.1468912844405157, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -57.11943477567318, 'true_reward_min': -142.44104076400856, 'true_reward_max': -3.939264068711935, 'proxy_reward_mean': -2.2634347756731272, 'proxy_reward_min': -4.709264068711925, 'proxy_reward_max': -1.0356980515339458, 'modified_reward_mean': -3.2471492831739166, 'modified_reward_min': -5.569407785175448, 'modified_reward_max': -1.677433334395097, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00034984455958549245, 'proxyInfectionSummaryAbsoluteReward_min': -0.0017202072538860117, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.06803288993125012, 'proxyLowerStageReward_min': -0.093410231052083, 'proxyLowerStageReward_max': -0.0443366866079765, 'proxySmoothStageChangesReward_mean': -0.14259067357512956, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.00034984455958549245, 'trueInfectionSummaryAbsoluteReward_min': -0.0017202072538860117, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.028422797927461135, 'truePoliticalReward_min': -0.07295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.06803288993125012, 'trueLowerStageReward_min': -0.093410231052083, 'trueLowerStageReward_max': -0.0443366866079765, 'trueSmoothStageChangesReward_mean': -0.14259067357512956, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -3.2471492831739166, 'total_modified_reward_min': -5.569407785175448, 'total_modified_reward_max': -1.677433334395097}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0353825103243193, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.025705599735180537, 'policy_loss': -0.007221234372506539, 'vf_loss': 0.02938833977251003, 'vf_explained_var': 0.5108748692274093, 'kl': 0.007265218318608468, 'entropy': 0.5202059804399808, 'entropy_coeff': 0.0645652}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 15450.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 200720, 'num_env_steps_trained': 200720, 'num_agent_steps_sampled': 200720, 'num_agent_steps_trained': 200720}, 'sampler_results': {'episode_reward_max': -1.677433334395097, 'episode_reward_min': -5.569407785175448, 'episode_reward_mean': -3.2471492831739166, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -57.11943477567318, 'default_policy/true_reward_min': -142.44104076400856, 'default_policy/true_reward_max': -3.939264068711935, 'default_policy/proxy_reward_mean': -2.2634347756731272, 'default_policy/proxy_reward_min': -4.709264068711925, 'default_policy/proxy_reward_max': -1.0356980515339458, 'default_policy/modified_reward_mean': -3.2471492831739166, 'default_policy/modified_reward_min': -5.569407785175448, 'default_policy/modified_reward_max': -1.677433334395097, 'default_policy/corr_btw_rewards_mean': 0.47690537273978106, 'default_policy/corr_btw_rewards_min': 0.1468912844405157, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -57.11943477567318, 'true_reward_min': -142.44104076400856, 'true_reward_max': -3.939264068711935, 'proxy_reward_mean': -2.2634347756731272, 'proxy_reward_min': -4.709264068711925, 'proxy_reward_max': -1.0356980515339458, 'modified_reward_mean': -3.2471492831739166, 'modified_reward_min': -5.569407785175448, 'modified_reward_max': -1.677433334395097, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00034984455958549245, 'proxyInfectionSummaryAbsoluteReward_min': -0.0017202072538860117, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.06803288993125012, 'proxyLowerStageReward_min': -0.093410231052083, 'proxyLowerStageReward_max': -0.0443366866079765, 'proxySmoothStageChangesReward_mean': -0.14259067357512956, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.06217616580310881, 'trueInfectionSummaryAbsoluteReward_mean': -0.00034984455958549245, 'trueInfectionSummaryAbsoluteReward_min': -0.0017202072538860117, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.028422797927461135, 'truePoliticalReward_min': -0.07295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.06803288993125012, 'trueLowerStageReward_min': -0.093410231052083, 'trueLowerStageReward_max': -0.0443366866079765, 'trueSmoothStageChangesReward_mean': -0.14259067357512956, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.06217616580310881, 'total_modified_reward_mean': -3.2471492831739166, 'total_modified_reward_min': -5.569407785175448, 'total_modified_reward_max': -1.677433334395097}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5301739418514515, 'mean_inference_ms': 1.68362505561126, 'mean_action_processing_ms': 0.10712446021356038, 'mean_env_wait_ms': 761.7862412667706, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.677433334395097, 'episode_reward_min': -5.569407785175448, 'episode_reward_mean': -3.2471492831739166, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5301739418514515, 'mean_inference_ms': 1.68362505561126, 'mean_action_processing_ms': 0.10712446021356038, 'mean_env_wait_ms': 761.7862412667706, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 200720, 'num_agent_steps_trained': 200720, 'num_env_steps_sampled': 200720, 'num_env_steps_trained': 200720, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.21771315277476, 'num_env_steps_trained_throughput_per_sec': 12.21771315277476, 'timesteps_total': 200720, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 200720, 'timers': {'training_iteration_time_ms': 318823.822, 'sample_time_ms': 317782.984, 'load_time_ms': 5.603, 'load_throughput': 688863.459, 'learn_time_ms': 1017.991, 'learn_throughput': 3791.782, 'synch_weights_time_ms': 16.276}, 'counters': {'num_env_steps_sampled': 200720, 'num_env_steps_trained': 200720, 'num_agent_steps_sampled': 200720, 'num_agent_steps_trained': 200720}, 'done': False, 'episodes_total': 1040, 'training_iteration': 52, 'trial_id': 'default', 'date': '2025-11-04_23-29-28', 'timestamp': 1762327768, 'time_this_iter_s': 315.95505833625793, 'time_total_s': 16593.618916749954, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e0f44d90>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699536050>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e177a380>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e177ad10>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 16593.618916749954, 'iterations_since_restore': 52, 'perf': {'cpu_util_percent': 18.913525498891353, 'ram_util_percent': 6.0}}
Iteration 53/100
{'custom_metrics': {'default_policy/true_reward_mean': -53.16900088322326, 'default_policy/true_reward_min': -142.44104076400856, 'default_policy/true_reward_max': -3.035330085889914, 'default_policy/proxy_reward_mean': -2.2370008832232067, 'default_policy/proxy_reward_min': -4.709264068711925, 'default_policy/proxy_reward_max': -0.9439213562373086, 'default_policy/modified_reward_mean': -3.170761175458803, 'default_policy/modified_reward_min': -5.569407785175448, 'default_policy/modified_reward_max': -1.457717897149064, 'default_policy/corr_btw_rewards_mean': 0.4787001343392388, 'default_policy/corr_btw_rewards_min': 0.11095595791622016, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -53.16900088322326, 'true_reward_min': -142.44104076400856, 'true_reward_max': -3.035330085889914, 'proxy_reward_mean': -2.2370008832232067, 'proxy_reward_min': -4.709264068711925, 'proxy_reward_max': -0.9439213562373086, 'modified_reward_mean': -3.170761175458803, 'modified_reward_min': -5.569407785175448, 'modified_reward_max': -1.457717897149064, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00037761658031088105, 'proxyInfectionSummaryAbsoluteReward_min': -0.0017202072538860117, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.06464771415664285, 'proxyLowerStageReward_min': -0.08952422068938867, 'proxyLowerStageReward_max': -0.04024749716562886, 'proxySmoothStageChangesReward_mean': -0.13497409326424872, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00037761658031088105, 'trueInfectionSummaryAbsoluteReward_min': -0.0017202072538860117, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.026389637305699484, 'truePoliticalReward_min': -0.07295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.06464771415664285, 'trueLowerStageReward_min': -0.08952422068938867, 'trueLowerStageReward_max': -0.04024749716562886, 'trueSmoothStageChangesReward_mean': -0.13497409326424872, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.170761175458803, 'total_modified_reward_min': -5.569407785175448, 'total_modified_reward_max': -1.457717897149064}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.2905259871731203, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.010065893158316613, 'policy_loss': -0.0027853517544766267, 'vf_loss': 0.050908747757979045, 'vf_explained_var': 0.4507662179072698, 'kl': 0.005982596279471056, 'entropy': 0.5177897350986799, 'entropy_coeff': 0.0638704}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 15750.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 204580, 'num_env_steps_trained': 204580, 'num_agent_steps_sampled': 204580, 'num_agent_steps_trained': 204580}, 'sampler_results': {'episode_reward_max': -1.457717897149064, 'episode_reward_min': -5.569407785175448, 'episode_reward_mean': -3.170761175458803, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -53.16900088322326, 'default_policy/true_reward_min': -142.44104076400856, 'default_policy/true_reward_max': -3.035330085889914, 'default_policy/proxy_reward_mean': -2.2370008832232067, 'default_policy/proxy_reward_min': -4.709264068711925, 'default_policy/proxy_reward_max': -0.9439213562373086, 'default_policy/modified_reward_mean': -3.170761175458803, 'default_policy/modified_reward_min': -5.569407785175448, 'default_policy/modified_reward_max': -1.457717897149064, 'default_policy/corr_btw_rewards_mean': 0.4787001343392388, 'default_policy/corr_btw_rewards_min': 0.11095595791622016, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -53.16900088322326, 'true_reward_min': -142.44104076400856, 'true_reward_max': -3.035330085889914, 'proxy_reward_mean': -2.2370008832232067, 'proxy_reward_min': -4.709264068711925, 'proxy_reward_max': -0.9439213562373086, 'modified_reward_mean': -3.170761175458803, 'modified_reward_min': -5.569407785175448, 'modified_reward_max': -1.457717897149064, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00037761658031088105, 'proxyInfectionSummaryAbsoluteReward_min': -0.0017202072538860117, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.06464771415664285, 'proxyLowerStageReward_min': -0.08952422068938867, 'proxyLowerStageReward_max': -0.04024749716562886, 'proxySmoothStageChangesReward_mean': -0.13497409326424872, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00037761658031088105, 'trueInfectionSummaryAbsoluteReward_min': -0.0017202072538860117, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.026389637305699484, 'truePoliticalReward_min': -0.07295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.06464771415664285, 'trueLowerStageReward_min': -0.08952422068938867, 'trueLowerStageReward_max': -0.04024749716562886, 'trueSmoothStageChangesReward_mean': -0.13497409326424872, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.170761175458803, 'total_modified_reward_min': -5.569407785175448, 'total_modified_reward_max': -1.457717897149064}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5300793859380272, 'mean_inference_ms': 1.6831914675665545, 'mean_action_processing_ms': 0.10705122925931423, 'mean_env_wait_ms': 760.5410076151544, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.457717897149064, 'episode_reward_min': -5.569407785175448, 'episode_reward_mean': -3.170761175458803, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5300793859380272, 'mean_inference_ms': 1.6831914675665545, 'mean_action_processing_ms': 0.10705122925931423, 'mean_env_wait_ms': 760.5410076151544, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 204580, 'num_agent_steps_trained': 204580, 'num_env_steps_sampled': 204580, 'num_env_steps_trained': 204580, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.360906421995947, 'num_env_steps_trained_throughput_per_sec': 12.360906421995947, 'timesteps_total': 204580, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 204580, 'timers': {'training_iteration_time_ms': 317190.773, 'sample_time_ms': 316127.404, 'load_time_ms': 5.653, 'load_throughput': 682846.334, 'learn_time_ms': 1040.224, 'learn_throughput': 3710.74, 'synch_weights_time_ms': 16.528}, 'counters': {'num_env_steps_sampled': 204580, 'num_env_steps_trained': 204580, 'num_agent_steps_sampled': 204580, 'num_agent_steps_trained': 204580}, 'done': False, 'episodes_total': 1060, 'training_iteration': 53, 'trial_id': 'default', 'date': '2025-11-04_23-34-41', 'timestamp': 1762328081, 'time_this_iter_s': 312.30015206336975, 'time_total_s': 16905.919068813324, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6882fd210>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6882fd000>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e1779d80>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e1779240>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 16905.919068813324, 'iterations_since_restore': 53, 'perf': {'cpu_util_percent': 18.81056179775281, 'ram_util_percent': 6.0}}
Iteration 54/100
{'custom_metrics': {'default_policy/true_reward_mean': -42.82938208819661, 'default_policy/true_reward_min': -142.44104076400856, 'default_policy/true_reward_max': -1.8274873734152903, 'default_policy/proxy_reward_mean': -2.265382088196589, 'default_policy/proxy_reward_min': -4.709264068711925, 'default_policy/proxy_reward_max': -0.9439213562373086, 'default_policy/modified_reward_mean': -3.1348552300964143, 'default_policy/modified_reward_min': -5.569407785175448, 'default_policy/modified_reward_max': -1.457717897149064, 'default_policy/corr_btw_rewards_mean': 0.4536507761147358, 'default_policy/corr_btw_rewards_min': 0.11095595791622016, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -42.82938208819661, 'true_reward_min': -142.44104076400856, 'true_reward_max': -1.8274873734152903, 'proxy_reward_mean': -2.265382088196589, 'proxy_reward_min': -4.709264068711925, 'proxy_reward_max': -0.9439213562373086, 'modified_reward_mean': -3.1348552300964143, 'modified_reward_min': -5.569407785175448, 'modified_reward_max': -1.457717897149064, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004417616580310884, 'proxyInfectionSummaryAbsoluteReward_min': -0.0017202072538860117, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.06114414964749166, 'proxyLowerStageReward_min': -0.08273323534337924, 'proxyLowerStageReward_max': -0.04024749716562886, 'proxySmoothStageChangesReward_mean': -0.1205699481865285, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004417616580310884, 'trueInfectionSummaryAbsoluteReward_min': -0.0017202072538860117, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.021017616580310882, 'truePoliticalReward_min': -0.07295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.06114414964749166, 'trueLowerStageReward_min': -0.08273323534337924, 'trueLowerStageReward_max': -0.04024749716562886, 'trueSmoothStageChangesReward_mean': -0.1205699481865285, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.1348552300964143, 'total_modified_reward_min': -5.569407785175448, 'total_modified_reward_max': -1.457717897149064}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.2132471562425295, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.019818839888709288, 'policy_loss': -0.004050056512157122, 'vf_loss': 0.03805423071840778, 'vf_explained_var': 0.5345637140671412, 'kl': 0.010060912880177892, 'entropy': 0.5597386729717254, 'entropy_coeff': 0.0631756}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 16050.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 208440, 'num_env_steps_trained': 208440, 'num_agent_steps_sampled': 208440, 'num_agent_steps_trained': 208440}, 'sampler_results': {'episode_reward_max': -1.457717897149064, 'episode_reward_min': -5.569407785175448, 'episode_reward_mean': -3.1348552300964143, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -42.82938208819661, 'default_policy/true_reward_min': -142.44104076400856, 'default_policy/true_reward_max': -1.8274873734152903, 'default_policy/proxy_reward_mean': -2.265382088196589, 'default_policy/proxy_reward_min': -4.709264068711925, 'default_policy/proxy_reward_max': -0.9439213562373086, 'default_policy/modified_reward_mean': -3.1348552300964143, 'default_policy/modified_reward_min': -5.569407785175448, 'default_policy/modified_reward_max': -1.457717897149064, 'default_policy/corr_btw_rewards_mean': 0.4536507761147358, 'default_policy/corr_btw_rewards_min': 0.11095595791622016, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -42.82938208819661, 'true_reward_min': -142.44104076400856, 'true_reward_max': -1.8274873734152903, 'proxy_reward_mean': -2.265382088196589, 'proxy_reward_min': -4.709264068711925, 'proxy_reward_max': -0.9439213562373086, 'modified_reward_mean': -3.1348552300964143, 'modified_reward_min': -5.569407785175448, 'modified_reward_max': -1.457717897149064, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004417616580310884, 'proxyInfectionSummaryAbsoluteReward_min': -0.0017202072538860117, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.06114414964749166, 'proxyLowerStageReward_min': -0.08273323534337924, 'proxyLowerStageReward_max': -0.04024749716562886, 'proxySmoothStageChangesReward_mean': -0.1205699481865285, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004417616580310884, 'trueInfectionSummaryAbsoluteReward_min': -0.0017202072538860117, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.021017616580310882, 'truePoliticalReward_min': -0.07295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.06114414964749166, 'trueLowerStageReward_min': -0.08273323534337924, 'trueLowerStageReward_max': -0.04024749716562886, 'trueSmoothStageChangesReward_mean': -0.1205699481865285, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.1348552300964143, 'total_modified_reward_min': -5.569407785175448, 'total_modified_reward_max': -1.457717897149064}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5301703320647262, 'mean_inference_ms': 1.6828217556441631, 'mean_action_processing_ms': 0.1069915754355397, 'mean_env_wait_ms': 759.3841544630606, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.457717897149064, 'episode_reward_min': -5.569407785175448, 'episode_reward_mean': -3.1348552300964143, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5301703320647262, 'mean_inference_ms': 1.6828217556441631, 'mean_action_processing_ms': 0.1069915754355397, 'mean_env_wait_ms': 759.3841544630606, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 208440, 'num_agent_steps_trained': 208440, 'num_env_steps_sampled': 208440, 'num_env_steps_trained': 208440, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.717039548481093, 'num_env_steps_trained_throughput_per_sec': 12.717039548481093, 'timesteps_total': 208440, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 208440, 'timers': {'training_iteration_time_ms': 314177.958, 'sample_time_ms': 313115.542, 'load_time_ms': 5.293, 'load_throughput': 729302.881, 'learn_time_ms': 1039.463, 'learn_throughput': 3713.456, 'synch_weights_time_ms': 16.763}, 'counters': {'num_env_steps_sampled': 208440, 'num_env_steps_trained': 208440, 'num_agent_steps_sampled': 208440, 'num_agent_steps_trained': 208440}, 'done': False, 'episodes_total': 1080, 'training_iteration': 54, 'trial_id': 'default', 'date': '2025-11-04_23-39-45', 'timestamp': 1762328385, 'time_this_iter_s': 303.54617834091187, 'time_total_s': 17209.465247154236, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e26325f0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e2632710>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2632ce0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2633ee0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 17209.465247154236, 'iterations_since_restore': 54, 'perf': {'cpu_util_percent': 19.361200923787532, 'ram_util_percent': 6.0}}
Iteration 55/100
{'custom_metrics': {'default_policy/true_reward_mean': -33.86204096269964, 'default_policy/true_reward_min': -112.0999747468307, 'default_policy/true_reward_max': -1.354264068711927, 'default_policy/proxy_reward_mean': -2.282040962699635, 'default_policy/proxy_reward_min': -4.709264068711925, 'default_policy/proxy_reward_max': -0.9439213562373086, 'default_policy/modified_reward_mean': -3.1041772349191787, 'default_policy/modified_reward_min': -5.569407785175448, 'default_policy/modified_reward_max': -1.457717897149064, 'default_policy/corr_btw_rewards_mean': 0.4064594600439158, 'default_policy/corr_btw_rewards_min': 0.10159462428067179, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -33.86204096269964, 'true_reward_min': -112.0999747468307, 'true_reward_max': -1.354264068711927, 'proxy_reward_mean': -2.282040962699635, 'proxy_reward_min': -4.709264068711925, 'proxy_reward_max': -0.9439213562373086, 'modified_reward_mean': -3.1041772349191787, 'modified_reward_min': -5.569407785175448, 'modified_reward_max': -1.457717897149064, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00048766839378238373, 'proxyInfectionSummaryAbsoluteReward_min': -0.0017202072538860117, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.05837517941448885, 'proxyLowerStageReward_min': -0.07594224999736983, 'proxyLowerStageReward_max': -0.04002525250856434, 'proxySmoothStageChangesReward_mean': -0.11098445595854922, 'proxySmoothStageChangesReward_min': -0.18652849740932642, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00048766839378238373, 'trueInfectionSummaryAbsoluteReward_min': -0.0017202072538860117, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.016362694300518132, 'truePoliticalReward_min': -0.0572020725388601, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.05837517941448885, 'trueLowerStageReward_min': -0.07594224999736983, 'trueLowerStageReward_max': -0.04002525250856434, 'trueSmoothStageChangesReward_mean': -0.11098445595854922, 'trueSmoothStageChangesReward_min': -0.18652849740932642, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.1041772349191787, 'total_modified_reward_min': -5.569407785175448, 'total_modified_reward_max': -1.457717897149064}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.1153545917073886, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.01894583255983889, 'policy_loss': -0.0017897226537267367, 'vf_loss': 0.03225729403862109, 'vf_explained_var': 0.5837859596808751, 'kl': 0.005134390686984324, 'entropy': 0.5373421344161033, 'entropy_coeff': 0.06248080000000002}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 16350.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 212300, 'num_env_steps_trained': 212300, 'num_agent_steps_sampled': 212300, 'num_agent_steps_trained': 212300}, 'sampler_results': {'episode_reward_max': -1.457717897149064, 'episode_reward_min': -5.569407785175448, 'episode_reward_mean': -3.1041772349191787, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -33.86204096269964, 'default_policy/true_reward_min': -112.0999747468307, 'default_policy/true_reward_max': -1.354264068711927, 'default_policy/proxy_reward_mean': -2.282040962699635, 'default_policy/proxy_reward_min': -4.709264068711925, 'default_policy/proxy_reward_max': -0.9439213562373086, 'default_policy/modified_reward_mean': -3.1041772349191787, 'default_policy/modified_reward_min': -5.569407785175448, 'default_policy/modified_reward_max': -1.457717897149064, 'default_policy/corr_btw_rewards_mean': 0.4064594600439158, 'default_policy/corr_btw_rewards_min': 0.10159462428067179, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -33.86204096269964, 'true_reward_min': -112.0999747468307, 'true_reward_max': -1.354264068711927, 'proxy_reward_mean': -2.282040962699635, 'proxy_reward_min': -4.709264068711925, 'proxy_reward_max': -0.9439213562373086, 'modified_reward_mean': -3.1041772349191787, 'modified_reward_min': -5.569407785175448, 'modified_reward_max': -1.457717897149064, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00048766839378238373, 'proxyInfectionSummaryAbsoluteReward_min': -0.0017202072538860117, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.05837517941448885, 'proxyLowerStageReward_min': -0.07594224999736983, 'proxyLowerStageReward_max': -0.04002525250856434, 'proxySmoothStageChangesReward_mean': -0.11098445595854922, 'proxySmoothStageChangesReward_min': -0.18652849740932642, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00048766839378238373, 'trueInfectionSummaryAbsoluteReward_min': -0.0017202072538860117, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.016362694300518132, 'truePoliticalReward_min': -0.0572020725388601, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.05837517941448885, 'trueLowerStageReward_min': -0.07594224999736983, 'trueLowerStageReward_max': -0.04002525250856434, 'trueSmoothStageChangesReward_mean': -0.11098445595854922, 'trueSmoothStageChangesReward_min': -0.18652849740932642, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.1041772349191787, 'total_modified_reward_min': -5.569407785175448, 'total_modified_reward_max': -1.457717897149064}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5301344555456861, 'mean_inference_ms': 1.6824721264463693, 'mean_action_processing_ms': 0.10693594002666024, 'mean_env_wait_ms': 758.3291045704464, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.457717897149064, 'episode_reward_min': -5.569407785175448, 'episode_reward_mean': -3.1041772349191787, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5301344555456861, 'mean_inference_ms': 1.6824721264463693, 'mean_action_processing_ms': 0.10693594002666024, 'mean_env_wait_ms': 758.3291045704464, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 212300, 'num_agent_steps_trained': 212300, 'num_env_steps_sampled': 212300, 'num_env_steps_trained': 212300, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.653283857726729, 'num_env_steps_trained_throughput_per_sec': 12.653283857726729, 'timesteps_total': 212300, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 212300, 'timers': {'training_iteration_time_ms': 312554.575, 'sample_time_ms': 311470.723, 'load_time_ms': 5.263, 'load_throughput': 733439.345, 'learn_time_ms': 1061.023, 'learn_throughput': 3637.998, 'synch_weights_time_ms': 16.632}, 'counters': {'num_env_steps_sampled': 212300, 'num_env_steps_trained': 212300, 'num_agent_steps_sampled': 212300, 'num_agent_steps_trained': 212300}, 'done': False, 'episodes_total': 1100, 'training_iteration': 55, 'trial_id': 'default', 'date': '2025-11-04_23-44-50', 'timestamp': 1762328690, 'time_this_iter_s': 305.07910776138306, 'time_total_s': 17514.54435491562, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a699563b20>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6995627d0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2633700>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2630b20>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 17514.54435491562, 'iterations_since_restore': 55, 'perf': {'cpu_util_percent': 19.150574712643678, 'ram_util_percent': 6.0}}
Iteration 56/100
{'custom_metrics': {'default_policy/true_reward_mean': -27.04978486604523, 'default_policy/true_reward_min': -112.0999747468307, 'default_policy/true_reward_max': -1.354264068711927, 'default_policy/proxy_reward_mean': -2.3097848660452254, 'default_policy/proxy_reward_min': -4.863908729652593, 'default_policy/proxy_reward_max': -0.9439213562373086, 'default_policy/modified_reward_mean': -3.0928821138699414, 'default_policy/modified_reward_min': -5.604034572104419, 'default_policy/modified_reward_max': -1.4379089733446153, 'default_policy/corr_btw_rewards_mean': 0.3723861775991446, 'default_policy/corr_btw_rewards_min': 0.10159462428067179, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -27.04978486604523, 'true_reward_min': -112.0999747468307, 'true_reward_max': -1.354264068711927, 'proxy_reward_mean': -2.3097848660452254, 'proxy_reward_min': -4.863908729652593, 'proxy_reward_max': -0.9439213562373086, 'modified_reward_mean': -3.0928821138699414, 'modified_reward_min': -5.604034572104419, 'modified_reward_max': -1.4379089733446153, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0005337823834196895, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.05587486352565932, 'proxyLowerStageReward_min': -0.07594224999736983, 'proxyLowerStageReward_max': -0.03560269608061991, 'proxySmoothStageChangesReward_mean': -0.10424870466321245, 'proxySmoothStageChangesReward_min': -0.16580310880829016, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0005337823834196895, 'trueInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.012818652849740935, 'truePoliticalReward_min': -0.0572020725388601, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.05587486352565932, 'trueLowerStageReward_min': -0.07594224999736983, 'trueLowerStageReward_max': -0.03560269608061991, 'trueSmoothStageChangesReward_mean': -0.10424870466321245, 'trueSmoothStageChangesReward_min': -0.16580310880829016, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.0928821138699414, 'total_modified_reward_min': -5.604034572104419, 'total_modified_reward_max': -1.4379089733446153}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.2522500036160151, 'cur_kl_coeff': 0.056250000000000015, 'cur_lr': 0.0003, 'total_loss': -0.011940119024414646, 'policy_loss': -0.0013059676997363566, 'vf_loss': 0.04375044615861649, 'vf_explained_var': 0.5635310890277226, 'kl': 0.004024655231231761, 'entropy': 0.529824883143107, 'entropy_coeff': 0.061785999999999994}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 16650.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 216160, 'num_env_steps_trained': 216160, 'num_agent_steps_sampled': 216160, 'num_agent_steps_trained': 216160}, 'sampler_results': {'episode_reward_max': -1.4379089733446153, 'episode_reward_min': -5.604034572104419, 'episode_reward_mean': -3.0928821138699414, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -27.04978486604523, 'default_policy/true_reward_min': -112.0999747468307, 'default_policy/true_reward_max': -1.354264068711927, 'default_policy/proxy_reward_mean': -2.3097848660452254, 'default_policy/proxy_reward_min': -4.863908729652593, 'default_policy/proxy_reward_max': -0.9439213562373086, 'default_policy/modified_reward_mean': -3.0928821138699414, 'default_policy/modified_reward_min': -5.604034572104419, 'default_policy/modified_reward_max': -1.4379089733446153, 'default_policy/corr_btw_rewards_mean': 0.3723861775991446, 'default_policy/corr_btw_rewards_min': 0.10159462428067179, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -27.04978486604523, 'true_reward_min': -112.0999747468307, 'true_reward_max': -1.354264068711927, 'proxy_reward_mean': -2.3097848660452254, 'proxy_reward_min': -4.863908729652593, 'proxy_reward_max': -0.9439213562373086, 'modified_reward_mean': -3.0928821138699414, 'modified_reward_min': -5.604034572104419, 'modified_reward_max': -1.4379089733446153, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0005337823834196895, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.05587486352565932, 'proxyLowerStageReward_min': -0.07594224999736983, 'proxyLowerStageReward_max': -0.03560269608061991, 'proxySmoothStageChangesReward_mean': -0.10424870466321245, 'proxySmoothStageChangesReward_min': -0.16580310880829016, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0005337823834196895, 'trueInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.012818652849740935, 'truePoliticalReward_min': -0.0572020725388601, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.05587486352565932, 'trueLowerStageReward_min': -0.07594224999736983, 'trueLowerStageReward_max': -0.03560269608061991, 'trueSmoothStageChangesReward_mean': -0.10424870466321245, 'trueSmoothStageChangesReward_min': -0.16580310880829016, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.0928821138699414, 'total_modified_reward_min': -5.604034572104419, 'total_modified_reward_max': -1.4379089733446153}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5308596154443184, 'mean_inference_ms': 1.6820829438609837, 'mean_action_processing_ms': 0.10688885077359059, 'mean_env_wait_ms': 757.2877667892109, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.4379089733446153, 'episode_reward_min': -5.604034572104419, 'episode_reward_mean': -3.0928821138699414, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5308596154443184, 'mean_inference_ms': 1.6820829438609837, 'mean_action_processing_ms': 0.10688885077359059, 'mean_env_wait_ms': 757.2877667892109, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 216160, 'num_agent_steps_trained': 216160, 'num_env_steps_sampled': 216160, 'num_env_steps_trained': 216160, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.12770269469255, 'num_env_steps_trained_throughput_per_sec': 12.12770269469255, 'timesteps_total': 216160, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 216160, 'timers': {'training_iteration_time_ms': 312388.184, 'sample_time_ms': 311303.971, 'load_time_ms': 5.036, 'load_throughput': 766438.334, 'learn_time_ms': 1061.734, 'learn_throughput': 3635.561, 'synch_weights_time_ms': 16.563}, 'counters': {'num_env_steps_sampled': 216160, 'num_env_steps_trained': 216160, 'num_agent_steps_sampled': 216160, 'num_agent_steps_trained': 216160}, 'done': False, 'episodes_total': 1120, 'training_iteration': 56, 'trial_id': 'default', 'date': '2025-11-04_23-50-08', 'timestamp': 1762329008, 'time_this_iter_s': 318.3034930229187, 'time_total_s': 17832.847847938538, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6a9cdb940>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6a9256770>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6882ff700>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6882fe6b0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 17832.847847938538, 'iterations_since_restore': 56, 'perf': {'cpu_util_percent': 18.633039647577093, 'ram_util_percent': 6.0}}
Iteration 57/100
{'custom_metrics': {'default_policy/true_reward_mean': -22.906928011795728, 'default_policy/true_reward_min': -70.38783008588999, 'default_policy/true_reward_max': -1.354264068711927, 'default_policy/proxy_reward_mean': -2.286928011795733, 'default_policy/proxy_reward_min': -4.863908729652593, 'default_policy/proxy_reward_max': -0.8321320343559635, 'default_policy/modified_reward_mean': -3.0474035976250597, 'default_policy/modified_reward_min': -5.604034572104419, 'default_policy/modified_reward_max': -1.3363989912905898, 'default_policy/corr_btw_rewards_mean': 0.37199279478594266, 'default_policy/corr_btw_rewards_min': 0.10159462428067179, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -22.906928011795728, 'true_reward_min': -70.38783008588999, 'true_reward_max': -1.354264068711927, 'proxy_reward_mean': -2.286928011795733, 'proxy_reward_min': -4.863908729652593, 'proxy_reward_max': -0.8321320343559635, 'modified_reward_mean': -3.0474035976250597, 'modified_reward_min': -5.604034572104419, 'modified_reward_max': -1.3363989912905898, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0005414507772020728, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.054182798538638985, 'proxyLowerStageReward_min': -0.07399924481602267, 'proxyLowerStageReward_max': -0.03560269608061991, 'proxySmoothStageChangesReward_mean': -0.10165803108808291, 'proxySmoothStageChangesReward_min': -0.16580310880829016, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0005414507772020728, 'trueInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010683937823834198, 'truePoliticalReward_min': -0.03523316062176166, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.054182798538638985, 'trueLowerStageReward_min': -0.07399924481602267, 'trueLowerStageReward_max': -0.03560269608061991, 'trueSmoothStageChangesReward_mean': -0.10165803108808291, 'trueSmoothStageChangesReward_min': -0.16580310880829016, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.0474035976250597, 'total_modified_reward_min': -5.604034572104419, 'total_modified_reward_max': -1.3363989912905898}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.2432557310163974, 'cur_kl_coeff': 0.028125000000000008, 'cur_lr': 0.0003, 'total_loss': -0.01952959906697894, 'policy_loss': -0.003841766572246949, 'vf_loss': 0.0381761044174588, 'vf_explained_var': 0.5001406174898148, 'kl': 0.007404782731020978, 'entropy': 0.5726544051369031, 'entropy_coeff': 0.0610912}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 16950.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 220020, 'num_env_steps_trained': 220020, 'num_agent_steps_sampled': 220020, 'num_agent_steps_trained': 220020}, 'sampler_results': {'episode_reward_max': -1.3363989912905898, 'episode_reward_min': -5.604034572104419, 'episode_reward_mean': -3.0474035976250597, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -22.906928011795728, 'default_policy/true_reward_min': -70.38783008588999, 'default_policy/true_reward_max': -1.354264068711927, 'default_policy/proxy_reward_mean': -2.286928011795733, 'default_policy/proxy_reward_min': -4.863908729652593, 'default_policy/proxy_reward_max': -0.8321320343559635, 'default_policy/modified_reward_mean': -3.0474035976250597, 'default_policy/modified_reward_min': -5.604034572104419, 'default_policy/modified_reward_max': -1.3363989912905898, 'default_policy/corr_btw_rewards_mean': 0.37199279478594266, 'default_policy/corr_btw_rewards_min': 0.10159462428067179, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -22.906928011795728, 'true_reward_min': -70.38783008588999, 'true_reward_max': -1.354264068711927, 'proxy_reward_mean': -2.286928011795733, 'proxy_reward_min': -4.863908729652593, 'proxy_reward_max': -0.8321320343559635, 'modified_reward_mean': -3.0474035976250597, 'modified_reward_min': -5.604034572104419, 'modified_reward_max': -1.3363989912905898, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0005414507772020728, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.054182798538638985, 'proxyLowerStageReward_min': -0.07399924481602267, 'proxyLowerStageReward_max': -0.03560269608061991, 'proxySmoothStageChangesReward_mean': -0.10165803108808291, 'proxySmoothStageChangesReward_min': -0.16580310880829016, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0005414507772020728, 'trueInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010683937823834198, 'truePoliticalReward_min': -0.03523316062176166, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.054182798538638985, 'trueLowerStageReward_min': -0.07399924481602267, 'trueLowerStageReward_max': -0.03560269608061991, 'trueSmoothStageChangesReward_mean': -0.10165803108808291, 'trueSmoothStageChangesReward_min': -0.16580310880829016, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.0474035976250597, 'total_modified_reward_min': -5.604034572104419, 'total_modified_reward_max': -1.3363989912905898}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5313310388657435, 'mean_inference_ms': 1.6817730036905372, 'mean_action_processing_ms': 0.1068597175990352, 'mean_env_wait_ms': 756.3002976037184, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.3363989912905898, 'episode_reward_min': -5.604034572104419, 'episode_reward_mean': -3.0474035976250597, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5313310388657435, 'mean_inference_ms': 1.6817730036905372, 'mean_action_processing_ms': 0.1068597175990352, 'mean_env_wait_ms': 756.3002976037184, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 220020, 'num_agent_steps_trained': 220020, 'num_env_steps_sampled': 220020, 'num_env_steps_trained': 220020, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.480751532601483, 'num_env_steps_trained_throughput_per_sec': 12.480751532601483, 'timesteps_total': 220020, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 220020, 'timers': {'training_iteration_time_ms': 312962.582, 'sample_time_ms': 311897.98, 'load_time_ms': 5.041, 'load_throughput': 765655.415, 'learn_time_ms': 1042.136, 'learn_throughput': 3703.93, 'synch_weights_time_ms': 16.54}, 'counters': {'num_env_steps_sampled': 220020, 'num_env_steps_trained': 220020, 'num_agent_steps_sampled': 220020, 'num_agent_steps_trained': 220020}, 'done': False, 'episodes_total': 1140, 'training_iteration': 57, 'trial_id': 'default', 'date': '2025-11-04_23-55-18', 'timestamp': 1762329318, 'time_this_iter_s': 309.2988851070404, 'time_total_s': 18142.146733045578, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e0ffcaf0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e0ffd1b0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0fff220>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffe530>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 18142.146733045578, 'iterations_since_restore': 57, 'perf': {'cpu_util_percent': 18.985000000000003, 'ram_util_percent': 6.0}}
Iteration 58/100
{'custom_metrics': {'default_policy/true_reward_mean': -21.95648106012293, 'default_policy/true_reward_min': -70.38783008588999, 'default_policy/true_reward_max': -1.354264068711927, 'default_policy/proxy_reward_mean': -2.3444810601229378, 'default_policy/proxy_reward_min': -5.245330085889914, 'default_policy/proxy_reward_max': -0.8321320343559635, 'default_policy/modified_reward_mean': -3.117638199984259, 'default_policy/modified_reward_min': -6.229687137252949, 'default_policy/modified_reward_max': -1.3363989912905898, 'default_policy/corr_btw_rewards_mean': 0.3673397858071868, 'default_policy/corr_btw_rewards_min': 0.09531971211042192, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -21.95648106012293, 'true_reward_min': -70.38783008588999, 'true_reward_max': -1.354264068711927, 'proxy_reward_mean': -2.3444810601229378, 'proxy_reward_min': -5.245330085889914, 'proxy_reward_max': -0.8321320343559635, 'modified_reward_mean': -3.117638199984259, 'modified_reward_min': -6.229687137252949, 'modified_reward_max': -1.3363989912905898, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0005616580310880832, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.054843578244711776, 'proxyLowerStageReward_min': -0.07399924481602267, 'proxyLowerStageReward_max': -0.03560269608061991, 'proxySmoothStageChangesReward_mean': -0.10466321243523317, 'proxySmoothStageChangesReward_min': -0.16580310880829016, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0005616580310880832, 'trueInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010161658031088084, 'truePoliticalReward_min': -0.03523316062176166, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.054843578244711776, 'trueLowerStageReward_min': -0.07399924481602267, 'trueLowerStageReward_max': -0.03560269608061991, 'trueSmoothStageChangesReward_mean': -0.10466321243523317, 'trueSmoothStageChangesReward_min': -0.16580310880829016, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.117638199984259, 'total_modified_reward_min': -6.229687137252949, 'total_modified_reward_max': -1.3363989912905898}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.3273417802651724, 'cur_kl_coeff': 0.028125000000000008, 'cur_lr': 0.0003, 'total_loss': -0.017068578144535423, 'policy_loss': -0.005290246202299992, 'vf_loss': 0.04623832410162625, 'vf_explained_var': 0.42642635862032574, 'kl': 0.010053723363039875, 'entropy': 0.5824892758329709, 'entropy_coeff': 0.06039640000000001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 17250.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 223880, 'num_env_steps_trained': 223880, 'num_agent_steps_sampled': 223880, 'num_agent_steps_trained': 223880}, 'sampler_results': {'episode_reward_max': -1.3363989912905898, 'episode_reward_min': -6.229687137252949, 'episode_reward_mean': -3.117638199984259, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -21.95648106012293, 'default_policy/true_reward_min': -70.38783008588999, 'default_policy/true_reward_max': -1.354264068711927, 'default_policy/proxy_reward_mean': -2.3444810601229378, 'default_policy/proxy_reward_min': -5.245330085889914, 'default_policy/proxy_reward_max': -0.8321320343559635, 'default_policy/modified_reward_mean': -3.117638199984259, 'default_policy/modified_reward_min': -6.229687137252949, 'default_policy/modified_reward_max': -1.3363989912905898, 'default_policy/corr_btw_rewards_mean': 0.3673397858071868, 'default_policy/corr_btw_rewards_min': 0.09531971211042192, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -21.95648106012293, 'true_reward_min': -70.38783008588999, 'true_reward_max': -1.354264068711927, 'proxy_reward_mean': -2.3444810601229378, 'proxy_reward_min': -5.245330085889914, 'proxy_reward_max': -0.8321320343559635, 'modified_reward_mean': -3.117638199984259, 'modified_reward_min': -6.229687137252949, 'modified_reward_max': -1.3363989912905898, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0005616580310880832, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.054843578244711776, 'proxyLowerStageReward_min': -0.07399924481602267, 'proxyLowerStageReward_max': -0.03560269608061991, 'proxySmoothStageChangesReward_mean': -0.10466321243523317, 'proxySmoothStageChangesReward_min': -0.16580310880829016, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0005616580310880832, 'trueInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010161658031088084, 'truePoliticalReward_min': -0.03523316062176166, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.054843578244711776, 'trueLowerStageReward_min': -0.07399924481602267, 'trueLowerStageReward_max': -0.03560269608061991, 'trueSmoothStageChangesReward_mean': -0.10466321243523317, 'trueSmoothStageChangesReward_min': -0.16580310880829016, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.117638199984259, 'total_modified_reward_min': -6.229687137252949, 'total_modified_reward_max': -1.3363989912905898}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5318490972125501, 'mean_inference_ms': 1.6814957495724001, 'mean_action_processing_ms': 0.10682334648439623, 'mean_env_wait_ms': 755.3806665164576, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.3363989912905898, 'episode_reward_min': -6.229687137252949, 'episode_reward_mean': -3.117638199984259, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5318490972125501, 'mean_inference_ms': 1.6814957495724001, 'mean_action_processing_ms': 0.10682334648439623, 'mean_env_wait_ms': 755.3806665164576, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 223880, 'num_agent_steps_trained': 223880, 'num_env_steps_sampled': 223880, 'num_env_steps_trained': 223880, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.962106345560509, 'num_env_steps_trained_throughput_per_sec': 12.962106345560509, 'timesteps_total': 223880, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 223880, 'timers': {'training_iteration_time_ms': 311911.568, 'sample_time_ms': 310847.515, 'load_time_ms': 5.004, 'load_throughput': 771335.015, 'learn_time_ms': 1041.648, 'learn_throughput': 3705.667, 'synch_weights_time_ms': 16.514}, 'counters': {'num_env_steps_sampled': 223880, 'num_env_steps_trained': 223880, 'num_agent_steps_sampled': 223880, 'num_agent_steps_trained': 223880}, 'done': False, 'episodes_total': 1160, 'training_iteration': 58, 'trial_id': 'default', 'date': '2025-11-05_00-00-16', 'timestamp': 1762329616, 'time_this_iter_s': 297.8123028278351, 'time_total_s': 18439.959035873413, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6a92059c0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699561120>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0f47310>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6a92062c0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 18439.959035873413, 'iterations_since_restore': 58, 'perf': {'cpu_util_percent': 19.5406103286385, 'ram_util_percent': 6.0}}
Iteration 59/100
{'custom_metrics': {'default_policy/true_reward_mean': -22.786858982184295, 'default_policy/true_reward_min': -70.38783008588999, 'default_policy/true_reward_max': -1.354264068711927, 'default_policy/proxy_reward_mean': -2.3148589821842953, 'default_policy/proxy_reward_min': -5.245330085889914, 'default_policy/proxy_reward_max': -0.8321320343559635, 'default_policy/modified_reward_mean': -3.0823631926227004, 'default_policy/modified_reward_min': -6.229687137252949, 'default_policy/modified_reward_max': -1.3363989912905898, 'default_policy/corr_btw_rewards_mean': 0.36147881018810213, 'default_policy/corr_btw_rewards_min': 0.09531971211042192, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -22.786858982184295, 'true_reward_min': -70.38783008588999, 'true_reward_max': -1.354264068711927, 'proxy_reward_mean': -2.3148589821842953, 'proxy_reward_min': -5.245330085889914, 'proxy_reward_max': -0.8321320343559635, 'modified_reward_mean': -3.0823631926227004, 'modified_reward_min': -6.229687137252949, 'modified_reward_max': -1.3363989912905898, 'proxyInfectionSummaryAbsoluteReward_mean': -0.000554611398963731, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.05367663120125882, 'proxyLowerStageReward_min': -0.08260304743743581, 'proxyLowerStageReward_max': -0.03560269608061991, 'proxySmoothStageChangesReward_mean': -0.10803108808290157, 'proxySmoothStageChangesReward_min': -0.23316062176165803, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.000554611398963731, 'trueInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010607253886010365, 'truePoliticalReward_min': -0.03523316062176166, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.05367663120125882, 'trueLowerStageReward_min': -0.08260304743743581, 'trueLowerStageReward_max': -0.03560269608061991, 'trueSmoothStageChangesReward_mean': -0.10803108808290157, 'trueSmoothStageChangesReward_min': -0.23316062176165803, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.0823631926227004, 'total_modified_reward_min': -6.229687137252949, 'total_modified_reward_max': -1.3363989912905898}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.2317629795273144, 'cur_kl_coeff': 0.028125000000000008, 'cur_lr': 0.0003, 'total_loss': -0.016068230445186297, 'policy_loss': -0.0011473370715975762, 'vf_loss': 0.041450474644855906, 'vf_explained_var': 0.4712567655245463, 'kl': 0.005270394651359553, 'entropy': 0.5995544970035553, 'entropy_coeff': 0.059701600000000014}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 17550.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 227740, 'num_env_steps_trained': 227740, 'num_agent_steps_sampled': 227740, 'num_agent_steps_trained': 227740}, 'sampler_results': {'episode_reward_max': -1.3363989912905898, 'episode_reward_min': -6.229687137252949, 'episode_reward_mean': -3.0823631926227004, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -22.786858982184295, 'default_policy/true_reward_min': -70.38783008588999, 'default_policy/true_reward_max': -1.354264068711927, 'default_policy/proxy_reward_mean': -2.3148589821842953, 'default_policy/proxy_reward_min': -5.245330085889914, 'default_policy/proxy_reward_max': -0.8321320343559635, 'default_policy/modified_reward_mean': -3.0823631926227004, 'default_policy/modified_reward_min': -6.229687137252949, 'default_policy/modified_reward_max': -1.3363989912905898, 'default_policy/corr_btw_rewards_mean': 0.36147881018810213, 'default_policy/corr_btw_rewards_min': 0.09531971211042192, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -22.786858982184295, 'true_reward_min': -70.38783008588999, 'true_reward_max': -1.354264068711927, 'proxy_reward_mean': -2.3148589821842953, 'proxy_reward_min': -5.245330085889914, 'proxy_reward_max': -0.8321320343559635, 'modified_reward_mean': -3.0823631926227004, 'modified_reward_min': -6.229687137252949, 'modified_reward_max': -1.3363989912905898, 'proxyInfectionSummaryAbsoluteReward_mean': -0.000554611398963731, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.05367663120125882, 'proxyLowerStageReward_min': -0.08260304743743581, 'proxyLowerStageReward_max': -0.03560269608061991, 'proxySmoothStageChangesReward_mean': -0.10803108808290157, 'proxySmoothStageChangesReward_min': -0.23316062176165803, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.000554611398963731, 'trueInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010607253886010365, 'truePoliticalReward_min': -0.03523316062176166, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.05367663120125882, 'trueLowerStageReward_min': -0.08260304743743581, 'trueLowerStageReward_max': -0.03560269608061991, 'trueSmoothStageChangesReward_mean': -0.10803108808290157, 'trueSmoothStageChangesReward_min': -0.23316062176165803, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.0823631926227004, 'total_modified_reward_min': -6.229687137252949, 'total_modified_reward_max': -1.3363989912905898}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.532388300218007, 'mean_inference_ms': 1.6812236361246442, 'mean_action_processing_ms': 0.10678969286051712, 'mean_env_wait_ms': 754.4756730320074, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.3363989912905898, 'episode_reward_min': -6.229687137252949, 'episode_reward_mean': -3.0823631926227004, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.532388300218007, 'mean_inference_ms': 1.6812236361246442, 'mean_action_processing_ms': 0.10678969286051712, 'mean_env_wait_ms': 754.4756730320074, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 227740, 'num_agent_steps_trained': 227740, 'num_env_steps_sampled': 227740, 'num_env_steps_trained': 227740, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.16455399745689, 'num_env_steps_trained_throughput_per_sec': 12.16455399745689, 'timesteps_total': 227740, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 227740, 'timers': {'training_iteration_time_ms': 310885.053, 'sample_time_ms': 309843.369, 'load_time_ms': 5.27, 'load_throughput': 732400.836, 'learn_time_ms': 1019.288, 'learn_throughput': 3786.956, 'synch_weights_time_ms': 16.275}, 'counters': {'num_env_steps_sampled': 227740, 'num_env_steps_trained': 227740, 'num_agent_steps_sampled': 227740, 'num_agent_steps_trained': 227740}, 'done': False, 'episodes_total': 1180, 'training_iteration': 59, 'trial_id': 'default', 'date': '2025-11-05_00-05-33', 'timestamp': 1762329933, 'time_this_iter_s': 317.34444975852966, 'time_total_s': 18757.303485631943, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e0f44d60>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6a9206170>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0f456f0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0f441c0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 18757.303485631943, 'iterations_since_restore': 59, 'perf': {'cpu_util_percent': 18.685398230088495, 'ram_util_percent': 6.0}}
Iteration 60/100
{'custom_metrics': {'default_policy/true_reward_mean': -21.95535860338675, 'default_policy/true_reward_min': -83.26889610306796, 'default_policy/true_reward_max': -1.7496194077712537, 'default_policy/proxy_reward_mean': -2.3473586033867546, 'default_policy/proxy_reward_min': -5.245330085889914, 'default_policy/proxy_reward_max': -0.8321320343559635, 'default_policy/modified_reward_mean': -3.124541295383798, 'default_policy/modified_reward_min': -6.229687137252949, 'default_policy/modified_reward_max': -1.3363989912905898, 'default_policy/corr_btw_rewards_mean': 0.3862916290860111, 'default_policy/corr_btw_rewards_min': 0.09531971211042192, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -21.95535860338675, 'true_reward_min': -83.26889610306796, 'true_reward_max': -1.7496194077712537, 'proxy_reward_mean': -2.3473586033867546, 'proxy_reward_min': -5.245330085889914, 'proxy_reward_max': -0.8321320343559635, 'modified_reward_mean': -3.124541295383798, 'modified_reward_min': -6.229687137252949, 'modified_reward_max': -1.3363989912905898, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0005644559585492231, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.05410666338791472, 'proxyLowerStageReward_min': -0.08260304743743581, 'proxyLowerStageReward_max': -0.03560269608061991, 'proxySmoothStageChangesReward_mean': -0.11072538860103628, 'proxySmoothStageChangesReward_min': -0.23316062176165803, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0005644559585492231, 'trueInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010159585492227978, 'truePoliticalReward_min': -0.04145077720207254, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.05410666338791472, 'trueLowerStageReward_min': -0.08260304743743581, 'trueLowerStageReward_max': -0.03560269608061991, 'trueSmoothStageChangesReward_mean': -0.11072538860103628, 'trueSmoothStageChangesReward_min': -0.23316062176165803, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.124541295383798, 'total_modified_reward_min': -6.229687137252949, 'total_modified_reward_max': -1.3363989912905898}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.4473699415723482, 'cur_kl_coeff': 0.028125000000000008, 'cur_lr': 0.0003, 'total_loss': -0.011358735176424186, 'policy_loss': -0.0002034377617140611, 'vf_loss': 0.051077513451843214, 'vf_explained_var': 0.5096081246932348, 'kl': 0.00993902885054944, 'entropy': 0.626598826845487, 'entropy_coeff': 0.05900680000000001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 17850.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 231600, 'num_env_steps_trained': 231600, 'num_agent_steps_sampled': 231600, 'num_agent_steps_trained': 231600}, 'sampler_results': {'episode_reward_max': -1.3363989912905898, 'episode_reward_min': -6.229687137252949, 'episode_reward_mean': -3.124541295383798, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -21.95535860338675, 'default_policy/true_reward_min': -83.26889610306796, 'default_policy/true_reward_max': -1.7496194077712537, 'default_policy/proxy_reward_mean': -2.3473586033867546, 'default_policy/proxy_reward_min': -5.245330085889914, 'default_policy/proxy_reward_max': -0.8321320343559635, 'default_policy/modified_reward_mean': -3.124541295383798, 'default_policy/modified_reward_min': -6.229687137252949, 'default_policy/modified_reward_max': -1.3363989912905898, 'default_policy/corr_btw_rewards_mean': 0.3862916290860111, 'default_policy/corr_btw_rewards_min': 0.09531971211042192, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -21.95535860338675, 'true_reward_min': -83.26889610306796, 'true_reward_max': -1.7496194077712537, 'proxy_reward_mean': -2.3473586033867546, 'proxy_reward_min': -5.245330085889914, 'proxy_reward_max': -0.8321320343559635, 'modified_reward_mean': -3.124541295383798, 'modified_reward_min': -6.229687137252949, 'modified_reward_max': -1.3363989912905898, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0005644559585492231, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.05410666338791472, 'proxyLowerStageReward_min': -0.08260304743743581, 'proxyLowerStageReward_max': -0.03560269608061991, 'proxySmoothStageChangesReward_mean': -0.11072538860103628, 'proxySmoothStageChangesReward_min': -0.23316062176165803, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0005644559585492231, 'trueInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010159585492227978, 'truePoliticalReward_min': -0.04145077720207254, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.05410666338791472, 'trueLowerStageReward_min': -0.08260304743743581, 'trueLowerStageReward_max': -0.03560269608061991, 'trueSmoothStageChangesReward_mean': -0.11072538860103628, 'trueSmoothStageChangesReward_min': -0.23316062176165803, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.124541295383798, 'total_modified_reward_min': -6.229687137252949, 'total_modified_reward_max': -1.3363989912905898}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5330116584440134, 'mean_inference_ms': 1.6809951959667415, 'mean_action_processing_ms': 0.10676613734537607, 'mean_env_wait_ms': 753.6202581407613, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.3363989912905898, 'episode_reward_min': -6.229687137252949, 'episode_reward_mean': -3.124541295383798, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5330116584440134, 'mean_inference_ms': 1.6809951959667415, 'mean_action_processing_ms': 0.10676613734537607, 'mean_env_wait_ms': 753.6202581407613, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 231600, 'num_agent_steps_trained': 231600, 'num_env_steps_sampled': 231600, 'num_env_steps_trained': 231600, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.9267262822196, 'num_env_steps_trained_throughput_per_sec': 12.9267262822196, 'timesteps_total': 231600, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 231600, 'timers': {'training_iteration_time_ms': 309697.638, 'sample_time_ms': 308657.009, 'load_time_ms': 4.891, 'load_throughput': 789175.458, 'learn_time_ms': 1018.218, 'learn_throughput': 3790.938, 'synch_weights_time_ms': 16.653}, 'counters': {'num_env_steps_sampled': 231600, 'num_env_steps_trained': 231600, 'num_agent_steps_sampled': 231600, 'num_agent_steps_trained': 231600}, 'done': False, 'episodes_total': 1200, 'training_iteration': 60, 'trial_id': 'default', 'date': '2025-11-05_00-10-32', 'timestamp': 1762330232, 'time_this_iter_s': 298.6316795349121, 'time_total_s': 19055.935165166855, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a699563a30>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699562590>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699535e10>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6995359c0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 19055.935165166855, 'iterations_since_restore': 60, 'perf': {'cpu_util_percent': 19.560563380281693, 'ram_util_percent': 6.0}}
Saved checkpoint to TrainingResult(checkpoint=Checkpoint(filesystem=local, path=logs/data/pandemic/20251104_185246/checkpoint_60), metrics={'custom_metrics': {'default_policy/true_reward_mean': -21.95535860338675, 'default_policy/true_reward_min': -83.26889610306796, 'default_policy/true_reward_max': -1.7496194077712537, 'default_policy/proxy_reward_mean': -2.3473586033867546, 'default_policy/proxy_reward_min': -5.245330085889914, 'default_policy/proxy_reward_max': -0.8321320343559635, 'default_policy/modified_reward_mean': -3.124541295383798, 'default_policy/modified_reward_min': -6.229687137252949, 'default_policy/modified_reward_max': -1.3363989912905898, 'default_policy/corr_btw_rewards_mean': 0.3862916290860111, 'default_policy/corr_btw_rewards_min': 0.09531971211042192, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -21.95535860338675, 'true_reward_min': -83.26889610306796, 'true_reward_max': -1.7496194077712537, 'proxy_reward_mean': -2.3473586033867546, 'proxy_reward_min': -5.245330085889914, 'proxy_reward_max': -0.8321320343559635, 'modified_reward_mean': -3.124541295383798, 'modified_reward_min': -6.229687137252949, 'modified_reward_max': -1.3363989912905898, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0005644559585492231, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.05410666338791472, 'proxyLowerStageReward_min': -0.08260304743743581, 'proxyLowerStageReward_max': -0.03560269608061991, 'proxySmoothStageChangesReward_mean': -0.11072538860103628, 'proxySmoothStageChangesReward_min': -0.23316062176165803, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0005644559585492231, 'trueInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010159585492227978, 'truePoliticalReward_min': -0.04145077720207254, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.05410666338791472, 'trueLowerStageReward_min': -0.08260304743743581, 'trueLowerStageReward_max': -0.03560269608061991, 'trueSmoothStageChangesReward_mean': -0.11072538860103628, 'trueSmoothStageChangesReward_min': -0.23316062176165803, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.124541295383798, 'total_modified_reward_min': -6.229687137252949, 'total_modified_reward_max': -1.3363989912905898}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.4473699415723482, 'cur_kl_coeff': 0.028125000000000008, 'cur_lr': 0.0003, 'total_loss': -0.011358735176424186, 'policy_loss': -0.0002034377617140611, 'vf_loss': 0.051077513451843214, 'vf_explained_var': 0.5096081246932348, 'kl': 0.00993902885054944, 'entropy': 0.626598826845487, 'entropy_coeff': 0.05900680000000001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 17850.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 231600, 'num_env_steps_trained': 231600, 'num_agent_steps_sampled': 231600, 'num_agent_steps_trained': 231600}, 'sampler_results': {'episode_reward_max': -1.3363989912905898, 'episode_reward_min': -6.229687137252949, 'episode_reward_mean': -3.124541295383798, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -21.95535860338675, 'default_policy/true_reward_min': -83.26889610306796, 'default_policy/true_reward_max': -1.7496194077712537, 'default_policy/proxy_reward_mean': -2.3473586033867546, 'default_policy/proxy_reward_min': -5.245330085889914, 'default_policy/proxy_reward_max': -0.8321320343559635, 'default_policy/modified_reward_mean': -3.124541295383798, 'default_policy/modified_reward_min': -6.229687137252949, 'default_policy/modified_reward_max': -1.3363989912905898, 'default_policy/corr_btw_rewards_mean': 0.3862916290860111, 'default_policy/corr_btw_rewards_min': 0.09531971211042192, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -21.95535860338675, 'true_reward_min': -83.26889610306796, 'true_reward_max': -1.7496194077712537, 'proxy_reward_mean': -2.3473586033867546, 'proxy_reward_min': -5.245330085889914, 'proxy_reward_max': -0.8321320343559635, 'modified_reward_mean': -3.124541295383798, 'modified_reward_min': -6.229687137252949, 'modified_reward_max': -1.3363989912905898, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0005644559585492231, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.05410666338791472, 'proxyLowerStageReward_min': -0.08260304743743581, 'proxyLowerStageReward_max': -0.03560269608061991, 'proxySmoothStageChangesReward_mean': -0.11072538860103628, 'proxySmoothStageChangesReward_min': -0.23316062176165803, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0005644559585492231, 'trueInfectionSummaryAbsoluteReward_min': -0.0019067357512953381, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010159585492227978, 'truePoliticalReward_min': -0.04145077720207254, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.05410666338791472, 'trueLowerStageReward_min': -0.08260304743743581, 'trueLowerStageReward_max': -0.03560269608061991, 'trueSmoothStageChangesReward_mean': -0.11072538860103628, 'trueSmoothStageChangesReward_min': -0.23316062176165803, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.124541295383798, 'total_modified_reward_min': -6.229687137252949, 'total_modified_reward_max': -1.3363989912905898}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5330116584440134, 'mean_inference_ms': 1.6809951959667415, 'mean_action_processing_ms': 0.10676613734537607, 'mean_env_wait_ms': 753.6202581407613, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.3363989912905898, 'episode_reward_min': -6.229687137252949, 'episode_reward_mean': -3.124541295383798, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5330116584440134, 'mean_inference_ms': 1.6809951959667415, 'mean_action_processing_ms': 0.10676613734537607, 'mean_env_wait_ms': 753.6202581407613, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 231600, 'num_agent_steps_trained': 231600, 'num_env_steps_sampled': 231600, 'num_env_steps_trained': 231600, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.9267262822196, 'num_env_steps_trained_throughput_per_sec': 12.9267262822196, 'timesteps_total': 231600, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 231600, 'timers': {'training_iteration_time_ms': 309697.638, 'sample_time_ms': 308657.009, 'load_time_ms': 4.891, 'load_throughput': 789175.458, 'learn_time_ms': 1018.218, 'learn_throughput': 3790.938, 'synch_weights_time_ms': 16.653}, 'counters': {'num_env_steps_sampled': 231600, 'num_env_steps_trained': 231600, 'num_agent_steps_sampled': 231600, 'num_agent_steps_trained': 231600}, 'done': False, 'episodes_total': 1200, 'training_iteration': 60, 'trial_id': 'default', 'date': '2025-11-05_00-10-32', 'timestamp': 1762330232, 'time_this_iter_s': 298.6316795349121, 'time_total_s': 19055.935165166855, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a699563a30>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699562590>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699535e10>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6995359c0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 19055.935165166855, 'iterations_since_restore': 60, 'perf': {'cpu_util_percent': 19.560563380281693, 'ram_util_percent': 6.0}})
Iteration 61/100
{'custom_metrics': {'default_policy/true_reward_mean': -22.348033603386753, 'default_policy/true_reward_min': -83.26889610306796, 'default_policy/true_reward_max': -1.7496194077712537, 'default_policy/proxy_reward_mean': -2.392033603386754, 'default_policy/proxy_reward_min': -5.333908729652602, 'default_policy/proxy_reward_max': -0.8321320343559635, 'default_policy/modified_reward_mean': -3.2014758865698103, 'default_policy/modified_reward_min': -6.316854895131972, 'default_policy/modified_reward_max': -1.3363989912905898, 'default_policy/corr_btw_rewards_mean': 0.3829119679279133, 'default_policy/corr_btw_rewards_min': 0.09531971211042192, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -22.348033603386753, 'true_reward_min': -83.26889610306796, 'true_reward_max': -1.7496194077712537, 'proxy_reward_mean': -2.392033603386754, 'proxy_reward_min': -5.333908729652602, 'proxy_reward_max': -0.8321320343559635, 'modified_reward_mean': -3.2014758865698103, 'modified_reward_min': -6.316854895131972, 'modified_reward_max': -1.3363989912905898, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0005572020725388605, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019170984455958563, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.05707946131537585, 'proxyLowerStageReward_min': -0.08260304743743581, 'proxyLowerStageReward_max': -0.03689803286818468, 'proxySmoothStageChangesReward_mean': -0.11139896373056996, 'proxySmoothStageChangesReward_min': -0.23316062176165803, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0005572020725388605, 'trueInfectionSummaryAbsoluteReward_min': -0.0019170984455958563, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010339896373056994, 'truePoliticalReward_min': -0.04145077720207254, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.05707946131537585, 'trueLowerStageReward_min': -0.08260304743743581, 'trueLowerStageReward_max': -0.03689803286818468, 'trueSmoothStageChangesReward_mean': -0.11139896373056996, 'trueSmoothStageChangesReward_min': -0.23316062176165803, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.2014758865698103, 'total_modified_reward_min': -6.316854895131972, 'total_modified_reward_max': -1.3363989912905898}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0962787597874801, 'cur_kl_coeff': 0.028125000000000008, 'cur_lr': 0.0003, 'total_loss': -0.028592070977513987, 'policy_loss': -0.007889704508706928, 'vf_loss': 0.034532247361494225, 'vf_explained_var': 0.49524948139985403, 'kl': 0.013479314041966593, 'entropy': 0.6576278886198997, 'entropy_coeff': 0.05831200000000002}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 18150.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 235460, 'num_env_steps_trained': 235460, 'num_agent_steps_sampled': 235460, 'num_agent_steps_trained': 235460}, 'sampler_results': {'episode_reward_max': -1.3363989912905898, 'episode_reward_min': -6.316854895131972, 'episode_reward_mean': -3.2014758865698103, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -22.348033603386753, 'default_policy/true_reward_min': -83.26889610306796, 'default_policy/true_reward_max': -1.7496194077712537, 'default_policy/proxy_reward_mean': -2.392033603386754, 'default_policy/proxy_reward_min': -5.333908729652602, 'default_policy/proxy_reward_max': -0.8321320343559635, 'default_policy/modified_reward_mean': -3.2014758865698103, 'default_policy/modified_reward_min': -6.316854895131972, 'default_policy/modified_reward_max': -1.3363989912905898, 'default_policy/corr_btw_rewards_mean': 0.3829119679279133, 'default_policy/corr_btw_rewards_min': 0.09531971211042192, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -22.348033603386753, 'true_reward_min': -83.26889610306796, 'true_reward_max': -1.7496194077712537, 'proxy_reward_mean': -2.392033603386754, 'proxy_reward_min': -5.333908729652602, 'proxy_reward_max': -0.8321320343559635, 'modified_reward_mean': -3.2014758865698103, 'modified_reward_min': -6.316854895131972, 'modified_reward_max': -1.3363989912905898, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0005572020725388605, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019170984455958563, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.05707946131537585, 'proxyLowerStageReward_min': -0.08260304743743581, 'proxyLowerStageReward_max': -0.03689803286818468, 'proxySmoothStageChangesReward_mean': -0.11139896373056996, 'proxySmoothStageChangesReward_min': -0.23316062176165803, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0005572020725388605, 'trueInfectionSummaryAbsoluteReward_min': -0.0019170984455958563, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010339896373056994, 'truePoliticalReward_min': -0.04145077720207254, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.05707946131537585, 'trueLowerStageReward_min': -0.08260304743743581, 'trueLowerStageReward_max': -0.03689803286818468, 'trueSmoothStageChangesReward_mean': -0.11139896373056996, 'trueSmoothStageChangesReward_min': -0.23316062176165803, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.2014758865698103, 'total_modified_reward_min': -6.316854895131972, 'total_modified_reward_max': -1.3363989912905898}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5329374274002595, 'mean_inference_ms': 1.680799208787635, 'mean_action_processing_ms': 0.10674785409942772, 'mean_env_wait_ms': 752.8228219176668, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.3363989912905898, 'episode_reward_min': -6.316854895131972, 'episode_reward_mean': -3.2014758865698103, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5329374274002595, 'mean_inference_ms': 1.680799208787635, 'mean_action_processing_ms': 0.10674785409942772, 'mean_env_wait_ms': 752.8228219176668, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 235460, 'num_agent_steps_trained': 235460, 'num_env_steps_sampled': 235460, 'num_env_steps_trained': 235460, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.583480884174916, 'num_env_steps_trained_throughput_per_sec': 12.583480884174916, 'timesteps_total': 235460, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 235460, 'timers': {'training_iteration_time_ms': 308481.732, 'sample_time_ms': 307446.967, 'load_time_ms': 5.005, 'load_throughput': 771195.397, 'learn_time_ms': 1012.292, 'learn_throughput': 3813.13, 'synch_weights_time_ms': 16.598}, 'counters': {'num_env_steps_sampled': 235460, 'num_env_steps_trained': 235460, 'num_agent_steps_sampled': 235460, 'num_agent_steps_trained': 235460}, 'done': False, 'episodes_total': 1220, 'training_iteration': 61, 'trial_id': 'default', 'date': '2025-11-05_00-15-39', 'timestamp': 1762330539, 'time_this_iter_s': 306.76804661750793, 'time_total_s': 19362.703211784363, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e1287580>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14cba9d0d9f0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e1287fa0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e1286ec0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 19362.703211784363, 'iterations_since_restore': 61, 'perf': {'cpu_util_percent': 19.126027397260277, 'ram_util_percent': 6.0}}
Iteration 62/100
{'custom_metrics': {'default_policy/true_reward_mean': -25.62694705935404, 'default_policy/true_reward_min': -89.7006854249493, 'default_policy/true_reward_max': -1.7496194077712537, 'default_policy/proxy_reward_mean': -2.438947059354044, 'default_policy/proxy_reward_min': -5.333908729652602, 'default_policy/proxy_reward_max': -0.8767766952966362, 'default_policy/modified_reward_mean': -3.284027637484062, 'default_policy/modified_reward_min': -6.316854895131972, 'default_policy/modified_reward_max': -1.3959259576793086, 'default_policy/corr_btw_rewards_mean': 0.37850275888290325, 'default_policy/corr_btw_rewards_min': 0.09531971211042192, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -25.62694705935404, 'true_reward_min': -89.7006854249493, 'true_reward_max': -1.7496194077712537, 'proxy_reward_mean': -2.438947059354044, 'proxy_reward_min': -5.333908729652602, 'proxy_reward_max': -0.8767766952966362, 'modified_reward_mean': -3.284027637484062, 'modified_reward_min': -6.316854895131972, 'modified_reward_max': -1.3959259576793086, 'proxyInfectionSummaryAbsoluteReward_mean': -0.000551709844559586, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019170984455958563, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.05954129841212665, 'proxyLowerStageReward_min': -0.09157834819926809, 'proxyLowerStageReward_max': -0.03884103804953183, 'proxySmoothStageChangesReward_mean': -0.11658031088082903, 'proxySmoothStageChangesReward_min': -0.23316062176165803, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.000551709844559586, 'trueInfectionSummaryAbsoluteReward_min': -0.0019170984455958563, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.012014507772020728, 'truePoliticalReward_min': -0.04559585492227978, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.05954129841212665, 'trueLowerStageReward_min': -0.09157834819926809, 'trueLowerStageReward_max': -0.03884103804953183, 'trueSmoothStageChangesReward_mean': -0.11658031088082903, 'trueSmoothStageChangesReward_min': -0.23316062176165803, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -3.284027637484062, 'total_modified_reward_min': -6.316854895131972, 'total_modified_reward_max': -1.3959259576793086}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.1905219980080923, 'cur_kl_coeff': 0.028125000000000008, 'cur_lr': 0.0003, 'total_loss': -0.02526786643390854, 'policy_loss': -0.008336606991166869, 'vf_loss': 0.036995669214908655, 'vf_explained_var': 0.5150027602910996, 'kl': 0.009169731950491394, 'entropy': 0.619380857249101, 'entropy_coeff': 0.05761720000000001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 18450.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 239320, 'num_env_steps_trained': 239320, 'num_agent_steps_sampled': 239320, 'num_agent_steps_trained': 239320}, 'sampler_results': {'episode_reward_max': -1.3959259576793086, 'episode_reward_min': -6.316854895131972, 'episode_reward_mean': -3.284027637484062, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -25.62694705935404, 'default_policy/true_reward_min': -89.7006854249493, 'default_policy/true_reward_max': -1.7496194077712537, 'default_policy/proxy_reward_mean': -2.438947059354044, 'default_policy/proxy_reward_min': -5.333908729652602, 'default_policy/proxy_reward_max': -0.8767766952966362, 'default_policy/modified_reward_mean': -3.284027637484062, 'default_policy/modified_reward_min': -6.316854895131972, 'default_policy/modified_reward_max': -1.3959259576793086, 'default_policy/corr_btw_rewards_mean': 0.37850275888290325, 'default_policy/corr_btw_rewards_min': 0.09531971211042192, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -25.62694705935404, 'true_reward_min': -89.7006854249493, 'true_reward_max': -1.7496194077712537, 'proxy_reward_mean': -2.438947059354044, 'proxy_reward_min': -5.333908729652602, 'proxy_reward_max': -0.8767766952966362, 'modified_reward_mean': -3.284027637484062, 'modified_reward_min': -6.316854895131972, 'modified_reward_max': -1.3959259576793086, 'proxyInfectionSummaryAbsoluteReward_mean': -0.000551709844559586, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019170984455958563, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.05954129841212665, 'proxyLowerStageReward_min': -0.09157834819926809, 'proxyLowerStageReward_max': -0.03884103804953183, 'proxySmoothStageChangesReward_mean': -0.11658031088082903, 'proxySmoothStageChangesReward_min': -0.23316062176165803, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.000551709844559586, 'trueInfectionSummaryAbsoluteReward_min': -0.0019170984455958563, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.012014507772020728, 'truePoliticalReward_min': -0.04559585492227978, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.05954129841212665, 'trueLowerStageReward_min': -0.09157834819926809, 'trueLowerStageReward_max': -0.03884103804953183, 'trueSmoothStageChangesReward_mean': -0.11658031088082903, 'trueSmoothStageChangesReward_min': -0.23316062176165803, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -3.284027637484062, 'total_modified_reward_min': -6.316854895131972, 'total_modified_reward_max': -1.3959259576793086}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.532888010562207, 'mean_inference_ms': 1.6805572469066454, 'mean_action_processing_ms': 0.1067332910912613, 'mean_env_wait_ms': 752.0507521271153, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.3959259576793086, 'episode_reward_min': -6.316854895131972, 'episode_reward_mean': -3.284027637484062, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.532888010562207, 'mean_inference_ms': 1.6805572469066454, 'mean_action_processing_ms': 0.1067332910912613, 'mean_env_wait_ms': 752.0507521271153, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 239320, 'num_agent_steps_trained': 239320, 'num_env_steps_sampled': 239320, 'num_env_steps_trained': 239320, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.771360682726998, 'num_env_steps_trained_throughput_per_sec': 12.771360682726998, 'timesteps_total': 239320, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 239320, 'timers': {'training_iteration_time_ms': 307112.139, 'sample_time_ms': 306086.026, 'load_time_ms': 4.934, 'load_throughput': 782269.858, 'learn_time_ms': 1003.891, 'learn_throughput': 3845.038, 'synch_weights_time_ms': 16.425}, 'counters': {'num_env_steps_sampled': 239320, 'num_env_steps_trained': 239320, 'num_agent_steps_sampled': 239320, 'num_agent_steps_trained': 239320}, 'done': False, 'episodes_total': 1240, 'training_iteration': 62, 'trial_id': 'default', 'date': '2025-11-05_00-20-41', 'timestamp': 1762330841, 'time_this_iter_s': 302.257107257843, 'time_total_s': 19664.960319042206, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e0fff580>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e0fff5e0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2632800>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6996121d0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 19664.960319042206, 'iterations_since_restore': 62, 'perf': {'cpu_util_percent': 19.14269141531323, 'ram_util_percent': 6.0}}
Iteration 63/100
{'custom_metrics': {'default_policy/true_reward_mean': -24.478618127165916, 'default_policy/true_reward_min': -89.7006854249493, 'default_policy/true_reward_max': -1.3239087296526006, 'default_policy/proxy_reward_mean': -2.3186181271659105, 'default_policy/proxy_reward_min': -5.333908729652602, 'default_policy/proxy_reward_max': -0.7364213562373092, 'default_policy/modified_reward_mean': -3.1616692495901115, 'default_policy/modified_reward_min': -6.316854895131972, 'default_policy/modified_reward_max': -1.1490427625542528, 'default_policy/corr_btw_rewards_mean': 0.3928279224149551, 'default_policy/corr_btw_rewards_min': 0.10801591125015228, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -24.478618127165916, 'true_reward_min': -89.7006854249493, 'true_reward_max': -1.3239087296526006, 'proxy_reward_mean': -2.3186181271659105, 'proxy_reward_min': -5.333908729652602, 'proxy_reward_max': -0.7364213562373092, 'modified_reward_mean': -3.1616692495901115, 'modified_reward_min': -6.316854895131972, 'modified_reward_max': -1.1490427625542528, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004917098445595858, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019170984455958563, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.059260006588907246, 'proxyLowerStageReward_min': -0.09157834819926809, 'proxyLowerStageReward_max': -0.03193893037499013, 'proxySmoothStageChangesReward_mean': -0.11704663212435236, 'proxySmoothStageChangesReward_min': -0.23316062176165803, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004917098445595858, 'trueInfectionSummaryAbsoluteReward_min': -0.0019170984455958563, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.011481865284974094, 'truePoliticalReward_min': -0.04559585492227978, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.059260006588907246, 'trueLowerStageReward_min': -0.09157834819926809, 'trueLowerStageReward_max': -0.03193893037499013, 'trueSmoothStageChangesReward_mean': -0.11704663212435236, 'trueSmoothStageChangesReward_min': -0.23316062176165803, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.1616692495901115, 'total_modified_reward_min': -6.316854895131972, 'total_modified_reward_max': -1.1490427625542528}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.1583341780304908, 'cur_kl_coeff': 0.028125000000000008, 'cur_lr': 0.0003, 'total_loss': -0.025891488219300905, 'policy_loss': -0.00822125240539511, 'vf_loss': 0.03116207522378924, 'vf_explained_var': 0.4930021768808365, 'kl': 0.00964474710959374, 'entropy': 0.5889162933826446, 'entropy_coeff': 0.056922400000000005}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 18750.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 243180, 'num_env_steps_trained': 243180, 'num_agent_steps_sampled': 243180, 'num_agent_steps_trained': 243180}, 'sampler_results': {'episode_reward_max': -1.1490427625542528, 'episode_reward_min': -6.316854895131972, 'episode_reward_mean': -3.1616692495901115, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -24.478618127165916, 'default_policy/true_reward_min': -89.7006854249493, 'default_policy/true_reward_max': -1.3239087296526006, 'default_policy/proxy_reward_mean': -2.3186181271659105, 'default_policy/proxy_reward_min': -5.333908729652602, 'default_policy/proxy_reward_max': -0.7364213562373092, 'default_policy/modified_reward_mean': -3.1616692495901115, 'default_policy/modified_reward_min': -6.316854895131972, 'default_policy/modified_reward_max': -1.1490427625542528, 'default_policy/corr_btw_rewards_mean': 0.3928279224149551, 'default_policy/corr_btw_rewards_min': 0.10801591125015228, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -24.478618127165916, 'true_reward_min': -89.7006854249493, 'true_reward_max': -1.3239087296526006, 'proxy_reward_mean': -2.3186181271659105, 'proxy_reward_min': -5.333908729652602, 'proxy_reward_max': -0.7364213562373092, 'modified_reward_mean': -3.1616692495901115, 'modified_reward_min': -6.316854895131972, 'modified_reward_max': -1.1490427625542528, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004917098445595858, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019170984455958563, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.059260006588907246, 'proxyLowerStageReward_min': -0.09157834819926809, 'proxyLowerStageReward_max': -0.03193893037499013, 'proxySmoothStageChangesReward_mean': -0.11704663212435236, 'proxySmoothStageChangesReward_min': -0.23316062176165803, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004917098445595858, 'trueInfectionSummaryAbsoluteReward_min': -0.0019170984455958563, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.011481865284974094, 'truePoliticalReward_min': -0.04559585492227978, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.059260006588907246, 'trueLowerStageReward_min': -0.09157834819926809, 'trueLowerStageReward_max': -0.03193893037499013, 'trueSmoothStageChangesReward_mean': -0.11704663212435236, 'trueSmoothStageChangesReward_min': -0.23316062176165803, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.1616692495901115, 'total_modified_reward_min': -6.316854895131972, 'total_modified_reward_max': -1.1490427625542528}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5328544388494464, 'mean_inference_ms': 1.6803573944444294, 'mean_action_processing_ms': 0.1067373852421197, 'mean_env_wait_ms': 751.308683285783, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.1490427625542528, 'episode_reward_min': -6.316854895131972, 'episode_reward_mean': -3.1616692495901115, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5328544388494464, 'mean_inference_ms': 1.6803573944444294, 'mean_action_processing_ms': 0.1067373852421197, 'mean_env_wait_ms': 751.308683285783, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 243180, 'num_agent_steps_trained': 243180, 'num_env_steps_sampled': 243180, 'num_env_steps_trained': 243180, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 11.48141740801304, 'num_env_steps_trained_throughput_per_sec': 11.48141740801304, 'timesteps_total': 243180, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 243180, 'timers': {'training_iteration_time_ms': 309504.199, 'sample_time_ms': 308479.624, 'load_time_ms': 4.836, 'load_throughput': 798174.575, 'learn_time_ms': 1002.487, 'learn_throughput': 3850.423, 'synch_weights_time_ms': 16.363}, 'counters': {'num_env_steps_sampled': 243180, 'num_env_steps_trained': 243180, 'num_agent_steps_sampled': 243180, 'num_agent_steps_trained': 243180}, 'done': False, 'episodes_total': 1260, 'training_iteration': 63, 'trial_id': 'default', 'date': '2025-11-05_00-26-18', 'timestamp': 1762331178, 'time_this_iter_s': 336.2220981121063, 'time_total_s': 20001.182417154312, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e0fff6d0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e0fff2e0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0fff1c0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffe1d0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 20001.182417154312, 'iterations_since_restore': 63, 'perf': {'cpu_util_percent': 18.274375000000003, 'ram_util_percent': 6.0}}
Iteration 64/100
{'custom_metrics': {'default_policy/true_reward_mean': -25.664578408540148, 'default_policy/true_reward_min': -89.7006854249493, 'default_policy/true_reward_max': -1.3239087296526006, 'default_policy/proxy_reward_mean': -2.2845784085401486, 'default_policy/proxy_reward_min': -5.333908729652602, 'default_policy/proxy_reward_max': -0.7364213562373092, 'default_policy/modified_reward_mean': -3.1366615433595477, 'default_policy/modified_reward_min': -6.316854895131972, 'default_policy/modified_reward_max': -1.1490427625542528, 'default_policy/corr_btw_rewards_mean': 0.39674592238009637, 'default_policy/corr_btw_rewards_min': 0.10801591125015228, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -25.664578408540148, 'true_reward_min': -89.7006854249493, 'true_reward_max': -1.3239087296526006, 'proxy_reward_mean': -2.2845784085401486, 'proxy_reward_min': -5.333908729652602, 'proxy_reward_max': -0.7364213562373092, 'modified_reward_mean': -3.1366615433595477, 'modified_reward_min': -6.316854895131972, 'modified_reward_max': -1.1490427625542528, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004678756476683941, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019170984455958563, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.05958955484663983, 'proxyLowerStageReward_min': -0.09157834819926809, 'proxyLowerStageReward_max': -0.03193893037499013, 'proxySmoothStageChangesReward_mean': -0.11994818652849742, 'proxySmoothStageChangesReward_min': -0.22797927461139897, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004678756476683941, 'trueInfectionSummaryAbsoluteReward_min': -0.0019170984455958563, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.012113989637305702, 'truePoliticalReward_min': -0.04559585492227978, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.05958955484663983, 'trueLowerStageReward_min': -0.09157834819926809, 'trueLowerStageReward_max': -0.03193893037499013, 'trueSmoothStageChangesReward_mean': -0.11994818652849742, 'trueSmoothStageChangesReward_min': -0.22797927461139897, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.1366615433595477, 'total_modified_reward_min': -6.316854895131972, 'total_modified_reward_max': -1.1490427625542528}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.1428459201256433, 'cur_kl_coeff': 0.028125000000000008, 'cur_lr': 0.0003, 'total_loss': -0.01879939383730137, 'policy_loss': -0.0032412700448185205, 'vf_loss': 0.03430618696108771, 'vf_explained_var': 0.5040369596083959, 'kl': 0.010233380068021875, 'entropy': 0.5868831732869149, 'entropy_coeff': 0.056227599999999996}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 19050.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 247040, 'num_env_steps_trained': 247040, 'num_agent_steps_sampled': 247040, 'num_agent_steps_trained': 247040}, 'sampler_results': {'episode_reward_max': -1.1490427625542528, 'episode_reward_min': -6.316854895131972, 'episode_reward_mean': -3.1366615433595477, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -25.664578408540148, 'default_policy/true_reward_min': -89.7006854249493, 'default_policy/true_reward_max': -1.3239087296526006, 'default_policy/proxy_reward_mean': -2.2845784085401486, 'default_policy/proxy_reward_min': -5.333908729652602, 'default_policy/proxy_reward_max': -0.7364213562373092, 'default_policy/modified_reward_mean': -3.1366615433595477, 'default_policy/modified_reward_min': -6.316854895131972, 'default_policy/modified_reward_max': -1.1490427625542528, 'default_policy/corr_btw_rewards_mean': 0.39674592238009637, 'default_policy/corr_btw_rewards_min': 0.10801591125015228, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -25.664578408540148, 'true_reward_min': -89.7006854249493, 'true_reward_max': -1.3239087296526006, 'proxy_reward_mean': -2.2845784085401486, 'proxy_reward_min': -5.333908729652602, 'proxy_reward_max': -0.7364213562373092, 'modified_reward_mean': -3.1366615433595477, 'modified_reward_min': -6.316854895131972, 'modified_reward_max': -1.1490427625542528, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004678756476683941, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019170984455958563, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.05958955484663983, 'proxyLowerStageReward_min': -0.09157834819926809, 'proxyLowerStageReward_max': -0.03193893037499013, 'proxySmoothStageChangesReward_mean': -0.11994818652849742, 'proxySmoothStageChangesReward_min': -0.22797927461139897, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004678756476683941, 'trueInfectionSummaryAbsoluteReward_min': -0.0019170984455958563, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.012113989637305702, 'truePoliticalReward_min': -0.04559585492227978, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.05958955484663983, 'trueLowerStageReward_min': -0.09157834819926809, 'trueLowerStageReward_max': -0.03193893037499013, 'trueSmoothStageChangesReward_mean': -0.11994818652849742, 'trueSmoothStageChangesReward_min': -0.22797927461139897, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -3.1366615433595477, 'total_modified_reward_min': -6.316854895131972, 'total_modified_reward_max': -1.1490427625542528}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5327273147257736, 'mean_inference_ms': 1.680147489478995, 'mean_action_processing_ms': 0.10672413797707662, 'mean_env_wait_ms': 750.5900890356984, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.1490427625542528, 'episode_reward_min': -6.316854895131972, 'episode_reward_mean': -3.1366615433595477, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5327273147257736, 'mean_inference_ms': 1.680147489478995, 'mean_action_processing_ms': 0.10672413797707662, 'mean_env_wait_ms': 750.5900890356984, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 247040, 'num_agent_steps_trained': 247040, 'num_env_steps_sampled': 247040, 'num_env_steps_trained': 247040, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.874760233634637, 'num_env_steps_trained_throughput_per_sec': 12.874760233634637, 'timesteps_total': 247040, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 247040, 'timers': {'training_iteration_time_ms': 309132.36, 'sample_time_ms': 308107.318, 'load_time_ms': 5.1, 'load_throughput': 756910.528, 'learn_time_ms': 1002.767, 'learn_throughput': 3849.348, 'synch_weights_time_ms': 16.283}, 'counters': {'num_env_steps_sampled': 247040, 'num_env_steps_trained': 247040, 'num_agent_steps_sampled': 247040, 'num_agent_steps_trained': 247040}, 'done': False, 'episodes_total': 1280, 'training_iteration': 64, 'trial_id': 'default', 'date': '2025-11-05_00-31-18', 'timestamp': 1762331478, 'time_this_iter_s': 299.8336501121521, 'time_total_s': 20301.016067266464, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e2513340>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699610790>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2511c30>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2513040>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 20301.016067266464, 'iterations_since_restore': 64, 'perf': {'cpu_util_percent': 19.418457943925233, 'ram_util_percent': 6.0}}
Iteration 65/100
{'custom_metrics': {'default_policy/true_reward_mean': -29.592967622102528, 'default_policy/true_reward_min': -89.7006854249493, 'default_policy/true_reward_max': -1.3239087296526006, 'default_policy/proxy_reward_mean': -2.1049676221025218, 'default_policy/proxy_reward_min': -5.333908729652602, 'default_policy/proxy_reward_max': -0.7364213562373092, 'default_policy/modified_reward_mean': -2.947205401334247, 'default_policy/modified_reward_min': -6.316854895131972, 'default_policy/modified_reward_max': -1.1490427625542528, 'default_policy/corr_btw_rewards_mean': 0.4052148460079198, 'default_policy/corr_btw_rewards_min': 0.10801591125015228, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -29.592967622102528, 'true_reward_min': -89.7006854249493, 'true_reward_max': -1.3239087296526006, 'proxy_reward_mean': -2.1049676221025218, 'proxy_reward_min': -5.333908729652602, 'proxy_reward_max': -0.7364213562373092, 'modified_reward_mean': -2.947205401334247, 'modified_reward_min': -6.316854895131972, 'modified_reward_max': -1.1490427625542528, 'proxyInfectionSummaryAbsoluteReward_mean': -0.000384974093264249, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019170984455958563, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.05849055036800633, 'proxyLowerStageReward_min': -0.09157834819926809, 'proxyLowerStageReward_max': -0.03193893037499013, 'proxySmoothStageChangesReward_mean': -0.12077720207253888, 'proxySmoothStageChangesReward_min': -0.22797927461139897, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.000384974093264249, 'trueInfectionSummaryAbsoluteReward_min': -0.0019170984455958563, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.014242487046632123, 'truePoliticalReward_min': -0.04559585492227978, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.05849055036800633, 'trueLowerStageReward_min': -0.09157834819926809, 'trueLowerStageReward_max': -0.03193893037499013, 'trueSmoothStageChangesReward_mean': -0.12077720207253888, 'trueSmoothStageChangesReward_min': -0.22797927461139897, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.947205401334247, 'total_modified_reward_min': -6.316854895131972, 'total_modified_reward_max': -1.1490427625542528}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.8678264269232749, 'cur_kl_coeff': 0.028125000000000008, 'cur_lr': 0.0003, 'total_loss': -0.03868646137416363, 'policy_loss': -0.015370775759220124, 'vf_loss': 0.011146109794887404, 'vf_explained_var': 0.7646815168857575, 'kl': 0.018673667071513828, 'entropy': 0.5296677800019582, 'entropy_coeff': 0.05553280000000001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 19350.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 250900, 'num_env_steps_trained': 250900, 'num_agent_steps_sampled': 250900, 'num_agent_steps_trained': 250900}, 'sampler_results': {'episode_reward_max': -1.1490427625542528, 'episode_reward_min': -6.316854895131972, 'episode_reward_mean': -2.947205401334247, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -29.592967622102528, 'default_policy/true_reward_min': -89.7006854249493, 'default_policy/true_reward_max': -1.3239087296526006, 'default_policy/proxy_reward_mean': -2.1049676221025218, 'default_policy/proxy_reward_min': -5.333908729652602, 'default_policy/proxy_reward_max': -0.7364213562373092, 'default_policy/modified_reward_mean': -2.947205401334247, 'default_policy/modified_reward_min': -6.316854895131972, 'default_policy/modified_reward_max': -1.1490427625542528, 'default_policy/corr_btw_rewards_mean': 0.4052148460079198, 'default_policy/corr_btw_rewards_min': 0.10801591125015228, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -29.592967622102528, 'true_reward_min': -89.7006854249493, 'true_reward_max': -1.3239087296526006, 'proxy_reward_mean': -2.1049676221025218, 'proxy_reward_min': -5.333908729652602, 'proxy_reward_max': -0.7364213562373092, 'modified_reward_mean': -2.947205401334247, 'modified_reward_min': -6.316854895131972, 'modified_reward_max': -1.1490427625542528, 'proxyInfectionSummaryAbsoluteReward_mean': -0.000384974093264249, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019170984455958563, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.05849055036800633, 'proxyLowerStageReward_min': -0.09157834819926809, 'proxyLowerStageReward_max': -0.03193893037499013, 'proxySmoothStageChangesReward_mean': -0.12077720207253888, 'proxySmoothStageChangesReward_min': -0.22797927461139897, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.000384974093264249, 'trueInfectionSummaryAbsoluteReward_min': -0.0019170984455958563, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.014242487046632123, 'truePoliticalReward_min': -0.04559585492227978, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.05849055036800633, 'trueLowerStageReward_min': -0.09157834819926809, 'trueLowerStageReward_max': -0.03193893037499013, 'trueSmoothStageChangesReward_mean': -0.12077720207253888, 'trueSmoothStageChangesReward_min': -0.22797927461139897, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.947205401334247, 'total_modified_reward_min': -6.316854895131972, 'total_modified_reward_max': -1.1490427625542528}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5323961303468836, 'mean_inference_ms': 1.6799551277622087, 'mean_action_processing_ms': 0.10671096588616119, 'mean_env_wait_ms': 749.882078588313, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.1490427625542528, 'episode_reward_min': -6.316854895131972, 'episode_reward_mean': -2.947205401334247, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5323961303468836, 'mean_inference_ms': 1.6799551277622087, 'mean_action_processing_ms': 0.10671096588616119, 'mean_env_wait_ms': 749.882078588313, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 250900, 'num_agent_steps_trained': 250900, 'num_env_steps_sampled': 250900, 'num_env_steps_trained': 250900, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.678500791408355, 'num_env_steps_trained_throughput_per_sec': 12.678500791408355, 'timesteps_total': 250900, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 250900, 'timers': {'training_iteration_time_ms': 309071.696, 'sample_time_ms': 308067.821, 'load_time_ms': 5.099, 'load_throughput': 757023.783, 'learn_time_ms': 981.602, 'learn_throughput': 3932.347, 'synch_weights_time_ms': 16.319}, 'counters': {'num_env_steps_sampled': 250900, 'num_env_steps_trained': 250900, 'num_agent_steps_sampled': 250900, 'num_agent_steps_trained': 250900}, 'done': False, 'episodes_total': 1300, 'training_iteration': 65, 'trial_id': 'default', 'date': '2025-11-05_00-36-22', 'timestamp': 1762331782, 'time_this_iter_s': 304.473650932312, 'time_total_s': 20605.489718198776, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e0fff610>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e0ffcf10>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffe860>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffc610>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 20605.489718198776, 'iterations_since_restore': 65, 'perf': {'cpu_util_percent': 19.252886836027713, 'ram_util_percent': 6.0}}
Iteration 66/100
{'custom_metrics': {'default_policy/true_reward_mean': -31.10723501025796, 'default_policy/true_reward_min': -89.7006854249493, 'default_policy/true_reward_max': -1.3239087296526006, 'default_policy/proxy_reward_mean': -1.9552350102579468, 'default_policy/proxy_reward_min': -4.5614087296526, 'default_policy/proxy_reward_max': -0.7364213562373092, 'default_policy/modified_reward_mean': -2.7634277008612247, 'default_policy/modified_reward_min': -5.561185949083789, 'default_policy/modified_reward_max': -1.1490427625542528, 'default_policy/corr_btw_rewards_mean': 0.42440002552684364, 'default_policy/corr_btw_rewards_min': 0.11373150306507812, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -31.10723501025796, 'true_reward_min': -89.7006854249493, 'true_reward_max': -1.3239087296526006, 'proxy_reward_mean': -1.9552350102579468, 'proxy_reward_min': -4.5614087296526, 'proxy_reward_max': -0.7364213562373092, 'modified_reward_mean': -2.7634277008612247, 'modified_reward_min': -5.561185949083789, 'modified_reward_max': -1.1490427625542528, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003420725388601039, 'proxyInfectionSummaryAbsoluteReward_min': -0.0018445595854922287, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.054789378769841815, 'proxyLowerStageReward_min': -0.09157834819926809, 'proxyLowerStageReward_max': -0.029126012142796077, 'proxySmoothStageChangesReward_mean': -0.12310880829015546, 'proxySmoothStageChangesReward_min': -0.22797927461139897, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003420725388601039, 'trueInfectionSummaryAbsoluteReward_min': -0.0018445595854922287, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.015104663212435232, 'truePoliticalReward_min': -0.04559585492227978, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.054789378769841815, 'trueLowerStageReward_min': -0.09157834819926809, 'trueLowerStageReward_max': -0.029126012142796077, 'trueSmoothStageChangesReward_mean': -0.12310880829015546, 'trueSmoothStageChangesReward_min': -0.22797927461139897, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.7634277008612247, 'total_modified_reward_min': -5.561185949083789, 'total_modified_reward_max': -1.1490427625542528}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0276027685403823, 'cur_kl_coeff': 0.028125000000000008, 'cur_lr': 0.0003, 'total_loss': -0.02816513596723477, 'policy_loss': -0.009357019163047275, 'vf_loss': 0.01922951755298224, 'vf_explained_var': 0.6815198451280594, 'kl': 0.010441413209569775, 'entropy': 0.5236613475282987, 'entropy_coeff': 0.054838}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 19650.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 254760, 'num_env_steps_trained': 254760, 'num_agent_steps_sampled': 254760, 'num_agent_steps_trained': 254760}, 'sampler_results': {'episode_reward_max': -1.1490427625542528, 'episode_reward_min': -5.561185949083789, 'episode_reward_mean': -2.7634277008612247, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -31.10723501025796, 'default_policy/true_reward_min': -89.7006854249493, 'default_policy/true_reward_max': -1.3239087296526006, 'default_policy/proxy_reward_mean': -1.9552350102579468, 'default_policy/proxy_reward_min': -4.5614087296526, 'default_policy/proxy_reward_max': -0.7364213562373092, 'default_policy/modified_reward_mean': -2.7634277008612247, 'default_policy/modified_reward_min': -5.561185949083789, 'default_policy/modified_reward_max': -1.1490427625542528, 'default_policy/corr_btw_rewards_mean': 0.42440002552684364, 'default_policy/corr_btw_rewards_min': 0.11373150306507812, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -31.10723501025796, 'true_reward_min': -89.7006854249493, 'true_reward_max': -1.3239087296526006, 'proxy_reward_mean': -1.9552350102579468, 'proxy_reward_min': -4.5614087296526, 'proxy_reward_max': -0.7364213562373092, 'modified_reward_mean': -2.7634277008612247, 'modified_reward_min': -5.561185949083789, 'modified_reward_max': -1.1490427625542528, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003420725388601039, 'proxyInfectionSummaryAbsoluteReward_min': -0.0018445595854922287, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.054789378769841815, 'proxyLowerStageReward_min': -0.09157834819926809, 'proxyLowerStageReward_max': -0.029126012142796077, 'proxySmoothStageChangesReward_mean': -0.12310880829015546, 'proxySmoothStageChangesReward_min': -0.22797927461139897, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003420725388601039, 'trueInfectionSummaryAbsoluteReward_min': -0.0018445595854922287, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.015104663212435232, 'truePoliticalReward_min': -0.04559585492227978, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.054789378769841815, 'trueLowerStageReward_min': -0.09157834819926809, 'trueLowerStageReward_max': -0.029126012142796077, 'trueSmoothStageChangesReward_mean': -0.12310880829015546, 'trueSmoothStageChangesReward_min': -0.22797927461139897, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.7634277008612247, 'total_modified_reward_min': -5.561185949083789, 'total_modified_reward_max': -1.1490427625542528}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5319313740464133, 'mean_inference_ms': 1.6796318390342355, 'mean_action_processing_ms': 0.10669648099805848, 'mean_env_wait_ms': 749.1550807647287, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.1490427625542528, 'episode_reward_min': -5.561185949083789, 'episode_reward_mean': -2.7634277008612247, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5319313740464133, 'mean_inference_ms': 1.6796318390342355, 'mean_action_processing_ms': 0.10669648099805848, 'mean_env_wait_ms': 749.1550807647287, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 254760, 'num_agent_steps_trained': 254760, 'num_env_steps_sampled': 254760, 'num_env_steps_trained': 254760, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.310655013777824, 'num_env_steps_trained_throughput_per_sec': 12.310655013777824, 'timesteps_total': 254760, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 254760, 'timers': {'training_iteration_time_ms': 308598.689, 'sample_time_ms': 307597.19, 'load_time_ms': 5.006, 'load_throughput': 771110.915, 'learn_time_ms': 979.217, 'learn_throughput': 3941.924, 'synch_weights_time_ms': 16.407}, 'counters': {'num_env_steps_sampled': 254760, 'num_env_steps_trained': 254760, 'num_agent_steps_sampled': 254760, 'num_agent_steps_trained': 254760}, 'done': False, 'episodes_total': 1320, 'training_iteration': 66, 'trial_id': 'default', 'date': '2025-11-05_00-41-36', 'timestamp': 1762332096, 'time_this_iter_s': 313.5721871852875, 'time_total_s': 20919.061905384064, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e24faec0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6995348b0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e24fa020>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e24fa710>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 20919.061905384064, 'iterations_since_restore': 66, 'perf': {'cpu_util_percent': 18.756249999999998, 'ram_util_percent': 6.0}}
Iteration 67/100
{'custom_metrics': {'default_policy/true_reward_mean': -26.488110641587188, 'default_policy/true_reward_min': -81.13068542494928, 'default_policy/true_reward_max': -1.3239087296526006, 'default_policy/proxy_reward_mean': -1.8721106415871822, 'default_policy/proxy_reward_min': -4.5614087296526, 'default_policy/proxy_reward_max': -0.7364213562373092, 'default_policy/modified_reward_mean': -2.638362176106904, 'default_policy/modified_reward_min': -5.465906971441414, 'default_policy/modified_reward_max': -1.1490427625542528, 'default_policy/corr_btw_rewards_mean': 0.4278080181059591, 'default_policy/corr_btw_rewards_min': 0.10753997687905968, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -26.488110641587188, 'true_reward_min': -81.13068542494928, 'true_reward_max': -1.3239087296526006, 'proxy_reward_mean': -1.8721106415871822, 'proxy_reward_min': -4.5614087296526, 'proxy_reward_max': -0.7364213562373092, 'modified_reward_mean': -2.638362176106904, 'modified_reward_min': -5.465906971441414, 'modified_reward_max': -1.1490427625542528, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00033626943005181376, 'proxyInfectionSummaryAbsoluteReward_min': -0.0018445595854922287, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.05141505914959493, 'proxyLowerStageReward_min': -0.08164107763546782, 'proxyLowerStageReward_max': -0.026646460896198803, 'proxySmoothStageChangesReward_mean': -0.11958549222797928, 'proxySmoothStageChangesReward_min': -0.22797927461139897, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00033626943005181376, 'trueInfectionSummaryAbsoluteReward_min': -0.0018445595854922287, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.012754404145077718, 'truePoliticalReward_min': -0.04103626943005182, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.05141505914959493, 'trueLowerStageReward_min': -0.08164107763546782, 'trueLowerStageReward_max': -0.026646460896198803, 'trueSmoothStageChangesReward_mean': -0.11958549222797928, 'trueSmoothStageChangesReward_min': -0.22797927461139897, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.638362176106904, 'total_modified_reward_min': -5.465906971441414, 'total_modified_reward_max': -1.1490427625542528}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.3138789534568787, 'cur_kl_coeff': 0.028125000000000008, 'cur_lr': 0.0003, 'total_loss': -0.012789295642481496, 'policy_loss': -0.0044423819271226725, 'vf_loss': 0.03846023095208996, 'vf_explained_var': 0.5199925635258357, 'kl': 0.007461756587162789, 'entropy': 0.5132111394405365, 'entropy_coeff': 0.05414320000000001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 19950.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 258620, 'num_env_steps_trained': 258620, 'num_agent_steps_sampled': 258620, 'num_agent_steps_trained': 258620}, 'sampler_results': {'episode_reward_max': -1.1490427625542528, 'episode_reward_min': -5.465906971441414, 'episode_reward_mean': -2.638362176106904, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -26.488110641587188, 'default_policy/true_reward_min': -81.13068542494928, 'default_policy/true_reward_max': -1.3239087296526006, 'default_policy/proxy_reward_mean': -1.8721106415871822, 'default_policy/proxy_reward_min': -4.5614087296526, 'default_policy/proxy_reward_max': -0.7364213562373092, 'default_policy/modified_reward_mean': -2.638362176106904, 'default_policy/modified_reward_min': -5.465906971441414, 'default_policy/modified_reward_max': -1.1490427625542528, 'default_policy/corr_btw_rewards_mean': 0.4278080181059591, 'default_policy/corr_btw_rewards_min': 0.10753997687905968, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -26.488110641587188, 'true_reward_min': -81.13068542494928, 'true_reward_max': -1.3239087296526006, 'proxy_reward_mean': -1.8721106415871822, 'proxy_reward_min': -4.5614087296526, 'proxy_reward_max': -0.7364213562373092, 'modified_reward_mean': -2.638362176106904, 'modified_reward_min': -5.465906971441414, 'modified_reward_max': -1.1490427625542528, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00033626943005181376, 'proxyInfectionSummaryAbsoluteReward_min': -0.0018445595854922287, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.05141505914959493, 'proxyLowerStageReward_min': -0.08164107763546782, 'proxyLowerStageReward_max': -0.026646460896198803, 'proxySmoothStageChangesReward_mean': -0.11958549222797928, 'proxySmoothStageChangesReward_min': -0.22797927461139897, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00033626943005181376, 'trueInfectionSummaryAbsoluteReward_min': -0.0018445595854922287, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.012754404145077718, 'truePoliticalReward_min': -0.04103626943005182, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.05141505914959493, 'trueLowerStageReward_min': -0.08164107763546782, 'trueLowerStageReward_max': -0.026646460896198803, 'trueSmoothStageChangesReward_mean': -0.11958549222797928, 'trueSmoothStageChangesReward_min': -0.22797927461139897, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.638362176106904, 'total_modified_reward_min': -5.465906971441414, 'total_modified_reward_max': -1.1490427625542528}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5314446671249011, 'mean_inference_ms': 1.6793894645885774, 'mean_action_processing_ms': 0.10667207772970827, 'mean_env_wait_ms': 748.4786090910327, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.1490427625542528, 'episode_reward_min': -5.465906971441414, 'episode_reward_mean': -2.638362176106904, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5314446671249011, 'mean_inference_ms': 1.6793894645885774, 'mean_action_processing_ms': 0.10667207772970827, 'mean_env_wait_ms': 748.4786090910327, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 258620, 'num_agent_steps_trained': 258620, 'num_env_steps_sampled': 258620, 'num_env_steps_trained': 258620, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.603268423671938, 'num_env_steps_trained_throughput_per_sec': 12.603268423671938, 'timesteps_total': 258620, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 258620, 'timers': {'training_iteration_time_ms': 308298.044, 'sample_time_ms': 307277.231, 'load_time_ms': 5.011, 'load_throughput': 770380.738, 'learn_time_ms': 998.424, 'learn_throughput': 3866.091, 'synch_weights_time_ms': 16.503}, 'counters': {'num_env_steps_sampled': 258620, 'num_env_steps_trained': 258620, 'num_agent_steps_sampled': 258620, 'num_agent_steps_trained': 258620}, 'done': False, 'episodes_total': 1340, 'training_iteration': 67, 'trial_id': 'default', 'date': '2025-11-05_00-46-43', 'timestamp': 1762332403, 'time_this_iter_s': 306.2916057109833, 'time_total_s': 21225.353511095047, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e0ffe770>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e0ffec20>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2513e20>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2512170>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 21225.353511095047, 'iterations_since_restore': 67, 'perf': {'cpu_util_percent': 19.39311926605505, 'ram_util_percent': 6.0}}
Iteration 68/100
{'custom_metrics': {'default_policy/true_reward_mean': -25.61573284579167, 'default_policy/true_reward_min': -81.13068542494928, 'default_policy/true_reward_max': -1.4456980515339455, 'default_policy/proxy_reward_mean': -1.8597328457916718, 'default_policy/proxy_reward_min': -4.5614087296526, 'default_policy/proxy_reward_max': -0.6642766952966366, 'default_policy/modified_reward_mean': -2.5917113675469388, 'default_policy/modified_reward_min': -5.465906971441414, 'default_policy/modified_reward_max': -1.068760805138522, 'default_policy/corr_btw_rewards_mean': 0.4352519081456662, 'default_policy/corr_btw_rewards_min': 0.10753997687905968, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -25.61573284579167, 'true_reward_min': -81.13068542494928, 'true_reward_max': -1.4456980515339455, 'proxy_reward_mean': -1.8597328457916718, 'proxy_reward_min': -4.5614087296526, 'proxy_reward_max': -0.6642766952966366, 'modified_reward_mean': -2.5917113675469388, 'modified_reward_min': -5.465906971441414, 'modified_reward_max': -1.068760805138522, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003589637305699484, 'proxyInfectionSummaryAbsoluteReward_min': -0.0018445595854922287, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.04894988838298817, 'proxyLowerStageReward_min': -0.08164107763546782, 'proxyLowerStageReward_max': -0.026646460896198803, 'proxySmoothStageChangesReward_mean': -0.1151295336787565, 'proxySmoothStageChangesReward_min': -0.22797927461139897, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003589637305699484, 'trueInfectionSummaryAbsoluteReward_min': -0.0018445595854922287, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.012308808290155439, 'truePoliticalReward_min': -0.04103626943005182, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.04894988838298817, 'trueLowerStageReward_min': -0.08164107763546782, 'trueLowerStageReward_max': -0.026646460896198803, 'trueSmoothStageChangesReward_mean': -0.1151295336787565, 'trueSmoothStageChangesReward_min': -0.22797927461139897, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.5917113675469388, 'total_modified_reward_min': -5.465906971441414, 'total_modified_reward_max': -1.068760805138522}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.3751256944735846, 'cur_kl_coeff': 0.028125000000000008, 'cur_lr': 0.0003, 'total_loss': -0.020127686597212837, 'policy_loss': -0.01473339030208687, 'vf_loss': 0.04553714546918248, 'vf_explained_var': 0.3937784953912099, 'kl': 0.022997714206643906, 'entropy': 0.5390186013778051, 'entropy_coeff': 0.0534484}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 20250.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 262480, 'num_env_steps_trained': 262480, 'num_agent_steps_sampled': 262480, 'num_agent_steps_trained': 262480}, 'sampler_results': {'episode_reward_max': -1.068760805138522, 'episode_reward_min': -5.465906971441414, 'episode_reward_mean': -2.5917113675469388, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -25.61573284579167, 'default_policy/true_reward_min': -81.13068542494928, 'default_policy/true_reward_max': -1.4456980515339455, 'default_policy/proxy_reward_mean': -1.8597328457916718, 'default_policy/proxy_reward_min': -4.5614087296526, 'default_policy/proxy_reward_max': -0.6642766952966366, 'default_policy/modified_reward_mean': -2.5917113675469388, 'default_policy/modified_reward_min': -5.465906971441414, 'default_policy/modified_reward_max': -1.068760805138522, 'default_policy/corr_btw_rewards_mean': 0.4352519081456662, 'default_policy/corr_btw_rewards_min': 0.10753997687905968, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -25.61573284579167, 'true_reward_min': -81.13068542494928, 'true_reward_max': -1.4456980515339455, 'proxy_reward_mean': -1.8597328457916718, 'proxy_reward_min': -4.5614087296526, 'proxy_reward_max': -0.6642766952966366, 'modified_reward_mean': -2.5917113675469388, 'modified_reward_min': -5.465906971441414, 'modified_reward_max': -1.068760805138522, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003589637305699484, 'proxyInfectionSummaryAbsoluteReward_min': -0.0018445595854922287, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.04894988838298817, 'proxyLowerStageReward_min': -0.08164107763546782, 'proxyLowerStageReward_max': -0.026646460896198803, 'proxySmoothStageChangesReward_mean': -0.1151295336787565, 'proxySmoothStageChangesReward_min': -0.22797927461139897, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003589637305699484, 'trueInfectionSummaryAbsoluteReward_min': -0.0018445595854922287, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.012308808290155439, 'truePoliticalReward_min': -0.04103626943005182, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.04894988838298817, 'trueLowerStageReward_min': -0.08164107763546782, 'trueLowerStageReward_max': -0.026646460896198803, 'trueSmoothStageChangesReward_mean': -0.1151295336787565, 'trueSmoothStageChangesReward_min': -0.22797927461139897, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.5917113675469388, 'total_modified_reward_min': -5.465906971441414, 'total_modified_reward_max': -1.068760805138522}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5309418247805965, 'mean_inference_ms': 1.679080302480949, 'mean_action_processing_ms': 0.1066266898810334, 'mean_env_wait_ms': 747.8114357139973, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.068760805138522, 'episode_reward_min': -5.465906971441414, 'episode_reward_mean': -2.5917113675469388, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5309418247805965, 'mean_inference_ms': 1.679080302480949, 'mean_action_processing_ms': 0.1066266898810334, 'mean_env_wait_ms': 747.8114357139973, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 262480, 'num_agent_steps_trained': 262480, 'num_env_steps_sampled': 262480, 'num_env_steps_trained': 262480, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.222206040877015, 'num_env_steps_trained_throughput_per_sec': 12.222206040877015, 'timesteps_total': 262480, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 262480, 'timers': {'training_iteration_time_ms': 310100.792, 'sample_time_ms': 309059.199, 'load_time_ms': 5.165, 'load_throughput': 747337.166, 'learn_time_ms': 1018.198, 'learn_throughput': 3791.012, 'synch_weights_time_ms': 17.317}, 'counters': {'num_env_steps_sampled': 262480, 'num_env_steps_trained': 262480, 'num_agent_steps_sampled': 262480, 'num_agent_steps_trained': 262480}, 'done': False, 'episodes_total': 1360, 'training_iteration': 68, 'trial_id': 'default', 'date': '2025-11-05_00-51-58', 'timestamp': 1762332718, 'time_this_iter_s': 315.8378324508667, 'time_total_s': 21541.191343545914, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a699610a00>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699610c10>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699613100>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699611180>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 21541.191343545914, 'iterations_since_restore': 68, 'perf': {'cpu_util_percent': 18.966518847006654, 'ram_util_percent': 6.0}}
Iteration 69/100
{'custom_metrics': {'default_policy/true_reward_mean': -24.44060771952583, 'default_policy/true_reward_min': -81.94105339059331, 'default_policy/true_reward_max': -1.4456980515339455, 'default_policy/proxy_reward_mean': -1.9006077195258249, 'default_policy/proxy_reward_min': -5.9038961030678925, 'default_policy/proxy_reward_max': -0.6642766952966366, 'default_policy/modified_reward_mean': -2.6231598702089025, 'default_policy/modified_reward_min': -6.86431131884368, 'default_policy/modified_reward_max': -1.068760805138522, 'default_policy/corr_btw_rewards_mean': 0.4609092373959961, 'default_policy/corr_btw_rewards_min': 0.10753997687905968, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -24.44060771952583, 'true_reward_min': -81.94105339059331, 'true_reward_max': -1.4456980515339455, 'proxy_reward_mean': -1.9006077195258249, 'proxy_reward_min': -5.9038961030678925, 'proxy_reward_max': -0.6642766952966366, 'modified_reward_mean': -2.6231598702089025, 'modified_reward_min': -6.86431131884368, 'modified_reward_max': -1.068760805138522, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00038932642487046656, 'proxyInfectionSummaryAbsoluteReward_min': -0.002269430051813473, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0480159440168821, 'proxyLowerStageReward_min': -0.07527551602617627, 'proxyLowerStageReward_max': -0.026646460896198803, 'proxySmoothStageChangesReward_mean': -0.11528497409326427, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00038932642487046656, 'trueInfectionSummaryAbsoluteReward_min': -0.002269430051813473, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.011678756476683936, 'truePoliticalReward_min': -0.04186528497409327, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.0480159440168821, 'trueLowerStageReward_min': -0.07527551602617627, 'trueLowerStageReward_max': -0.026646460896198803, 'trueSmoothStageChangesReward_mean': -0.11528497409326427, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.6231598702089025, 'total_modified_reward_min': -6.86431131884368, 'total_modified_reward_max': -1.068760805138522}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.3821834545830887, 'cur_kl_coeff': 0.042187499999999996, 'cur_lr': 0.0003, 'total_loss': -0.010425993582854669, 'policy_loss': -0.007947987557078401, 'vf_loss': 0.05225759049605889, 'vf_explained_var': 0.42163851340611774, 'kl': 0.012266746149788482, 'entropy': 0.5520818304022154, 'entropy_coeff': 0.052753600000000005}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 20550.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 266340, 'num_env_steps_trained': 266340, 'num_agent_steps_sampled': 266340, 'num_agent_steps_trained': 266340}, 'sampler_results': {'episode_reward_max': -1.068760805138522, 'episode_reward_min': -6.86431131884368, 'episode_reward_mean': -2.6231598702089025, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -24.44060771952583, 'default_policy/true_reward_min': -81.94105339059331, 'default_policy/true_reward_max': -1.4456980515339455, 'default_policy/proxy_reward_mean': -1.9006077195258249, 'default_policy/proxy_reward_min': -5.9038961030678925, 'default_policy/proxy_reward_max': -0.6642766952966366, 'default_policy/modified_reward_mean': -2.6231598702089025, 'default_policy/modified_reward_min': -6.86431131884368, 'default_policy/modified_reward_max': -1.068760805138522, 'default_policy/corr_btw_rewards_mean': 0.4609092373959961, 'default_policy/corr_btw_rewards_min': 0.10753997687905968, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -24.44060771952583, 'true_reward_min': -81.94105339059331, 'true_reward_max': -1.4456980515339455, 'proxy_reward_mean': -1.9006077195258249, 'proxy_reward_min': -5.9038961030678925, 'proxy_reward_max': -0.6642766952966366, 'modified_reward_mean': -2.6231598702089025, 'modified_reward_min': -6.86431131884368, 'modified_reward_max': -1.068760805138522, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00038932642487046656, 'proxyInfectionSummaryAbsoluteReward_min': -0.002269430051813473, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0480159440168821, 'proxyLowerStageReward_min': -0.07527551602617627, 'proxyLowerStageReward_max': -0.026646460896198803, 'proxySmoothStageChangesReward_mean': -0.11528497409326427, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00038932642487046656, 'trueInfectionSummaryAbsoluteReward_min': -0.002269430051813473, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.011678756476683936, 'truePoliticalReward_min': -0.04186528497409327, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.0480159440168821, 'trueLowerStageReward_min': -0.07527551602617627, 'trueLowerStageReward_max': -0.026646460896198803, 'trueSmoothStageChangesReward_mean': -0.11528497409326427, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.6231598702089025, 'total_modified_reward_min': -6.86431131884368, 'total_modified_reward_max': -1.068760805138522}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5305202831282161, 'mean_inference_ms': 1.6787268603487278, 'mean_action_processing_ms': 0.10659381713178848, 'mean_env_wait_ms': 747.1844530364909, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.068760805138522, 'episode_reward_min': -6.86431131884368, 'episode_reward_mean': -2.6231598702089025, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5305202831282161, 'mean_inference_ms': 1.6787268603487278, 'mean_action_processing_ms': 0.10659381713178848, 'mean_env_wait_ms': 747.1844530364909, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 266340, 'num_agent_steps_trained': 266340, 'num_env_steps_sampled': 266340, 'num_env_steps_trained': 266340, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.596254386662372, 'num_env_steps_trained_throughput_per_sec': 12.596254386662372, 'timesteps_total': 266340, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 266340, 'timers': {'training_iteration_time_ms': 309013.275, 'sample_time_ms': 307970.768, 'load_time_ms': 5.046, 'load_throughput': 764982.515, 'learn_time_ms': 1019.327, 'learn_throughput': 3786.813, 'synch_weights_time_ms': 17.206}, 'counters': {'num_env_steps_sampled': 266340, 'num_env_steps_trained': 266340, 'num_agent_steps_sampled': 266340, 'num_agent_steps_trained': 266340}, 'done': False, 'episodes_total': 1380, 'training_iteration': 69, 'trial_id': 'default', 'date': '2025-11-05_00-57-05', 'timestamp': 1762333025, 'time_this_iter_s': 306.46286964416504, 'time_total_s': 21847.65421319008, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6996130d0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699612e90>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699613940>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699613220>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 21847.65421319008, 'iterations_since_restore': 69, 'perf': {'cpu_util_percent': 19.06887871853547, 'ram_util_percent': 6.0}}
Iteration 70/100
{'custom_metrics': {'default_policy/true_reward_mean': -19.525978913603534, 'default_policy/true_reward_min': -81.94105339059331, 'default_policy/true_reward_max': -1.2428427124746186, 'default_policy/proxy_reward_mean': -2.057978913603537, 'default_policy/proxy_reward_min': -5.9038961030678925, 'default_policy/proxy_reward_max': -0.6642766952966366, 'default_policy/modified_reward_mean': -2.7729611105405247, 'default_policy/modified_reward_min': -6.86431131884368, 'default_policy/modified_reward_max': -1.068760805138522, 'default_policy/corr_btw_rewards_mean': 0.4525880455773726, 'default_policy/corr_btw_rewards_min': 0.09426259572604613, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -19.525978913603534, 'true_reward_min': -81.94105339059331, 'true_reward_max': -1.2428427124746186, 'proxy_reward_mean': -2.057978913603537, 'proxy_reward_min': -5.9038961030678925, 'proxy_reward_max': -0.6642766952966366, 'modified_reward_mean': -2.7729611105405247, 'modified_reward_min': -6.86431131884368, 'modified_reward_max': -1.068760805138522, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004781347150259071, 'proxyInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.04728906288101228, 'proxyLowerStageReward_min': -0.07527551602617627, 'proxyLowerStageReward_max': -0.026646460896198803, 'proxySmoothStageChangesReward_mean': -0.11528497409326427, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004781347150259071, 'trueInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.009050777202072537, 'truePoliticalReward_min': -0.04186528497409327, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.04728906288101228, 'trueLowerStageReward_min': -0.07527551602617627, 'trueLowerStageReward_max': -0.026646460896198803, 'trueSmoothStageChangesReward_mean': -0.11528497409326427, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.7729611105405247, 'total_modified_reward_min': -6.86431131884368, 'total_modified_reward_max': -1.068760805138522}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.3056011340022087, 'cur_kl_coeff': 0.042187499999999996, 'cur_lr': 0.0003, 'total_loss': -0.00398177525261417, 'policy_loss': -0.00702669463896503, 'vf_loss': 0.06147345224046148, 'vf_explained_var': 0.4580064368247986, 'kl': 0.013150769450275225, 'entropy': 0.5425904393196106, 'entropy_coeff': 0.0520588}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 20850.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 270200, 'num_env_steps_trained': 270200, 'num_agent_steps_sampled': 270200, 'num_agent_steps_trained': 270200}, 'sampler_results': {'episode_reward_max': -1.068760805138522, 'episode_reward_min': -6.86431131884368, 'episode_reward_mean': -2.7729611105405247, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -19.525978913603534, 'default_policy/true_reward_min': -81.94105339059331, 'default_policy/true_reward_max': -1.2428427124746186, 'default_policy/proxy_reward_mean': -2.057978913603537, 'default_policy/proxy_reward_min': -5.9038961030678925, 'default_policy/proxy_reward_max': -0.6642766952966366, 'default_policy/modified_reward_mean': -2.7729611105405247, 'default_policy/modified_reward_min': -6.86431131884368, 'default_policy/modified_reward_max': -1.068760805138522, 'default_policy/corr_btw_rewards_mean': 0.4525880455773726, 'default_policy/corr_btw_rewards_min': 0.09426259572604613, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -19.525978913603534, 'true_reward_min': -81.94105339059331, 'true_reward_max': -1.2428427124746186, 'proxy_reward_mean': -2.057978913603537, 'proxy_reward_min': -5.9038961030678925, 'proxy_reward_max': -0.6642766952966366, 'modified_reward_mean': -2.7729611105405247, 'modified_reward_min': -6.86431131884368, 'modified_reward_max': -1.068760805138522, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004781347150259071, 'proxyInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.04728906288101228, 'proxyLowerStageReward_min': -0.07527551602617627, 'proxyLowerStageReward_max': -0.026646460896198803, 'proxySmoothStageChangesReward_mean': -0.11528497409326427, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004781347150259071, 'trueInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.009050777202072537, 'truePoliticalReward_min': -0.04186528497409327, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.04728906288101228, 'trueLowerStageReward_min': -0.07527551602617627, 'trueLowerStageReward_max': -0.026646460896198803, 'trueSmoothStageChangesReward_mean': -0.11528497409326427, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.7729611105405247, 'total_modified_reward_min': -6.86431131884368, 'total_modified_reward_max': -1.068760805138522}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.530441511853544, 'mean_inference_ms': 1.6783437238758796, 'mean_action_processing_ms': 0.10655936001137807, 'mean_env_wait_ms': 746.5525704632194, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.068760805138522, 'episode_reward_min': -6.86431131884368, 'episode_reward_mean': -2.7729611105405247, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.530441511853544, 'mean_inference_ms': 1.6783437238758796, 'mean_action_processing_ms': 0.10655936001137807, 'mean_env_wait_ms': 746.5525704632194, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 270200, 'num_agent_steps_trained': 270200, 'num_env_steps_sampled': 270200, 'num_env_steps_trained': 270200, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.573642694318647, 'num_env_steps_trained_throughput_per_sec': 12.573642694318647, 'timesteps_total': 270200, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 270200, 'timers': {'training_iteration_time_ms': 309851.795, 'sample_time_ms': 308809.221, 'load_time_ms': 5.09, 'load_throughput': 758317.999, 'learn_time_ms': 1019.649, 'learn_throughput': 3785.617, 'synch_weights_time_ms': 16.923}, 'counters': {'num_env_steps_sampled': 270200, 'num_env_steps_trained': 270200, 'num_agent_steps_sampled': 270200, 'num_agent_steps_trained': 270200}, 'done': False, 'episodes_total': 1400, 'training_iteration': 70, 'trial_id': 'default', 'date': '2025-11-05_01-02-12', 'timestamp': 1762333332, 'time_this_iter_s': 307.0154182910919, 'time_total_s': 22154.66963148117, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6600c3fa0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6600c2980>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2565180>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6882fd120>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 22154.66963148117, 'iterations_since_restore': 70, 'perf': {'cpu_util_percent': 19.016704805491994, 'ram_util_percent': 6.0}}
Saved checkpoint to TrainingResult(checkpoint=Checkpoint(filesystem=local, path=logs/data/pandemic/20251104_185246/checkpoint_70), metrics={'custom_metrics': {'default_policy/true_reward_mean': -19.525978913603534, 'default_policy/true_reward_min': -81.94105339059331, 'default_policy/true_reward_max': -1.2428427124746186, 'default_policy/proxy_reward_mean': -2.057978913603537, 'default_policy/proxy_reward_min': -5.9038961030678925, 'default_policy/proxy_reward_max': -0.6642766952966366, 'default_policy/modified_reward_mean': -2.7729611105405247, 'default_policy/modified_reward_min': -6.86431131884368, 'default_policy/modified_reward_max': -1.068760805138522, 'default_policy/corr_btw_rewards_mean': 0.4525880455773726, 'default_policy/corr_btw_rewards_min': 0.09426259572604613, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -19.525978913603534, 'true_reward_min': -81.94105339059331, 'true_reward_max': -1.2428427124746186, 'proxy_reward_mean': -2.057978913603537, 'proxy_reward_min': -5.9038961030678925, 'proxy_reward_max': -0.6642766952966366, 'modified_reward_mean': -2.7729611105405247, 'modified_reward_min': -6.86431131884368, 'modified_reward_max': -1.068760805138522, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004781347150259071, 'proxyInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.04728906288101228, 'proxyLowerStageReward_min': -0.07527551602617627, 'proxyLowerStageReward_max': -0.026646460896198803, 'proxySmoothStageChangesReward_mean': -0.11528497409326427, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004781347150259071, 'trueInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.009050777202072537, 'truePoliticalReward_min': -0.04186528497409327, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.04728906288101228, 'trueLowerStageReward_min': -0.07527551602617627, 'trueLowerStageReward_max': -0.026646460896198803, 'trueSmoothStageChangesReward_mean': -0.11528497409326427, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.7729611105405247, 'total_modified_reward_min': -6.86431131884368, 'total_modified_reward_max': -1.068760805138522}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.3056011340022087, 'cur_kl_coeff': 0.042187499999999996, 'cur_lr': 0.0003, 'total_loss': -0.00398177525261417, 'policy_loss': -0.00702669463896503, 'vf_loss': 0.06147345224046148, 'vf_explained_var': 0.4580064368247986, 'kl': 0.013150769450275225, 'entropy': 0.5425904393196106, 'entropy_coeff': 0.0520588}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 20850.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 270200, 'num_env_steps_trained': 270200, 'num_agent_steps_sampled': 270200, 'num_agent_steps_trained': 270200}, 'sampler_results': {'episode_reward_max': -1.068760805138522, 'episode_reward_min': -6.86431131884368, 'episode_reward_mean': -2.7729611105405247, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -19.525978913603534, 'default_policy/true_reward_min': -81.94105339059331, 'default_policy/true_reward_max': -1.2428427124746186, 'default_policy/proxy_reward_mean': -2.057978913603537, 'default_policy/proxy_reward_min': -5.9038961030678925, 'default_policy/proxy_reward_max': -0.6642766952966366, 'default_policy/modified_reward_mean': -2.7729611105405247, 'default_policy/modified_reward_min': -6.86431131884368, 'default_policy/modified_reward_max': -1.068760805138522, 'default_policy/corr_btw_rewards_mean': 0.4525880455773726, 'default_policy/corr_btw_rewards_min': 0.09426259572604613, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -19.525978913603534, 'true_reward_min': -81.94105339059331, 'true_reward_max': -1.2428427124746186, 'proxy_reward_mean': -2.057978913603537, 'proxy_reward_min': -5.9038961030678925, 'proxy_reward_max': -0.6642766952966366, 'modified_reward_mean': -2.7729611105405247, 'modified_reward_min': -6.86431131884368, 'modified_reward_max': -1.068760805138522, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004781347150259071, 'proxyInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.04728906288101228, 'proxyLowerStageReward_min': -0.07527551602617627, 'proxyLowerStageReward_max': -0.026646460896198803, 'proxySmoothStageChangesReward_mean': -0.11528497409326427, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004781347150259071, 'trueInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.009050777202072537, 'truePoliticalReward_min': -0.04186528497409327, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.04728906288101228, 'trueLowerStageReward_min': -0.07527551602617627, 'trueLowerStageReward_max': -0.026646460896198803, 'trueSmoothStageChangesReward_mean': -0.11528497409326427, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.7729611105405247, 'total_modified_reward_min': -6.86431131884368, 'total_modified_reward_max': -1.068760805138522}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.530441511853544, 'mean_inference_ms': 1.6783437238758796, 'mean_action_processing_ms': 0.10655936001137807, 'mean_env_wait_ms': 746.5525704632194, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.068760805138522, 'episode_reward_min': -6.86431131884368, 'episode_reward_mean': -2.7729611105405247, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.530441511853544, 'mean_inference_ms': 1.6783437238758796, 'mean_action_processing_ms': 0.10655936001137807, 'mean_env_wait_ms': 746.5525704632194, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 270200, 'num_agent_steps_trained': 270200, 'num_env_steps_sampled': 270200, 'num_env_steps_trained': 270200, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.573642694318647, 'num_env_steps_trained_throughput_per_sec': 12.573642694318647, 'timesteps_total': 270200, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 270200, 'timers': {'training_iteration_time_ms': 309851.795, 'sample_time_ms': 308809.221, 'load_time_ms': 5.09, 'load_throughput': 758317.999, 'learn_time_ms': 1019.649, 'learn_throughput': 3785.617, 'synch_weights_time_ms': 16.923}, 'counters': {'num_env_steps_sampled': 270200, 'num_env_steps_trained': 270200, 'num_agent_steps_sampled': 270200, 'num_agent_steps_trained': 270200}, 'done': False, 'episodes_total': 1400, 'training_iteration': 70, 'trial_id': 'default', 'date': '2025-11-05_01-02-12', 'timestamp': 1762333332, 'time_this_iter_s': 307.0154182910919, 'time_total_s': 22154.66963148117, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6600c3fa0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6600c2980>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2565180>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6882fd120>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 22154.66963148117, 'iterations_since_restore': 70, 'perf': {'cpu_util_percent': 19.016704805491994, 'ram_util_percent': 6.0}})
Iteration 71/100
{'custom_metrics': {'default_policy/true_reward_mean': -18.96670746699413, 'default_policy/true_reward_min': -81.94105339059331, 'default_policy/true_reward_max': -1.2428427124746186, 'default_policy/proxy_reward_mean': -2.0747074669941306, 'default_policy/proxy_reward_min': -5.9038961030678925, 'default_policy/proxy_reward_max': -0.6642766952966366, 'default_policy/modified_reward_mean': -2.7885243889923093, 'default_policy/modified_reward_min': -6.86431131884368, 'default_policy/modified_reward_max': -1.068760805138522, 'default_policy/corr_btw_rewards_mean': 0.459298626822255, 'default_policy/corr_btw_rewards_min': 0.09426259572604613, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -18.96670746699413, 'true_reward_min': -81.94105339059331, 'true_reward_max': -1.2428427124746186, 'proxy_reward_mean': -2.0747074669941306, 'proxy_reward_min': -5.9038961030678925, 'proxy_reward_max': -0.6642766952966366, 'modified_reward_mean': -2.7885243889923093, 'modified_reward_min': -6.86431131884368, 'modified_reward_max': -1.068760805138522, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00048818652849740967, 'proxyInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.04711955787534354, 'proxyLowerStageReward_min': -0.07527551602617627, 'proxyLowerStageReward_max': -0.026646460896198803, 'proxySmoothStageChangesReward_mean': -0.1155958549222798, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00048818652849740967, 'trueInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.008752331606217616, 'truePoliticalReward_min': -0.04186528497409327, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.04711955787534354, 'trueLowerStageReward_min': -0.07527551602617627, 'trueLowerStageReward_max': -0.026646460896198803, 'trueSmoothStageChangesReward_mean': -0.1155958549222798, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.7885243889923093, 'total_modified_reward_min': -6.86431131884368, 'total_modified_reward_max': -1.068760805138522}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.023617531657219, 'cur_kl_coeff': 0.042187499999999996, 'cur_lr': 0.0003, 'total_loss': -0.02531233067003389, 'policy_loss': -0.013441432705149055, 'vf_loss': 0.02408415460959077, 'vf_explained_var': 0.6290532012780508, 'kl': 0.009667929833593132, 'entropy': 0.4734997010231018, 'entropy_coeff': 0.05136400000000002}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 21150.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 274060, 'num_env_steps_trained': 274060, 'num_agent_steps_sampled': 274060, 'num_agent_steps_trained': 274060}, 'sampler_results': {'episode_reward_max': -1.068760805138522, 'episode_reward_min': -6.86431131884368, 'episode_reward_mean': -2.7885243889923093, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -18.96670746699413, 'default_policy/true_reward_min': -81.94105339059331, 'default_policy/true_reward_max': -1.2428427124746186, 'default_policy/proxy_reward_mean': -2.0747074669941306, 'default_policy/proxy_reward_min': -5.9038961030678925, 'default_policy/proxy_reward_max': -0.6642766952966366, 'default_policy/modified_reward_mean': -2.7885243889923093, 'default_policy/modified_reward_min': -6.86431131884368, 'default_policy/modified_reward_max': -1.068760805138522, 'default_policy/corr_btw_rewards_mean': 0.459298626822255, 'default_policy/corr_btw_rewards_min': 0.09426259572604613, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -18.96670746699413, 'true_reward_min': -81.94105339059331, 'true_reward_max': -1.2428427124746186, 'proxy_reward_mean': -2.0747074669941306, 'proxy_reward_min': -5.9038961030678925, 'proxy_reward_max': -0.6642766952966366, 'modified_reward_mean': -2.7885243889923093, 'modified_reward_min': -6.86431131884368, 'modified_reward_max': -1.068760805138522, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00048818652849740967, 'proxyInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.04711955787534354, 'proxyLowerStageReward_min': -0.07527551602617627, 'proxyLowerStageReward_max': -0.026646460896198803, 'proxySmoothStageChangesReward_mean': -0.1155958549222798, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00048818652849740967, 'trueInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.008752331606217616, 'truePoliticalReward_min': -0.04186528497409327, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.04711955787534354, 'trueLowerStageReward_min': -0.07527551602617627, 'trueLowerStageReward_max': -0.026646460896198803, 'trueSmoothStageChangesReward_mean': -0.1155958549222798, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.7885243889923093, 'total_modified_reward_min': -6.86431131884368, 'total_modified_reward_max': -1.068760805138522}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5307414312831809, 'mean_inference_ms': 1.6780443217966259, 'mean_action_processing_ms': 0.10652633672848927, 'mean_env_wait_ms': 745.9416039322256, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.068760805138522, 'episode_reward_min': -6.86431131884368, 'episode_reward_mean': -2.7885243889923093, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5307414312831809, 'mean_inference_ms': 1.6780443217966259, 'mean_action_processing_ms': 0.10652633672848927, 'mean_env_wait_ms': 745.9416039322256, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 274060, 'num_agent_steps_trained': 274060, 'num_env_steps_sampled': 274060, 'num_env_steps_trained': 274060, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.485516766303013, 'num_env_steps_trained_throughput_per_sec': 12.485516766303013, 'timesteps_total': 274060, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 274060, 'timers': {'training_iteration_time_ms': 310092.484, 'sample_time_ms': 309056.42, 'load_time_ms': 5.053, 'load_throughput': 763881.659, 'learn_time_ms': 1013.274, 'learn_throughput': 3809.434, 'synch_weights_time_ms': 16.834}, 'counters': {'num_env_steps_sampled': 274060, 'num_env_steps_trained': 274060, 'num_agent_steps_sampled': 274060, 'num_agent_steps_trained': 274060}, 'done': False, 'episodes_total': 1420, 'training_iteration': 71, 'trial_id': 'default', 'date': '2025-11-05_01-07-22', 'timestamp': 1762333642, 'time_this_iter_s': 309.1803689002991, 'time_total_s': 22463.85000038147, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6a9205780>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6a9206530>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6a9206410>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6a9205960>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 22463.85000038147, 'iterations_since_restore': 71, 'perf': {'cpu_util_percent': 18.90090702947846, 'ram_util_percent': 6.0}}
Iteration 72/100
{'custom_metrics': {'default_policy/true_reward_mean': -25.204613689914385, 'default_policy/true_reward_min': -95.8031854249493, 'default_policy/true_reward_max': -1.2428427124746186, 'default_policy/proxy_reward_mean': -2.0206136899143874, 'default_policy/proxy_reward_min': -5.9038961030678925, 'default_policy/proxy_reward_max': -0.6642766952966366, 'default_policy/modified_reward_mean': -2.746259211168699, 'default_policy/modified_reward_min': -6.86431131884368, 'default_policy/modified_reward_max': -1.068760805138522, 'default_policy/corr_btw_rewards_mean': 0.4805638182978964, 'default_policy/corr_btw_rewards_min': 0.09426259572604613, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -25.204613689914385, 'true_reward_min': -95.8031854249493, 'true_reward_max': -1.2428427124746186, 'proxy_reward_mean': -2.0206136899143874, 'proxy_reward_min': -5.9038961030678925, 'proxy_reward_max': -0.6642766952966366, 'modified_reward_mean': -2.746259211168699, 'modified_reward_min': -6.86431131884368, 'modified_reward_max': -1.068760805138522, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00045357512953367904, 'proxyInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.04721832590229986, 'proxyLowerStageReward_min': -0.07527551602617627, 'proxyLowerStageReward_max': -0.028589466077545957, 'proxySmoothStageChangesReward_mean': -0.12119170984455958, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00045357512953367904, 'trueInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.012012435233160623, 'truePoliticalReward_min': -0.04870466321243524, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.04721832590229986, 'trueLowerStageReward_min': -0.07527551602617627, 'trueLowerStageReward_max': -0.028589466077545957, 'trueSmoothStageChangesReward_mean': -0.12119170984455958, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.746259211168699, 'total_modified_reward_min': -6.86431131884368, 'total_modified_reward_max': -1.068760805138522}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.7938655190169811, 'cur_kl_coeff': 0.042187499999999996, 'cur_lr': 0.0003, 'total_loss': -0.028516865399045247, 'policy_loss': -0.012386802608768146, 'vf_loss': 0.011600426062359474, 'vf_explained_var': 0.7595540505647659, 'kl': 0.0085041990639479, 'entropy': 0.4398934641480446, 'entropy_coeff': 0.05066919999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 21450.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 277920, 'num_env_steps_trained': 277920, 'num_agent_steps_sampled': 277920, 'num_agent_steps_trained': 277920}, 'sampler_results': {'episode_reward_max': -1.068760805138522, 'episode_reward_min': -6.86431131884368, 'episode_reward_mean': -2.746259211168699, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -25.204613689914385, 'default_policy/true_reward_min': -95.8031854249493, 'default_policy/true_reward_max': -1.2428427124746186, 'default_policy/proxy_reward_mean': -2.0206136899143874, 'default_policy/proxy_reward_min': -5.9038961030678925, 'default_policy/proxy_reward_max': -0.6642766952966366, 'default_policy/modified_reward_mean': -2.746259211168699, 'default_policy/modified_reward_min': -6.86431131884368, 'default_policy/modified_reward_max': -1.068760805138522, 'default_policy/corr_btw_rewards_mean': 0.4805638182978964, 'default_policy/corr_btw_rewards_min': 0.09426259572604613, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -25.204613689914385, 'true_reward_min': -95.8031854249493, 'true_reward_max': -1.2428427124746186, 'proxy_reward_mean': -2.0206136899143874, 'proxy_reward_min': -5.9038961030678925, 'proxy_reward_max': -0.6642766952966366, 'modified_reward_mean': -2.746259211168699, 'modified_reward_min': -6.86431131884368, 'modified_reward_max': -1.068760805138522, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00045357512953367904, 'proxyInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.04721832590229986, 'proxyLowerStageReward_min': -0.07527551602617627, 'proxyLowerStageReward_max': -0.028589466077545957, 'proxySmoothStageChangesReward_mean': -0.12119170984455958, 'proxySmoothStageChangesReward_min': -0.22279792746113988, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00045357512953367904, 'trueInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.012012435233160623, 'truePoliticalReward_min': -0.04870466321243524, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.04721832590229986, 'trueLowerStageReward_min': -0.07527551602617627, 'trueLowerStageReward_max': -0.028589466077545957, 'trueSmoothStageChangesReward_mean': -0.12119170984455958, 'trueSmoothStageChangesReward_min': -0.22279792746113988, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.746259211168699, 'total_modified_reward_min': -6.86431131884368, 'total_modified_reward_max': -1.068760805138522}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5314621976840697, 'mean_inference_ms': 1.6777277428004027, 'mean_action_processing_ms': 0.10650039663903187, 'mean_env_wait_ms': 745.3698647162743, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.068760805138522, 'episode_reward_min': -6.86431131884368, 'episode_reward_mean': -2.746259211168699, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5314621976840697, 'mean_inference_ms': 1.6777277428004027, 'mean_action_processing_ms': 0.10650039663903187, 'mean_env_wait_ms': 745.3698647162743, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 277920, 'num_agent_steps_trained': 277920, 'num_env_steps_sampled': 277920, 'num_env_steps_trained': 277920, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.133116086626812, 'num_env_steps_trained_throughput_per_sec': 13.133116086626812, 'timesteps_total': 277920, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 277920, 'timers': {'training_iteration_time_ms': 309259.958, 'sample_time_ms': 308215.849, 'load_time_ms': 5.101, 'load_throughput': 756648.756, 'learn_time_ms': 1021.387, 'learn_throughput': 3779.176, 'synch_weights_time_ms': 16.72}, 'counters': {'num_env_steps_sampled': 277920, 'num_env_steps_trained': 277920, 'num_agent_steps_sampled': 277920, 'num_agent_steps_trained': 277920}, 'done': False, 'episodes_total': 1440, 'training_iteration': 72, 'trial_id': 'default', 'date': '2025-11-05_01-12-16', 'timestamp': 1762333936, 'time_this_iter_s': 293.92990231513977, 'time_total_s': 22757.77990269661, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e2630250>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e0ffff70>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e26329e0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2631ed0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 22757.77990269661, 'iterations_since_restore': 72, 'perf': {'cpu_util_percent': 20.11551312649165, 'ram_util_percent': 6.0}}
Iteration 73/100
{'custom_metrics': {'default_policy/true_reward_mean': -27.56624909755448, 'default_policy/true_reward_min': -95.8031854249493, 'default_policy/true_reward_max': -1.1267640687119282, 'default_policy/proxy_reward_mean': -1.9422490975544726, 'default_policy/proxy_reward_min': -5.9038961030678925, 'default_policy/proxy_reward_max': -0.7678427124746191, 'default_policy/modified_reward_mean': -2.6595776669226, 'default_policy/modified_reward_min': -6.86431131884368, 'default_policy/modified_reward_max': -1.255835076459129, 'default_policy/corr_btw_rewards_mean': 0.46611990812832305, 'default_policy/corr_btw_rewards_min': 0.09426259572604613, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -27.56624909755448, 'true_reward_min': -95.8031854249493, 'true_reward_max': -1.1267640687119282, 'proxy_reward_mean': -1.9422490975544726, 'proxy_reward_min': -5.9038961030678925, 'proxy_reward_max': -0.7678427124746191, 'modified_reward_mean': -2.6595776669226, 'modified_reward_min': -6.86431131884368, 'modified_reward_max': -1.255835076459129, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00042321243523316094, 'proxyInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0459300050546359, 'proxyLowerStageReward_min': -0.06654152549881968, 'proxyLowerStageReward_max': -0.025128879451569518, 'proxySmoothStageChangesReward_mean': -0.12383419689119173, 'proxySmoothStageChangesReward_min': -0.20725388601036268, 'proxySmoothStageChangesReward_max': -0.07253886010362694, 'trueInfectionSummaryAbsoluteReward_mean': -0.00042321243523316094, 'trueInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.013276683937823837, 'truePoliticalReward_min': -0.04870466321243524, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.0459300050546359, 'trueLowerStageReward_min': -0.06654152549881968, 'trueLowerStageReward_max': -0.025128879451569518, 'trueSmoothStageChangesReward_mean': -0.12383419689119173, 'trueSmoothStageChangesReward_min': -0.20725388601036268, 'trueSmoothStageChangesReward_max': -0.07253886010362694, 'total_modified_reward_mean': -2.6595776669226, 'total_modified_reward_min': -6.86431131884368, 'total_modified_reward_max': -1.255835076459129}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0514201692243417, 'cur_kl_coeff': 0.042187499999999996, 'cur_lr': 0.0003, 'total_loss': -0.010307138844703634, 'policy_loss': -0.005338485418663671, 'vf_loss': 0.03065191089796523, 'vf_explained_var': 0.5734190964698791, 'kl': 0.004937471296059848, 'entropy': 0.41026829436421397, 'entropy_coeff': 0.049974399999999995}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 21750.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 281780, 'num_env_steps_trained': 281780, 'num_agent_steps_sampled': 281780, 'num_agent_steps_trained': 281780}, 'sampler_results': {'episode_reward_max': -1.255835076459129, 'episode_reward_min': -6.86431131884368, 'episode_reward_mean': -2.6595776669226, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -27.56624909755448, 'default_policy/true_reward_min': -95.8031854249493, 'default_policy/true_reward_max': -1.1267640687119282, 'default_policy/proxy_reward_mean': -1.9422490975544726, 'default_policy/proxy_reward_min': -5.9038961030678925, 'default_policy/proxy_reward_max': -0.7678427124746191, 'default_policy/modified_reward_mean': -2.6595776669226, 'default_policy/modified_reward_min': -6.86431131884368, 'default_policy/modified_reward_max': -1.255835076459129, 'default_policy/corr_btw_rewards_mean': 0.46611990812832305, 'default_policy/corr_btw_rewards_min': 0.09426259572604613, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -27.56624909755448, 'true_reward_min': -95.8031854249493, 'true_reward_max': -1.1267640687119282, 'proxy_reward_mean': -1.9422490975544726, 'proxy_reward_min': -5.9038961030678925, 'proxy_reward_max': -0.7678427124746191, 'modified_reward_mean': -2.6595776669226, 'modified_reward_min': -6.86431131884368, 'modified_reward_max': -1.255835076459129, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00042321243523316094, 'proxyInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0459300050546359, 'proxyLowerStageReward_min': -0.06654152549881968, 'proxyLowerStageReward_max': -0.025128879451569518, 'proxySmoothStageChangesReward_mean': -0.12383419689119173, 'proxySmoothStageChangesReward_min': -0.20725388601036268, 'proxySmoothStageChangesReward_max': -0.07253886010362694, 'trueInfectionSummaryAbsoluteReward_mean': -0.00042321243523316094, 'trueInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.013276683937823837, 'truePoliticalReward_min': -0.04870466321243524, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.0459300050546359, 'trueLowerStageReward_min': -0.06654152549881968, 'trueLowerStageReward_max': -0.025128879451569518, 'trueSmoothStageChangesReward_mean': -0.12383419689119173, 'trueSmoothStageChangesReward_min': -0.20725388601036268, 'trueSmoothStageChangesReward_max': -0.07253886010362694, 'total_modified_reward_mean': -2.6595776669226, 'total_modified_reward_min': -6.86431131884368, 'total_modified_reward_max': -1.255835076459129}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.53275848791515, 'mean_inference_ms': 1.6774785235069438, 'mean_action_processing_ms': 0.10647519327122096, 'mean_env_wait_ms': 744.8667955048212, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.255835076459129, 'episode_reward_min': -6.86431131884368, 'episode_reward_mean': -2.6595776669226, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.53275848791515, 'mean_inference_ms': 1.6774785235069438, 'mean_action_processing_ms': 0.10647519327122096, 'mean_env_wait_ms': 744.8667955048212, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 281780, 'num_agent_steps_trained': 281780, 'num_env_steps_sampled': 281780, 'num_env_steps_trained': 281780, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.324527827662758, 'num_env_steps_trained_throughput_per_sec': 13.324527827662758, 'timesteps_total': 281780, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 281780, 'timers': {'training_iteration_time_ms': 304609.551, 'sample_time_ms': 303582.775, 'load_time_ms': 5.35, 'load_throughput': 721454.38, 'learn_time_ms': 1003.725, 'learn_throughput': 3845.673, 'synch_weights_time_ms': 16.813}, 'counters': {'num_env_steps_sampled': 281780, 'num_env_steps_trained': 281780, 'num_agent_steps_sampled': 281780, 'num_agent_steps_trained': 281780}, 'done': False, 'episodes_total': 1460, 'training_iteration': 73, 'trial_id': 'default', 'date': '2025-11-05_01-17-06', 'timestamp': 1762334226, 'time_this_iter_s': 289.71231341362, 'time_total_s': 23047.49221611023, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e2097e20>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e2097370>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2567730>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2566890>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 23047.49221611023, 'iterations_since_restore': 73, 'perf': {'cpu_util_percent': 20.452300242130754, 'ram_util_percent': 6.0}}
Iteration 74/100
{'custom_metrics': {'default_policy/true_reward_mean': -28.86468881618024, 'default_policy/true_reward_min': -95.8031854249493, 'default_policy/true_reward_max': -1.1267640687119282, 'default_policy/proxy_reward_mean': -1.8486888161802344, 'default_policy/proxy_reward_min': -5.831408729652601, 'default_policy/proxy_reward_max': -0.7053427124746192, 'default_policy/modified_reward_mean': -2.540808749105558, 'default_policy/modified_reward_min': -6.79694987943087, 'default_policy/modified_reward_max': -1.159610031594192, 'default_policy/corr_btw_rewards_mean': 0.46922214010993796, 'default_policy/corr_btw_rewards_min': 0.09426259572604613, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -28.86468881618024, 'true_reward_min': -95.8031854249493, 'true_reward_max': -1.1267640687119282, 'proxy_reward_mean': -1.8486888161802344, 'proxy_reward_min': -5.831408729652601, 'proxy_reward_max': -0.7053427124746192, 'modified_reward_mean': -2.540808749105558, 'modified_reward_min': -6.79694987943087, 'modified_reward_max': -1.159610031594192, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003973056994818656, 'proxyInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.043864705501566556, 'proxyLowerStageReward_min': -0.06922425582507029, 'proxyLowerStageReward_max': -0.025128879451569518, 'proxySmoothStageChangesReward_mean': -0.12191709844559587, 'proxySmoothStageChangesReward_min': -0.20725388601036268, 'proxySmoothStageChangesReward_max': -0.07253886010362694, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003973056994818656, 'trueInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.013997927461139896, 'truePoliticalReward_min': -0.04870466321243524, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.043864705501566556, 'trueLowerStageReward_min': -0.06922425582507029, 'trueLowerStageReward_max': -0.025128879451569518, 'trueSmoothStageChangesReward_mean': -0.12191709844559587, 'trueSmoothStageChangesReward_min': -0.20725388601036268, 'trueSmoothStageChangesReward_max': -0.07253886010362694, 'total_modified_reward_mean': -2.540808749105558, 'total_modified_reward_min': -6.79694987943087, 'total_modified_reward_max': -1.159610031594192}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0955681580305099, 'cur_kl_coeff': 0.021093749999999998, 'cur_lr': 0.0003, 'total_loss': -0.021519819103802244, 'policy_loss': -0.019176792309929927, 'vf_loss': 0.035102712933439764, 'vf_explained_var': 0.47252480645974476, 'kl': 0.006088074690837139, 'entropy': 0.40631020029385884, 'entropy_coeff': 0.04927960000000001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 22050.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 285640, 'num_env_steps_trained': 285640, 'num_agent_steps_sampled': 285640, 'num_agent_steps_trained': 285640}, 'sampler_results': {'episode_reward_max': -1.159610031594192, 'episode_reward_min': -6.79694987943087, 'episode_reward_mean': -2.540808749105558, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -28.86468881618024, 'default_policy/true_reward_min': -95.8031854249493, 'default_policy/true_reward_max': -1.1267640687119282, 'default_policy/proxy_reward_mean': -1.8486888161802344, 'default_policy/proxy_reward_min': -5.831408729652601, 'default_policy/proxy_reward_max': -0.7053427124746192, 'default_policy/modified_reward_mean': -2.540808749105558, 'default_policy/modified_reward_min': -6.79694987943087, 'default_policy/modified_reward_max': -1.159610031594192, 'default_policy/corr_btw_rewards_mean': 0.46922214010993796, 'default_policy/corr_btw_rewards_min': 0.09426259572604613, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -28.86468881618024, 'true_reward_min': -95.8031854249493, 'true_reward_max': -1.1267640687119282, 'proxy_reward_mean': -1.8486888161802344, 'proxy_reward_min': -5.831408729652601, 'proxy_reward_max': -0.7053427124746192, 'modified_reward_mean': -2.540808749105558, 'modified_reward_min': -6.79694987943087, 'modified_reward_max': -1.159610031594192, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003973056994818656, 'proxyInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.043864705501566556, 'proxyLowerStageReward_min': -0.06922425582507029, 'proxyLowerStageReward_max': -0.025128879451569518, 'proxySmoothStageChangesReward_mean': -0.12191709844559587, 'proxySmoothStageChangesReward_min': -0.20725388601036268, 'proxySmoothStageChangesReward_max': -0.07253886010362694, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003973056994818656, 'trueInfectionSummaryAbsoluteReward_min': -0.00250777202072539, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.013997927461139896, 'truePoliticalReward_min': -0.04870466321243524, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.043864705501566556, 'trueLowerStageReward_min': -0.06922425582507029, 'trueLowerStageReward_max': -0.025128879451569518, 'trueSmoothStageChangesReward_mean': -0.12191709844559587, 'trueSmoothStageChangesReward_min': -0.20725388601036268, 'trueSmoothStageChangesReward_max': -0.07253886010362694, 'total_modified_reward_mean': -2.540808749105558, 'total_modified_reward_min': -6.79694987943087, 'total_modified_reward_max': -1.159610031594192}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5342177075725527, 'mean_inference_ms': 1.6772940198877309, 'mean_action_processing_ms': 0.10645810556174792, 'mean_env_wait_ms': 744.4066085226452, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -1.159610031594192, 'episode_reward_min': -6.79694987943087, 'episode_reward_mean': -2.540808749105558, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5342177075725527, 'mean_inference_ms': 1.6772940198877309, 'mean_action_processing_ms': 0.10645810556174792, 'mean_env_wait_ms': 744.4066085226452, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 285640, 'num_agent_steps_trained': 285640, 'num_env_steps_sampled': 285640, 'num_env_steps_trained': 285640, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.384057828770583, 'num_env_steps_trained_throughput_per_sec': 13.384057828770583, 'timesteps_total': 285640, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 285640, 'timers': {'training_iteration_time_ms': 303468.703, 'sample_time_ms': 302443.498, 'load_time_ms': 5.163, 'load_throughput': 747606.343, 'learn_time_ms': 1002.713, 'learn_throughput': 3849.555, 'synch_weights_time_ms': 16.45}, 'counters': {'num_env_steps_sampled': 285640, 'num_env_steps_trained': 285640, 'num_agent_steps_sampled': 285640, 'num_agent_steps_trained': 285640}, 'done': False, 'episodes_total': 1480, 'training_iteration': 74, 'trial_id': 'default', 'date': '2025-11-05_01-21-54', 'timestamp': 1762334514, 'time_this_iter_s': 288.42319321632385, 'time_total_s': 23335.915409326553, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e2565bd0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6a9255cf0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2632ce0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2633f10>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 23335.915409326553, 'iterations_since_restore': 74, 'perf': {'cpu_util_percent': 20.04563106796117, 'ram_util_percent': 6.0}}
Iteration 75/100
{'custom_metrics': {'default_policy/true_reward_mean': -29.25657561274465, 'default_policy/true_reward_min': -95.8031854249493, 'default_policy/true_reward_max': -1.1267640687119282, 'default_policy/proxy_reward_mean': -1.7405756127446375, 'default_policy/proxy_reward_min': -5.6860281374238495, 'default_policy/proxy_reward_max': -0.5571320343559643, 'default_policy/modified_reward_mean': -2.401975673665186, 'default_policy/modified_reward_min': -6.79694987943087, 'default_policy/modified_reward_max': -0.913008793884866, 'default_policy/corr_btw_rewards_mean': 0.49738493157741365, 'default_policy/corr_btw_rewards_min': 0.11370222818131065, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -29.25657561274465, 'true_reward_min': -95.8031854249493, 'true_reward_max': -1.1267640687119282, 'proxy_reward_mean': -1.7405756127446375, 'proxy_reward_min': -5.6860281374238495, 'proxy_reward_max': -0.5571320343559643, 'modified_reward_mean': -2.401975673665186, 'modified_reward_min': -6.79694987943087, 'modified_reward_max': -0.913008793884866, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00036632124352331633, 'proxyInfectionSummaryAbsoluteReward_min': -0.002051813471502592, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.04188474677433357, 'proxyLowerStageReward_min': -0.06922425582507029, 'proxyLowerStageReward_max': -0.022649328204972244, 'proxySmoothStageChangesReward_mean': -0.11668393782383422, 'proxySmoothStageChangesReward_min': -0.20207253886010362, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.00036632124352331633, 'trueInfectionSummaryAbsoluteReward_min': -0.002051813471502592, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.014256994818652852, 'truePoliticalReward_min': -0.04870466321243524, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.04188474677433357, 'trueLowerStageReward_min': -0.06922425582507029, 'trueLowerStageReward_max': -0.022649328204972244, 'trueSmoothStageChangesReward_mean': -0.11668393782383422, 'trueSmoothStageChangesReward_min': -0.20207253886010362, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -2.401975673665186, 'total_modified_reward_min': -6.79694987943087, 'total_modified_reward_max': -0.913008793884866}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.3492020875712236, 'cur_kl_coeff': 0.021093749999999998, 'cur_lr': 0.0003, 'total_loss': 0.002281264290213585, 'policy_loss': -0.004545534527860582, 'vf_loss': 0.052138394232994566, 'vf_explained_var': 0.4414086220661799, 'kl': 0.006082510640160536, 'entropy': 0.3986988108853499, 'entropy_coeff': 0.04858479999999999}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 22350.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 289500, 'num_env_steps_trained': 289500, 'num_agent_steps_sampled': 289500, 'num_agent_steps_trained': 289500}, 'sampler_results': {'episode_reward_max': -0.913008793884866, 'episode_reward_min': -6.79694987943087, 'episode_reward_mean': -2.401975673665186, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -29.25657561274465, 'default_policy/true_reward_min': -95.8031854249493, 'default_policy/true_reward_max': -1.1267640687119282, 'default_policy/proxy_reward_mean': -1.7405756127446375, 'default_policy/proxy_reward_min': -5.6860281374238495, 'default_policy/proxy_reward_max': -0.5571320343559643, 'default_policy/modified_reward_mean': -2.401975673665186, 'default_policy/modified_reward_min': -6.79694987943087, 'default_policy/modified_reward_max': -0.913008793884866, 'default_policy/corr_btw_rewards_mean': 0.49738493157741365, 'default_policy/corr_btw_rewards_min': 0.11370222818131065, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -29.25657561274465, 'true_reward_min': -95.8031854249493, 'true_reward_max': -1.1267640687119282, 'proxy_reward_mean': -1.7405756127446375, 'proxy_reward_min': -5.6860281374238495, 'proxy_reward_max': -0.5571320343559643, 'modified_reward_mean': -2.401975673665186, 'modified_reward_min': -6.79694987943087, 'modified_reward_max': -0.913008793884866, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00036632124352331633, 'proxyInfectionSummaryAbsoluteReward_min': -0.002051813471502592, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.04188474677433357, 'proxyLowerStageReward_min': -0.06922425582507029, 'proxyLowerStageReward_max': -0.022649328204972244, 'proxySmoothStageChangesReward_mean': -0.11668393782383422, 'proxySmoothStageChangesReward_min': -0.20207253886010362, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.00036632124352331633, 'trueInfectionSummaryAbsoluteReward_min': -0.002051813471502592, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.014256994818652852, 'truePoliticalReward_min': -0.04870466321243524, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.04188474677433357, 'trueLowerStageReward_min': -0.06922425582507029, 'trueLowerStageReward_max': -0.022649328204972244, 'trueSmoothStageChangesReward_mean': -0.11668393782383422, 'trueSmoothStageChangesReward_min': -0.20207253886010362, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -2.401975673665186, 'total_modified_reward_min': -6.79694987943087, 'total_modified_reward_max': -0.913008793884866}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5356813155716402, 'mean_inference_ms': 1.6771192272467652, 'mean_action_processing_ms': 0.10644030472877475, 'mean_env_wait_ms': 744.0389892310334, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.913008793884866, 'episode_reward_min': -6.79694987943087, 'episode_reward_mean': -2.401975673665186, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5356813155716402, 'mean_inference_ms': 1.6771192272467652, 'mean_action_processing_ms': 0.10644030472877475, 'mean_env_wait_ms': 744.0389892310334, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 289500, 'num_agent_steps_trained': 289500, 'num_env_steps_sampled': 289500, 'num_env_steps_trained': 289500, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.400386172488204, 'num_env_steps_trained_throughput_per_sec': 13.400386172488204, 'timesteps_total': 289500, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 289500, 'timers': {'training_iteration_time_ms': 301828.599, 'sample_time_ms': 300789.721, 'load_time_ms': 5.158, 'load_throughput': 748376.982, 'learn_time_ms': 1016.351, 'learn_throughput': 3797.901, 'synch_weights_time_ms': 16.475}, 'counters': {'num_env_steps_sampled': 289500, 'num_env_steps_trained': 289500, 'num_agent_steps_sampled': 289500, 'num_agent_steps_trained': 289500}, 'done': False, 'episodes_total': 1500, 'training_iteration': 75, 'trial_id': 'default', 'date': '2025-11-05_01-26-42', 'timestamp': 1762334802, 'time_this_iter_s': 288.07104325294495, 'time_total_s': 23623.9864525795, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a699535e70>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6a9255cc0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffd390>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffe9e0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 23623.9864525795, 'iterations_since_restore': 75, 'perf': {'cpu_util_percent': 20.157804878048783, 'ram_util_percent': 6.0}}
Iteration 76/100
{'custom_metrics': {'default_policy/true_reward_mean': -26.699226117808035, 'default_policy/true_reward_min': -95.8031854249493, 'default_policy/true_reward_max': -1.1267640687119282, 'default_policy/proxy_reward_mean': -1.7232261178080264, 'default_policy/proxy_reward_min': -5.6860281374238495, 'default_policy/proxy_reward_max': -0.5571320343559643, 'default_policy/modified_reward_mean': -2.371609903257237, 'default_policy/modified_reward_min': -6.79694987943087, 'default_policy/modified_reward_max': -0.913008793884866, 'default_policy/corr_btw_rewards_mean': 0.5037400330456765, 'default_policy/corr_btw_rewards_min': 0.11370222818131065, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -26.699226117808035, 'true_reward_min': -95.8031854249493, 'true_reward_max': -1.1267640687119282, 'proxy_reward_mean': -1.7232261178080264, 'proxy_reward_min': -5.6860281374238495, 'proxy_reward_max': -0.5571320343559643, 'modified_reward_mean': -2.371609903257237, 'modified_reward_min': -6.79694987943087, 'modified_reward_max': -0.913008793884866, 'proxyInfectionSummaryAbsoluteReward_mean': -0.000366735751295337, 'proxyInfectionSummaryAbsoluteReward_min': -0.002051813471502592, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.04130705273616716, 'proxyLowerStageReward_min': -0.06922425582507029, 'proxyLowerStageReward_max': -0.022649328204972244, 'proxySmoothStageChangesReward_mean': -0.11305699481865286, 'proxySmoothStageChangesReward_min': -0.20207253886010362, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.000366735751295337, 'trueInfectionSummaryAbsoluteReward_min': -0.002051813471502592, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.012940932642487048, 'truePoliticalReward_min': -0.04870466321243524, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.04130705273616716, 'trueLowerStageReward_min': -0.06922425582507029, 'trueLowerStageReward_max': -0.022649328204972244, 'trueSmoothStageChangesReward_mean': -0.11305699481865286, 'trueSmoothStageChangesReward_min': -0.20207253886010362, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -2.371609903257237, 'total_modified_reward_min': -6.79694987943087, 'total_modified_reward_max': -0.913008793884866}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9790420278906822, 'cur_kl_coeff': 0.021093749999999998, 'cur_lr': 0.0003, 'total_loss': -0.02086524213043352, 'policy_loss': -0.014338541540006796, 'vf_loss': 0.025642149874280828, 'vf_explained_var': 0.6499460552136104, 'kl': 0.007082673058560989, 'entropy': 0.40712418635686237, 'entropy_coeff': 0.04788999999999999}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 22650.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 293360, 'num_env_steps_trained': 293360, 'num_agent_steps_sampled': 293360, 'num_agent_steps_trained': 293360}, 'sampler_results': {'episode_reward_max': -0.913008793884866, 'episode_reward_min': -6.79694987943087, 'episode_reward_mean': -2.371609903257237, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -26.699226117808035, 'default_policy/true_reward_min': -95.8031854249493, 'default_policy/true_reward_max': -1.1267640687119282, 'default_policy/proxy_reward_mean': -1.7232261178080264, 'default_policy/proxy_reward_min': -5.6860281374238495, 'default_policy/proxy_reward_max': -0.5571320343559643, 'default_policy/modified_reward_mean': -2.371609903257237, 'default_policy/modified_reward_min': -6.79694987943087, 'default_policy/modified_reward_max': -0.913008793884866, 'default_policy/corr_btw_rewards_mean': 0.5037400330456765, 'default_policy/corr_btw_rewards_min': 0.11370222818131065, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -26.699226117808035, 'true_reward_min': -95.8031854249493, 'true_reward_max': -1.1267640687119282, 'proxy_reward_mean': -1.7232261178080264, 'proxy_reward_min': -5.6860281374238495, 'proxy_reward_max': -0.5571320343559643, 'modified_reward_mean': -2.371609903257237, 'modified_reward_min': -6.79694987943087, 'modified_reward_max': -0.913008793884866, 'proxyInfectionSummaryAbsoluteReward_mean': -0.000366735751295337, 'proxyInfectionSummaryAbsoluteReward_min': -0.002051813471502592, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.04130705273616716, 'proxyLowerStageReward_min': -0.06922425582507029, 'proxyLowerStageReward_max': -0.022649328204972244, 'proxySmoothStageChangesReward_mean': -0.11305699481865286, 'proxySmoothStageChangesReward_min': -0.20207253886010362, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.000366735751295337, 'trueInfectionSummaryAbsoluteReward_min': -0.002051813471502592, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.012940932642487048, 'truePoliticalReward_min': -0.04870466321243524, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.04130705273616716, 'trueLowerStageReward_min': -0.06922425582507029, 'trueLowerStageReward_max': -0.022649328204972244, 'trueSmoothStageChangesReward_mean': -0.11305699481865286, 'trueSmoothStageChangesReward_min': -0.20207253886010362, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -2.371609903257237, 'total_modified_reward_min': -6.79694987943087, 'total_modified_reward_max': -0.913008793884866}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.536846041288524, 'mean_inference_ms': 1.6769731438580715, 'mean_action_processing_ms': 0.10642881744004674, 'mean_env_wait_ms': 743.77019452024, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.913008793884866, 'episode_reward_min': -6.79694987943087, 'episode_reward_mean': -2.371609903257237, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.536846041288524, 'mean_inference_ms': 1.6769731438580715, 'mean_action_processing_ms': 0.10642881744004674, 'mean_env_wait_ms': 743.77019452024, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 293360, 'num_agent_steps_trained': 293360, 'num_env_steps_sampled': 293360, 'num_env_steps_trained': 293360, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.315934025146827, 'num_env_steps_trained_throughput_per_sec': 13.315934025146827, 'timesteps_total': 293360, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 293360, 'timers': {'training_iteration_time_ms': 299461.478, 'sample_time_ms': 298422.712, 'load_time_ms': 4.989, 'load_throughput': 773701.503, 'learn_time_ms': 1016.515, 'learn_throughput': 3797.289, 'synch_weights_time_ms': 16.401}, 'counters': {'num_env_steps_sampled': 293360, 'num_env_steps_trained': 293360, 'num_agent_steps_sampled': 293360, 'num_agent_steps_trained': 293360}, 'done': False, 'episodes_total': 1520, 'training_iteration': 76, 'trial_id': 'default', 'date': '2025-11-05_01-31-32', 'timestamp': 1762335092, 'time_this_iter_s': 289.8950626850128, 'time_total_s': 23913.88151526451, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6a9cdb8e0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6995347f0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699561e40>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699563370>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 23913.88151526451, 'iterations_since_restore': 76, 'perf': {'cpu_util_percent': 20.11113801452785, 'ram_util_percent': 6.0}}
Iteration 77/100
{'custom_metrics': {'default_policy/true_reward_mean': -20.92709527368531, 'default_policy/true_reward_min': -82.04961940777129, 'default_policy/true_reward_max': -0.6821320343559639, 'default_policy/proxy_reward_mean': -1.6790952736853106, 'default_policy/proxy_reward_min': -5.6860281374238495, 'default_policy/proxy_reward_max': -0.4517766952966371, 'default_policy/modified_reward_mean': -2.288916506694851, 'default_policy/modified_reward_min': -6.79694987943087, 'default_policy/modified_reward_max': -0.7415956525977342, 'default_policy/corr_btw_rewards_mean': 0.4976759104364507, 'default_policy/corr_btw_rewards_min': 0.10416519971131906, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -20.92709527368531, 'true_reward_min': -82.04961940777129, 'true_reward_max': -0.6821320343559639, 'proxy_reward_mean': -1.6790952736853106, 'proxy_reward_min': -5.6860281374238495, 'proxy_reward_max': -0.4517766952966371, 'modified_reward_mean': -2.288916506694851, 'modified_reward_min': -6.79694987943087, 'modified_reward_max': -0.7415956525977342, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003734715025906737, 'proxyInfectionSummaryAbsoluteReward_min': -0.002051813471502592, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03921737169353941, 'proxyLowerStageReward_min': -0.06922425582507029, 'proxyLowerStageReward_max': -0.01822677177702782, 'proxySmoothStageChangesReward_mean': -0.10435233160621761, 'proxySmoothStageChangesReward_min': -0.20207253886010362, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003734715025906737, 'trueInfectionSummaryAbsoluteReward_min': -0.002051813471502592, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.009973056994818652, 'truePoliticalReward_min': -0.04186528497409327, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03921737169353941, 'trueLowerStageReward_min': -0.06922425582507029, 'trueLowerStageReward_max': -0.01822677177702782, 'trueSmoothStageChangesReward_mean': -0.10435233160621761, 'trueSmoothStageChangesReward_min': -0.20207253886010362, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.288916506694851, 'total_modified_reward_min': -6.79694987943087, 'total_modified_reward_max': -0.7415956525977342}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9938732496028145, 'cur_kl_coeff': 0.021093749999999998, 'cur_lr': 0.0003, 'total_loss': -0.0033799889854465924, 'policy_loss': -0.0006201209236557284, 'vf_loss': 0.028442429886587586, 'vf_explained_var': 0.5460214338699977, 'kl': 0.008459228390973446, 'entropy': 0.3635860611498356, 'entropy_coeff': 0.0471952}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 22950.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 297220, 'num_env_steps_trained': 297220, 'num_agent_steps_sampled': 297220, 'num_agent_steps_trained': 297220}, 'sampler_results': {'episode_reward_max': -0.7415956525977342, 'episode_reward_min': -6.79694987943087, 'episode_reward_mean': -2.288916506694851, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -20.92709527368531, 'default_policy/true_reward_min': -82.04961940777129, 'default_policy/true_reward_max': -0.6821320343559639, 'default_policy/proxy_reward_mean': -1.6790952736853106, 'default_policy/proxy_reward_min': -5.6860281374238495, 'default_policy/proxy_reward_max': -0.4517766952966371, 'default_policy/modified_reward_mean': -2.288916506694851, 'default_policy/modified_reward_min': -6.79694987943087, 'default_policy/modified_reward_max': -0.7415956525977342, 'default_policy/corr_btw_rewards_mean': 0.4976759104364507, 'default_policy/corr_btw_rewards_min': 0.10416519971131906, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -20.92709527368531, 'true_reward_min': -82.04961940777129, 'true_reward_max': -0.6821320343559639, 'proxy_reward_mean': -1.6790952736853106, 'proxy_reward_min': -5.6860281374238495, 'proxy_reward_max': -0.4517766952966371, 'modified_reward_mean': -2.288916506694851, 'modified_reward_min': -6.79694987943087, 'modified_reward_max': -0.7415956525977342, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003734715025906737, 'proxyInfectionSummaryAbsoluteReward_min': -0.002051813471502592, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03921737169353941, 'proxyLowerStageReward_min': -0.06922425582507029, 'proxyLowerStageReward_max': -0.01822677177702782, 'proxySmoothStageChangesReward_mean': -0.10435233160621761, 'proxySmoothStageChangesReward_min': -0.20207253886010362, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003734715025906737, 'trueInfectionSummaryAbsoluteReward_min': -0.002051813471502592, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.009973056994818652, 'truePoliticalReward_min': -0.04186528497409327, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03921737169353941, 'trueLowerStageReward_min': -0.06922425582507029, 'trueLowerStageReward_max': -0.01822677177702782, 'trueSmoothStageChangesReward_mean': -0.10435233160621761, 'trueSmoothStageChangesReward_min': -0.20207253886010362, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.288916506694851, 'total_modified_reward_min': -6.79694987943087, 'total_modified_reward_max': -0.7415956525977342}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5375967669678176, 'mean_inference_ms': 1.676810490057498, 'mean_action_processing_ms': 0.10642380112485209, 'mean_env_wait_ms': 743.5060929504851, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.7415956525977342, 'episode_reward_min': -6.79694987943087, 'episode_reward_mean': -2.288916506694851, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5375967669678176, 'mean_inference_ms': 1.676810490057498, 'mean_action_processing_ms': 0.10642380112485209, 'mean_env_wait_ms': 743.5060929504851, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 297220, 'num_agent_steps_trained': 297220, 'num_env_steps_sampled': 297220, 'num_env_steps_trained': 297220, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.470024555243663, 'num_env_steps_trained_throughput_per_sec': 13.470024555243663, 'timesteps_total': 297220, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 297220, 'timers': {'training_iteration_time_ms': 297490.717, 'sample_time_ms': 296471.352, 'load_time_ms': 5.135, 'load_throughput': 751670.873, 'learn_time_ms': 997.118, 'learn_throughput': 3871.159, 'synch_weights_time_ms': 16.261}, 'counters': {'num_env_steps_sampled': 297220, 'num_env_steps_trained': 297220, 'num_agent_steps_sampled': 297220, 'num_agent_steps_trained': 297220}, 'done': False, 'episodes_total': 1540, 'training_iteration': 77, 'trial_id': 'default', 'date': '2025-11-05_01-36-19', 'timestamp': 1762335379, 'time_this_iter_s': 286.5875389575958, 'time_total_s': 24200.469054222107, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e26300d0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e2631510>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699613b20>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6a9255cc0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 24200.469054222107, 'iterations_since_restore': 77, 'perf': {'cpu_util_percent': 20.33308823529412, 'ram_util_percent': 6.0}}
Iteration 78/100
{'custom_metrics': {'default_policy/true_reward_mean': -18.92886697282641, 'default_policy/true_reward_min': -82.04961940777129, 'default_policy/true_reward_max': -0.6821320343559639, 'default_policy/proxy_reward_mean': -1.7448669728264117, 'default_policy/proxy_reward_min': -5.6860281374238495, 'default_policy/proxy_reward_max': -0.4517766952966371, 'default_policy/modified_reward_mean': -2.3557323029991064, 'default_policy/modified_reward_min': -6.79694987943087, 'default_policy/modified_reward_max': -0.7415956525977342, 'default_policy/corr_btw_rewards_mean': 0.5252435835301124, 'default_policy/corr_btw_rewards_min': 0.10416519971131906, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -18.92886697282641, 'true_reward_min': -82.04961940777129, 'true_reward_max': -0.6821320343559639, 'proxy_reward_mean': -1.7448669728264117, 'proxy_reward_min': -5.6860281374238495, 'proxy_reward_max': -0.4517766952966371, 'modified_reward_mean': -2.3557323029991064, 'modified_reward_min': -6.79694987943087, 'modified_reward_max': -0.7415956525977342, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00040424870466321266, 'proxyInfectionSummaryAbsoluteReward_min': -0.002051813471502592, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0398169415972234, 'proxyLowerStageReward_min': -0.06922425582507029, 'proxyLowerStageReward_max': -0.01822677177702782, 'proxySmoothStageChangesReward_mean': -0.10165803108808291, 'proxySmoothStageChangesReward_min': -0.20207253886010362, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.00040424870466321266, 'trueInfectionSummaryAbsoluteReward_min': -0.002051813471502592, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.00890362694300518, 'truePoliticalReward_min': -0.04186528497409327, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.0398169415972234, 'trueLowerStageReward_min': -0.06922425582507029, 'trueLowerStageReward_max': -0.01822677177702782, 'trueSmoothStageChangesReward_mean': -0.10165803108808291, 'trueSmoothStageChangesReward_min': -0.20207253886010362, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.3557323029991064, 'total_modified_reward_min': -6.79694987943087, 'total_modified_reward_max': -0.7415956525977342}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.2581825666377942, 'cur_kl_coeff': 0.021093749999999998, 'cur_lr': 0.0003, 'total_loss': 0.0029894401195148627, 'policy_loss': -0.0001748610008507967, 'vf_loss': 0.042484634059558934, 'vf_explained_var': 0.5131038981676102, 'kl': 0.011284397776234708, 'entropy': 0.3938901308675607, 'entropy_coeff': 0.046500400000000004}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 23250.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 301080, 'num_env_steps_trained': 301080, 'num_agent_steps_sampled': 301080, 'num_agent_steps_trained': 301080}, 'sampler_results': {'episode_reward_max': -0.7415956525977342, 'episode_reward_min': -6.79694987943087, 'episode_reward_mean': -2.3557323029991064, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -18.92886697282641, 'default_policy/true_reward_min': -82.04961940777129, 'default_policy/true_reward_max': -0.6821320343559639, 'default_policy/proxy_reward_mean': -1.7448669728264117, 'default_policy/proxy_reward_min': -5.6860281374238495, 'default_policy/proxy_reward_max': -0.4517766952966371, 'default_policy/modified_reward_mean': -2.3557323029991064, 'default_policy/modified_reward_min': -6.79694987943087, 'default_policy/modified_reward_max': -0.7415956525977342, 'default_policy/corr_btw_rewards_mean': 0.5252435835301124, 'default_policy/corr_btw_rewards_min': 0.10416519971131906, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -18.92886697282641, 'true_reward_min': -82.04961940777129, 'true_reward_max': -0.6821320343559639, 'proxy_reward_mean': -1.7448669728264117, 'proxy_reward_min': -5.6860281374238495, 'proxy_reward_max': -0.4517766952966371, 'modified_reward_mean': -2.3557323029991064, 'modified_reward_min': -6.79694987943087, 'modified_reward_max': -0.7415956525977342, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00040424870466321266, 'proxyInfectionSummaryAbsoluteReward_min': -0.002051813471502592, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0398169415972234, 'proxyLowerStageReward_min': -0.06922425582507029, 'proxyLowerStageReward_max': -0.01822677177702782, 'proxySmoothStageChangesReward_mean': -0.10165803108808291, 'proxySmoothStageChangesReward_min': -0.20207253886010362, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.00040424870466321266, 'trueInfectionSummaryAbsoluteReward_min': -0.002051813471502592, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.00890362694300518, 'truePoliticalReward_min': -0.04186528497409327, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.0398169415972234, 'trueLowerStageReward_min': -0.06922425582507029, 'trueLowerStageReward_max': -0.01822677177702782, 'trueSmoothStageChangesReward_mean': -0.10165803108808291, 'trueSmoothStageChangesReward_min': -0.20207253886010362, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.3557323029991064, 'total_modified_reward_min': -6.79694987943087, 'total_modified_reward_max': -0.7415956525977342}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5378404420128264, 'mean_inference_ms': 1.6766297931910148, 'mean_action_processing_ms': 0.10641825074299907, 'mean_env_wait_ms': 743.253220037212, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.7415956525977342, 'episode_reward_min': -6.79694987943087, 'episode_reward_mean': -2.3557323029991064, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5378404420128264, 'mean_inference_ms': 1.6766297931910148, 'mean_action_processing_ms': 0.10641825074299907, 'mean_env_wait_ms': 743.253220037212, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 301080, 'num_agent_steps_trained': 301080, 'num_env_steps_sampled': 301080, 'num_env_steps_trained': 301080, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.353594411613631, 'num_env_steps_trained_throughput_per_sec': 13.353594411613631, 'timesteps_total': 301080, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 301080, 'timers': {'training_iteration_time_ms': 294814.93, 'sample_time_ms': 293794.713, 'load_time_ms': 5.004, 'load_throughput': 771445.277, 'learn_time_ms': 998.835, 'learn_throughput': 3864.503, 'synch_weights_time_ms': 15.546}, 'counters': {'num_env_steps_sampled': 301080, 'num_env_steps_trained': 301080, 'num_agent_steps_sampled': 301080, 'num_agent_steps_trained': 301080}, 'done': False, 'episodes_total': 1560, 'training_iteration': 78, 'trial_id': 'default', 'date': '2025-11-05_01-41-08', 'timestamp': 1762335668, 'time_this_iter_s': 289.07912039756775, 'time_total_s': 24489.548174619675, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a699535cc0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699534b50>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699534910>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699535870>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 24489.548174619675, 'iterations_since_restore': 78, 'perf': {'cpu_util_percent': 20.124213075060535, 'ram_util_percent': 6.0}}
Iteration 79/100
{'custom_metrics': {'default_policy/true_reward_mean': -17.185214555828438, 'default_policy/true_reward_min': -71.16355339059331, 'default_policy/true_reward_max': -0.49642135623730976, 'default_policy/proxy_reward_mean': -1.685214555828442, 'default_policy/proxy_reward_min': -5.468540764008557, 'default_policy/proxy_reward_max': -0.4517766952966371, 'default_policy/modified_reward_mean': -2.273200669045656, 'default_policy/modified_reward_min': -6.449878213448496, 'default_policy/modified_reward_max': -0.7415956525977342, 'default_policy/corr_btw_rewards_mean': 0.5101056037971197, 'default_policy/corr_btw_rewards_min': 0.10416519971131906, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -17.185214555828438, 'true_reward_min': -71.16355339059331, 'true_reward_max': -0.49642135623730976, 'proxy_reward_mean': -1.685214555828442, 'proxy_reward_min': -5.468540764008557, 'proxy_reward_max': -0.4517766952966371, 'modified_reward_mean': -2.273200669045656, 'modified_reward_min': -6.449878213448496, 'modified_reward_max': -0.7415956525977342, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00038943005181347177, 'proxyInfectionSummaryAbsoluteReward_min': -0.002041450777202074, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03889712724499699, 'proxyLowerStageReward_min': -0.061582423005625136, 'proxyLowerStageReward_max': -0.01822677177702782, 'proxySmoothStageChangesReward_mean': -0.09476683937823836, 'proxySmoothStageChangesReward_min': -0.17616580310880828, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.00038943005181347177, 'trueInfectionSummaryAbsoluteReward_min': -0.002041450777202074, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.008031088082901554, 'truePoliticalReward_min': -0.03626943005181347, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03889712724499699, 'trueLowerStageReward_min': -0.061582423005625136, 'trueLowerStageReward_max': -0.01822677177702782, 'trueSmoothStageChangesReward_mean': -0.09476683937823836, 'trueSmoothStageChangesReward_min': -0.17616580310880828, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.273200669045656, 'total_modified_reward_min': -6.449878213448496, 'total_modified_reward_max': -0.7415956525977342}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0235906782249609, 'cur_kl_coeff': 0.021093749999999998, 'cur_lr': 0.0003, 'total_loss': -0.005010639877679447, 'policy_loss': -0.006187212976316611, 'vf_loss': 0.03368641786316099, 'vf_explained_var': 0.5591939620176951, 'kl': 0.005602166307015611, 'entropy': 0.34460434183478356, 'entropy_coeff': 0.045805599999999995}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 23550.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 304940, 'num_env_steps_trained': 304940, 'num_agent_steps_sampled': 304940, 'num_agent_steps_trained': 304940}, 'sampler_results': {'episode_reward_max': -0.7415956525977342, 'episode_reward_min': -6.449878213448496, 'episode_reward_mean': -2.273200669045656, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -17.185214555828438, 'default_policy/true_reward_min': -71.16355339059331, 'default_policy/true_reward_max': -0.49642135623730976, 'default_policy/proxy_reward_mean': -1.685214555828442, 'default_policy/proxy_reward_min': -5.468540764008557, 'default_policy/proxy_reward_max': -0.4517766952966371, 'default_policy/modified_reward_mean': -2.273200669045656, 'default_policy/modified_reward_min': -6.449878213448496, 'default_policy/modified_reward_max': -0.7415956525977342, 'default_policy/corr_btw_rewards_mean': 0.5101056037971197, 'default_policy/corr_btw_rewards_min': 0.10416519971131906, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -17.185214555828438, 'true_reward_min': -71.16355339059331, 'true_reward_max': -0.49642135623730976, 'proxy_reward_mean': -1.685214555828442, 'proxy_reward_min': -5.468540764008557, 'proxy_reward_max': -0.4517766952966371, 'modified_reward_mean': -2.273200669045656, 'modified_reward_min': -6.449878213448496, 'modified_reward_max': -0.7415956525977342, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00038943005181347177, 'proxyInfectionSummaryAbsoluteReward_min': -0.002041450777202074, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03889712724499699, 'proxyLowerStageReward_min': -0.061582423005625136, 'proxyLowerStageReward_max': -0.01822677177702782, 'proxySmoothStageChangesReward_mean': -0.09476683937823836, 'proxySmoothStageChangesReward_min': -0.17616580310880828, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.00038943005181347177, 'trueInfectionSummaryAbsoluteReward_min': -0.002041450777202074, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.008031088082901554, 'truePoliticalReward_min': -0.03626943005181347, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03889712724499699, 'trueLowerStageReward_min': -0.061582423005625136, 'trueLowerStageReward_max': -0.01822677177702782, 'trueSmoothStageChangesReward_mean': -0.09476683937823836, 'trueSmoothStageChangesReward_min': -0.17616580310880828, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.273200669045656, 'total_modified_reward_min': -6.449878213448496, 'total_modified_reward_max': -0.7415956525977342}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5378623566861873, 'mean_inference_ms': 1.6764373045710124, 'mean_action_processing_ms': 0.10648705572292044, 'mean_env_wait_ms': 743.0199252280539, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.7415956525977342, 'episode_reward_min': -6.449878213448496, 'episode_reward_mean': -2.273200669045656, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5378623566861873, 'mean_inference_ms': 1.6764373045710124, 'mean_action_processing_ms': 0.10648705572292044, 'mean_env_wait_ms': 743.0199252280539, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 304940, 'num_agent_steps_trained': 304940, 'num_env_steps_sampled': 304940, 'num_env_steps_trained': 304940, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.272078791998656, 'num_env_steps_trained_throughput_per_sec': 13.272078791998656, 'timesteps_total': 304940, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 304940, 'timers': {'training_iteration_time_ms': 293254.515, 'sample_time_ms': 292214.551, 'load_time_ms': 4.847, 'load_throughput': 796407.729, 'learn_time_ms': 1018.74, 'learn_throughput': 3788.993, 'synch_weights_time_ms': 15.528}, 'counters': {'num_env_steps_sampled': 304940, 'num_env_steps_trained': 304940, 'num_agent_steps_sampled': 304940, 'num_agent_steps_trained': 304940}, 'done': False, 'episodes_total': 1580, 'training_iteration': 79, 'trial_id': 'default', 'date': '2025-11-05_01-45-59', 'timestamp': 1762335959, 'time_this_iter_s': 290.8525335788727, 'time_total_s': 24780.400708198547, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6996123e0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699611690>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699611ff0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6996138b0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 24780.400708198547, 'iterations_since_restore': 79, 'perf': {'cpu_util_percent': 20.30531400966184, 'ram_util_percent': 6.0}}
Iteration 80/100
{'custom_metrics': {'default_policy/true_reward_mean': -15.709533080376486, 'default_policy/true_reward_min': -71.16355339059331, 'default_policy/true_reward_max': -0.49642135623730976, 'default_policy/proxy_reward_mean': -1.6335330803764907, 'default_policy/proxy_reward_min': -4.1017640687119306, 'default_policy/proxy_reward_max': -0.4517766952966371, 'default_policy/modified_reward_mean': -2.2056302204083575, 'default_policy/modified_reward_min': -4.820732650580646, 'default_policy/modified_reward_max': -0.7415956525977342, 'default_policy/corr_btw_rewards_mean': 0.518739549426257, 'default_policy/corr_btw_rewards_min': 0.10416519971131906, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -15.709533080376486, 'true_reward_min': -71.16355339059331, 'true_reward_max': -0.49642135623730976, 'proxy_reward_mean': -1.6335330803764907, 'proxy_reward_min': -4.1017640687119306, 'proxy_reward_max': -0.4517766952966371, 'modified_reward_mean': -2.2056302204083575, 'modified_reward_min': -4.820732650580646, 'modified_reward_max': -0.7415956525977342, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003738860103626945, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015233160621761668, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.038245237325206786, 'proxyLowerStageReward_min': -0.06535731103978717, 'proxyLowerStageReward_max': -0.01822677177702782, 'proxySmoothStageChangesReward_mean': -0.0900518134715026, 'proxySmoothStageChangesReward_min': -0.17616580310880828, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003738860103626945, 'trueInfectionSummaryAbsoluteReward_min': -0.0015233160621761668, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.007293264248704662, 'truePoliticalReward_min': -0.03626943005181347, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.038245237325206786, 'trueLowerStageReward_min': -0.06535731103978717, 'trueLowerStageReward_max': -0.01822677177702782, 'trueSmoothStageChangesReward_mean': -0.0900518134715026, 'trueSmoothStageChangesReward_min': -0.17616580310880828, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.2056302204083575, 'total_modified_reward_min': -4.820732650580646, 'total_modified_reward_max': -0.7415956525977342}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.2592148437102635, 'cur_kl_coeff': 0.021093749999999998, 'cur_lr': 0.0003, 'total_loss': 0.0014101973967626691, 'policy_loss': -0.003623073805744449, 'vf_loss': 0.04121732801548205, 'vf_explained_var': 0.3789360511302948, 'kl': 0.01301872042918576, 'entropy': 0.35135719339052834, 'entropy_coeff': 0.0451108}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 23850.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 308800, 'num_env_steps_trained': 308800, 'num_agent_steps_sampled': 308800, 'num_agent_steps_trained': 308800}, 'sampler_results': {'episode_reward_max': -0.7415956525977342, 'episode_reward_min': -4.820732650580646, 'episode_reward_mean': -2.2056302204083575, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -15.709533080376486, 'default_policy/true_reward_min': -71.16355339059331, 'default_policy/true_reward_max': -0.49642135623730976, 'default_policy/proxy_reward_mean': -1.6335330803764907, 'default_policy/proxy_reward_min': -4.1017640687119306, 'default_policy/proxy_reward_max': -0.4517766952966371, 'default_policy/modified_reward_mean': -2.2056302204083575, 'default_policy/modified_reward_min': -4.820732650580646, 'default_policy/modified_reward_max': -0.7415956525977342, 'default_policy/corr_btw_rewards_mean': 0.518739549426257, 'default_policy/corr_btw_rewards_min': 0.10416519971131906, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -15.709533080376486, 'true_reward_min': -71.16355339059331, 'true_reward_max': -0.49642135623730976, 'proxy_reward_mean': -1.6335330803764907, 'proxy_reward_min': -4.1017640687119306, 'proxy_reward_max': -0.4517766952966371, 'modified_reward_mean': -2.2056302204083575, 'modified_reward_min': -4.820732650580646, 'modified_reward_max': -0.7415956525977342, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003738860103626945, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015233160621761668, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.038245237325206786, 'proxyLowerStageReward_min': -0.06535731103978717, 'proxyLowerStageReward_max': -0.01822677177702782, 'proxySmoothStageChangesReward_mean': -0.0900518134715026, 'proxySmoothStageChangesReward_min': -0.17616580310880828, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003738860103626945, 'trueInfectionSummaryAbsoluteReward_min': -0.0015233160621761668, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.007293264248704662, 'truePoliticalReward_min': -0.03626943005181347, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.038245237325206786, 'trueLowerStageReward_min': -0.06535731103978717, 'trueLowerStageReward_max': -0.01822677177702782, 'trueSmoothStageChangesReward_mean': -0.0900518134715026, 'trueSmoothStageChangesReward_min': -0.17616580310880828, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.2056302204083575, 'total_modified_reward_min': -4.820732650580646, 'total_modified_reward_max': -0.7415956525977342}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5375621565816298, 'mean_inference_ms': 1.6762858276720658, 'mean_action_processing_ms': 0.1065581994012308, 'mean_env_wait_ms': 742.7960446538085, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.7415956525977342, 'episode_reward_min': -4.820732650580646, 'episode_reward_mean': -2.2056302204083575, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5375621565816298, 'mean_inference_ms': 1.6762858276720658, 'mean_action_processing_ms': 0.1065581994012308, 'mean_env_wait_ms': 742.7960446538085, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 308800, 'num_agent_steps_trained': 308800, 'num_env_steps_sampled': 308800, 'num_env_steps_trained': 308800, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.39469884061722, 'num_env_steps_trained_throughput_per_sec': 13.39469884061722, 'timesteps_total': 308800, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 308800, 'timers': {'training_iteration_time_ms': 291372.751, 'sample_time_ms': 290354.239, 'load_time_ms': 4.943, 'load_throughput': 780915.269, 'learn_time_ms': 997.251, 'learn_throughput': 3870.641, 'synch_weights_time_ms': 15.5}, 'counters': {'num_env_steps_sampled': 308800, 'num_env_steps_trained': 308800, 'num_agent_steps_sampled': 308800, 'num_agent_steps_trained': 308800}, 'done': False, 'episodes_total': 1600, 'training_iteration': 80, 'trial_id': 'default', 'date': '2025-11-05_01-50-48', 'timestamp': 1762336248, 'time_this_iter_s': 288.2000479698181, 'time_total_s': 25068.600756168365, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6a9206260>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e226bac0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0fff640>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffc5b0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 25068.600756168365, 'iterations_since_restore': 80, 'perf': {'cpu_util_percent': 20.37542579075426, 'ram_util_percent': 6.0}}
Saved checkpoint to TrainingResult(checkpoint=Checkpoint(filesystem=local, path=logs/data/pandemic/20251104_185246/checkpoint_80), metrics={'custom_metrics': {'default_policy/true_reward_mean': -15.709533080376486, 'default_policy/true_reward_min': -71.16355339059331, 'default_policy/true_reward_max': -0.49642135623730976, 'default_policy/proxy_reward_mean': -1.6335330803764907, 'default_policy/proxy_reward_min': -4.1017640687119306, 'default_policy/proxy_reward_max': -0.4517766952966371, 'default_policy/modified_reward_mean': -2.2056302204083575, 'default_policy/modified_reward_min': -4.820732650580646, 'default_policy/modified_reward_max': -0.7415956525977342, 'default_policy/corr_btw_rewards_mean': 0.518739549426257, 'default_policy/corr_btw_rewards_min': 0.10416519971131906, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -15.709533080376486, 'true_reward_min': -71.16355339059331, 'true_reward_max': -0.49642135623730976, 'proxy_reward_mean': -1.6335330803764907, 'proxy_reward_min': -4.1017640687119306, 'proxy_reward_max': -0.4517766952966371, 'modified_reward_mean': -2.2056302204083575, 'modified_reward_min': -4.820732650580646, 'modified_reward_max': -0.7415956525977342, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003738860103626945, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015233160621761668, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.038245237325206786, 'proxyLowerStageReward_min': -0.06535731103978717, 'proxyLowerStageReward_max': -0.01822677177702782, 'proxySmoothStageChangesReward_mean': -0.0900518134715026, 'proxySmoothStageChangesReward_min': -0.17616580310880828, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003738860103626945, 'trueInfectionSummaryAbsoluteReward_min': -0.0015233160621761668, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.007293264248704662, 'truePoliticalReward_min': -0.03626943005181347, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.038245237325206786, 'trueLowerStageReward_min': -0.06535731103978717, 'trueLowerStageReward_max': -0.01822677177702782, 'trueSmoothStageChangesReward_mean': -0.0900518134715026, 'trueSmoothStageChangesReward_min': -0.17616580310880828, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.2056302204083575, 'total_modified_reward_min': -4.820732650580646, 'total_modified_reward_max': -0.7415956525977342}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.2592148437102635, 'cur_kl_coeff': 0.021093749999999998, 'cur_lr': 0.0003, 'total_loss': 0.0014101973967626691, 'policy_loss': -0.003623073805744449, 'vf_loss': 0.04121732801548205, 'vf_explained_var': 0.3789360511302948, 'kl': 0.01301872042918576, 'entropy': 0.35135719339052834, 'entropy_coeff': 0.0451108}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 23850.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 308800, 'num_env_steps_trained': 308800, 'num_agent_steps_sampled': 308800, 'num_agent_steps_trained': 308800}, 'sampler_results': {'episode_reward_max': -0.7415956525977342, 'episode_reward_min': -4.820732650580646, 'episode_reward_mean': -2.2056302204083575, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -15.709533080376486, 'default_policy/true_reward_min': -71.16355339059331, 'default_policy/true_reward_max': -0.49642135623730976, 'default_policy/proxy_reward_mean': -1.6335330803764907, 'default_policy/proxy_reward_min': -4.1017640687119306, 'default_policy/proxy_reward_max': -0.4517766952966371, 'default_policy/modified_reward_mean': -2.2056302204083575, 'default_policy/modified_reward_min': -4.820732650580646, 'default_policy/modified_reward_max': -0.7415956525977342, 'default_policy/corr_btw_rewards_mean': 0.518739549426257, 'default_policy/corr_btw_rewards_min': 0.10416519971131906, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -15.709533080376486, 'true_reward_min': -71.16355339059331, 'true_reward_max': -0.49642135623730976, 'proxy_reward_mean': -1.6335330803764907, 'proxy_reward_min': -4.1017640687119306, 'proxy_reward_max': -0.4517766952966371, 'modified_reward_mean': -2.2056302204083575, 'modified_reward_min': -4.820732650580646, 'modified_reward_max': -0.7415956525977342, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003738860103626945, 'proxyInfectionSummaryAbsoluteReward_min': -0.0015233160621761668, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.038245237325206786, 'proxyLowerStageReward_min': -0.06535731103978717, 'proxyLowerStageReward_max': -0.01822677177702782, 'proxySmoothStageChangesReward_mean': -0.0900518134715026, 'proxySmoothStageChangesReward_min': -0.17616580310880828, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003738860103626945, 'trueInfectionSummaryAbsoluteReward_min': -0.0015233160621761668, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.007293264248704662, 'truePoliticalReward_min': -0.03626943005181347, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.038245237325206786, 'trueLowerStageReward_min': -0.06535731103978717, 'trueLowerStageReward_max': -0.01822677177702782, 'trueSmoothStageChangesReward_mean': -0.0900518134715026, 'trueSmoothStageChangesReward_min': -0.17616580310880828, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.2056302204083575, 'total_modified_reward_min': -4.820732650580646, 'total_modified_reward_max': -0.7415956525977342}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5375621565816298, 'mean_inference_ms': 1.6762858276720658, 'mean_action_processing_ms': 0.1065581994012308, 'mean_env_wait_ms': 742.7960446538085, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.7415956525977342, 'episode_reward_min': -4.820732650580646, 'episode_reward_mean': -2.2056302204083575, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5375621565816298, 'mean_inference_ms': 1.6762858276720658, 'mean_action_processing_ms': 0.1065581994012308, 'mean_env_wait_ms': 742.7960446538085, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 308800, 'num_agent_steps_trained': 308800, 'num_env_steps_sampled': 308800, 'num_env_steps_trained': 308800, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.39469884061722, 'num_env_steps_trained_throughput_per_sec': 13.39469884061722, 'timesteps_total': 308800, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 308800, 'timers': {'training_iteration_time_ms': 291372.751, 'sample_time_ms': 290354.239, 'load_time_ms': 4.943, 'load_throughput': 780915.269, 'learn_time_ms': 997.251, 'learn_throughput': 3870.641, 'synch_weights_time_ms': 15.5}, 'counters': {'num_env_steps_sampled': 308800, 'num_env_steps_trained': 308800, 'num_agent_steps_sampled': 308800, 'num_agent_steps_trained': 308800}, 'done': False, 'episodes_total': 1600, 'training_iteration': 80, 'trial_id': 'default', 'date': '2025-11-05_01-50-48', 'timestamp': 1762336248, 'time_this_iter_s': 288.2000479698181, 'time_total_s': 25068.600756168365, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6a9206260>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e226bac0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0fff640>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffc5b0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 25068.600756168365, 'iterations_since_restore': 80, 'perf': {'cpu_util_percent': 20.37542579075426, 'ram_util_percent': 6.0}})
Iteration 81/100
{'custom_metrics': {'default_policy/true_reward_mean': -18.776132954110643, 'default_policy/true_reward_min': -71.16355339059331, 'default_policy/true_reward_max': -0.49642135623730976, 'default_policy/proxy_reward_mean': -1.656132954110644, 'default_policy/proxy_reward_min': -4.808553390593273, 'default_policy/proxy_reward_max': -0.4517766952966371, 'default_policy/modified_reward_mean': -2.2277953835687163, 'default_policy/modified_reward_min': -5.508368231394475, 'default_policy/modified_reward_max': -0.7415956525977342, 'default_policy/corr_btw_rewards_mean': 0.5199387863639723, 'default_policy/corr_btw_rewards_min': 0.09400005572585993, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -18.776132954110643, 'true_reward_min': -71.16355339059331, 'true_reward_max': -0.49642135623730976, 'proxy_reward_mean': -1.656132954110644, 'proxy_reward_min': -4.808553390593273, 'proxy_reward_max': -0.4517766952966371, 'modified_reward_mean': -2.2277953835687163, 'modified_reward_min': -5.508368231394475, 'modified_reward_max': -0.7415956525977342, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003866321243523318, 'proxyInfectionSummaryAbsoluteReward_min': -0.001968911917098447, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0380690649798261, 'proxyLowerStageReward_min': -0.07431354622420827, 'proxyLowerStageReward_max': -0.01822677177702782, 'proxySmoothStageChangesReward_mean': -0.09077720207253887, 'proxySmoothStageChangesReward_min': -0.17616580310880828, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003866321243523318, 'trueInfectionSummaryAbsoluteReward_min': -0.001968911917098447, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.008870466321243524, 'truePoliticalReward_min': -0.03626943005181347, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.0380690649798261, 'trueLowerStageReward_min': -0.07431354622420827, 'trueLowerStageReward_max': -0.01822677177702782, 'trueSmoothStageChangesReward_mean': -0.09077720207253887, 'trueSmoothStageChangesReward_min': -0.17616580310880828, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.2277953835687163, 'total_modified_reward_min': -5.508368231394475, 'total_modified_reward_max': -0.7415956525977342}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0730586925645669, 'cur_kl_coeff': 0.021093749999999998, 'cur_lr': 0.0003, 'total_loss': -0.001644909866154194, 'policy_loss': -0.004585979447389642, 'vf_loss': 0.042058468296503025, 'vf_explained_var': 0.4485961761077245, 'kl': 0.008098547065111256, 'entropy': 0.41109050462643304, 'entropy_coeff': 0.044416000000000004}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 24150.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 312660, 'num_env_steps_trained': 312660, 'num_agent_steps_sampled': 312660, 'num_agent_steps_trained': 312660}, 'sampler_results': {'episode_reward_max': -0.7415956525977342, 'episode_reward_min': -5.508368231394475, 'episode_reward_mean': -2.2277953835687163, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -18.776132954110643, 'default_policy/true_reward_min': -71.16355339059331, 'default_policy/true_reward_max': -0.49642135623730976, 'default_policy/proxy_reward_mean': -1.656132954110644, 'default_policy/proxy_reward_min': -4.808553390593273, 'default_policy/proxy_reward_max': -0.4517766952966371, 'default_policy/modified_reward_mean': -2.2277953835687163, 'default_policy/modified_reward_min': -5.508368231394475, 'default_policy/modified_reward_max': -0.7415956525977342, 'default_policy/corr_btw_rewards_mean': 0.5199387863639723, 'default_policy/corr_btw_rewards_min': 0.09400005572585993, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -18.776132954110643, 'true_reward_min': -71.16355339059331, 'true_reward_max': -0.49642135623730976, 'proxy_reward_mean': -1.656132954110644, 'proxy_reward_min': -4.808553390593273, 'proxy_reward_max': -0.4517766952966371, 'modified_reward_mean': -2.2277953835687163, 'modified_reward_min': -5.508368231394475, 'modified_reward_max': -0.7415956525977342, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003866321243523318, 'proxyInfectionSummaryAbsoluteReward_min': -0.001968911917098447, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0380690649798261, 'proxyLowerStageReward_min': -0.07431354622420827, 'proxyLowerStageReward_max': -0.01822677177702782, 'proxySmoothStageChangesReward_mean': -0.09077720207253887, 'proxySmoothStageChangesReward_min': -0.17616580310880828, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003866321243523318, 'trueInfectionSummaryAbsoluteReward_min': -0.001968911917098447, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.008870466321243524, 'truePoliticalReward_min': -0.03626943005181347, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.0380690649798261, 'trueLowerStageReward_min': -0.07431354622420827, 'trueLowerStageReward_max': -0.01822677177702782, 'trueSmoothStageChangesReward_mean': -0.09077720207253887, 'trueSmoothStageChangesReward_min': -0.17616580310880828, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.2277953835687163, 'total_modified_reward_min': -5.508368231394475, 'total_modified_reward_max': -0.7415956525977342}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5372467487322452, 'mean_inference_ms': 1.676154266199325, 'mean_action_processing_ms': 0.10662797740856785, 'mean_env_wait_ms': 742.58135220923, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.7415956525977342, 'episode_reward_min': -5.508368231394475, 'episode_reward_mean': -2.2277953835687163, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5372467487322452, 'mean_inference_ms': 1.676154266199325, 'mean_action_processing_ms': 0.10662797740856785, 'mean_env_wait_ms': 742.58135220923, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 312660, 'num_agent_steps_trained': 312660, 'num_env_steps_sampled': 312660, 'num_env_steps_trained': 312660, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.287562197988796, 'num_env_steps_trained_throughput_per_sec': 13.287562197988796, 'timesteps_total': 312660, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 312660, 'timers': {'training_iteration_time_ms': 289506.656, 'sample_time_ms': 288495.151, 'load_time_ms': 4.725, 'load_throughput': 816947.145, 'learn_time_ms': 990.053, 'learn_throughput': 3898.783, 'synch_weights_time_ms': 15.919}, 'counters': {'num_env_steps_sampled': 312660, 'num_env_steps_trained': 312660, 'num_agent_steps_sampled': 312660, 'num_agent_steps_trained': 312660}, 'done': False, 'episodes_total': 1620, 'training_iteration': 81, 'trial_id': 'default', 'date': '2025-11-05_01-55-39', 'timestamp': 1762336539, 'time_this_iter_s': 290.51520228385925, 'time_total_s': 25359.115958452225, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e0fff6d0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e0ffd300>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffee30>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e0ffd2d0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 25359.115958452225, 'iterations_since_restore': 81, 'perf': {'cpu_util_percent': 20.129710144927543, 'ram_util_percent': 6.0}}
Iteration 82/100
{'custom_metrics': {'default_policy/true_reward_mean': -19.885707827844797, 'default_policy/true_reward_min': -62.69711940777128, 'default_policy/true_reward_max': -0.49642135623730976, 'default_policy/proxy_reward_mean': -1.7017078278447968, 'default_policy/proxy_reward_min': -4.808553390593273, 'default_policy/proxy_reward_max': -0.49642135623730976, 'default_policy/modified_reward_mean': -2.286827914944239, 'default_policy/modified_reward_min': -5.508368231394475, 'default_policy/modified_reward_max': -0.8011226189864527, 'default_policy/corr_btw_rewards_mean': 0.49567480859579083, 'default_policy/corr_btw_rewards_min': 0.09400005572585993, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -19.885707827844797, 'true_reward_min': -62.69711940777128, 'true_reward_max': -0.49642135623730976, 'proxy_reward_mean': -1.7017078278447968, 'proxy_reward_min': -4.808553390593273, 'proxy_reward_max': -0.49642135623730976, 'modified_reward_mean': -2.286827914944239, 'modified_reward_min': -5.508368231394475, 'modified_reward_max': -0.8011226189864527, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00039803108808290173, 'proxyInfectionSummaryAbsoluteReward_min': -0.001968911917098447, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03920765947382366, 'proxyLowerStageReward_min': -0.07431354622420827, 'proxyLowerStageReward_max': -0.02016977695837497, 'proxySmoothStageChangesReward_mean': -0.09160621761658032, 'proxySmoothStageChangesReward_min': -0.17616580310880828, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00039803108808290173, 'trueInfectionSummaryAbsoluteReward_min': -0.001968911917098447, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.009421761658031089, 'truePoliticalReward_min': -0.03129533678756477, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03920765947382366, 'trueLowerStageReward_min': -0.07431354622420827, 'trueLowerStageReward_max': -0.02016977695837497, 'trueSmoothStageChangesReward_mean': -0.09160621761658032, 'trueSmoothStageChangesReward_min': -0.17616580310880828, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.286827914944239, 'total_modified_reward_min': -5.508368231394475, 'total_modified_reward_max': -0.8011226189864527}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9702892001966635, 'cur_kl_coeff': 0.021093749999999998, 'cur_lr': 0.0003, 'total_loss': -0.006868191863953446, 'policy_loss': -0.004628973348687093, 'vf_loss': 0.02870661773699491, 'vf_explained_var': 0.4291358828544617, 'kl': 0.004453649705129177, 'entropy': 0.38165643577774366, 'entropy_coeff': 0.04372120000000001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 24450.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 316520, 'num_env_steps_trained': 316520, 'num_agent_steps_sampled': 316520, 'num_agent_steps_trained': 316520}, 'sampler_results': {'episode_reward_max': -0.8011226189864527, 'episode_reward_min': -5.508368231394475, 'episode_reward_mean': -2.286827914944239, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -19.885707827844797, 'default_policy/true_reward_min': -62.69711940777128, 'default_policy/true_reward_max': -0.49642135623730976, 'default_policy/proxy_reward_mean': -1.7017078278447968, 'default_policy/proxy_reward_min': -4.808553390593273, 'default_policy/proxy_reward_max': -0.49642135623730976, 'default_policy/modified_reward_mean': -2.286827914944239, 'default_policy/modified_reward_min': -5.508368231394475, 'default_policy/modified_reward_max': -0.8011226189864527, 'default_policy/corr_btw_rewards_mean': 0.49567480859579083, 'default_policy/corr_btw_rewards_min': 0.09400005572585993, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -19.885707827844797, 'true_reward_min': -62.69711940777128, 'true_reward_max': -0.49642135623730976, 'proxy_reward_mean': -1.7017078278447968, 'proxy_reward_min': -4.808553390593273, 'proxy_reward_max': -0.49642135623730976, 'modified_reward_mean': -2.286827914944239, 'modified_reward_min': -5.508368231394475, 'modified_reward_max': -0.8011226189864527, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00039803108808290173, 'proxyInfectionSummaryAbsoluteReward_min': -0.001968911917098447, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03920765947382366, 'proxyLowerStageReward_min': -0.07431354622420827, 'proxyLowerStageReward_max': -0.02016977695837497, 'proxySmoothStageChangesReward_mean': -0.09160621761658032, 'proxySmoothStageChangesReward_min': -0.17616580310880828, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00039803108808290173, 'trueInfectionSummaryAbsoluteReward_min': -0.001968911917098447, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.009421761658031089, 'truePoliticalReward_min': -0.03129533678756477, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03920765947382366, 'trueLowerStageReward_min': -0.07431354622420827, 'trueLowerStageReward_max': -0.02016977695837497, 'trueSmoothStageChangesReward_mean': -0.09160621761658032, 'trueSmoothStageChangesReward_min': -0.17616580310880828, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.286827914944239, 'total_modified_reward_min': -5.508368231394475, 'total_modified_reward_max': -0.8011226189864527}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5369803364571031, 'mean_inference_ms': 1.6760353876799852, 'mean_action_processing_ms': 0.10669334774600603, 'mean_env_wait_ms': 742.364488018541, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.8011226189864527, 'episode_reward_min': -5.508368231394475, 'episode_reward_mean': -2.286827914944239, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5369803364571031, 'mean_inference_ms': 1.6760353876799852, 'mean_action_processing_ms': 0.10669334774600603, 'mean_env_wait_ms': 742.364488018541, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 316520, 'num_agent_steps_trained': 316520, 'num_env_steps_sampled': 316520, 'num_env_steps_trained': 316520, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.248549332719282, 'num_env_steps_trained_throughput_per_sec': 13.248549332719282, 'timesteps_total': 316520, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 316520, 'timers': {'training_iteration_time_ms': 289250.57, 'sample_time_ms': 288245.219, 'load_time_ms': 4.704, 'load_throughput': 820528.576, 'learn_time_ms': 983.786, 'learn_throughput': 3923.617, 'synch_weights_time_ms': 16.063}, 'counters': {'num_env_steps_sampled': 316520, 'num_env_steps_trained': 316520, 'num_agent_steps_sampled': 316520, 'num_agent_steps_trained': 316520}, 'done': False, 'episodes_total': 1640, 'training_iteration': 82, 'trial_id': 'default', 'date': '2025-11-05_02-00-30', 'timestamp': 1762336830, 'time_this_iter_s': 291.36884927749634, 'time_total_s': 25650.48480772972, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6882fcbb0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6882fef80>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e1779d20>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6882feaa0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 25650.48480772972, 'iterations_since_restore': 82, 'perf': {'cpu_util_percent': 20.040384615384617, 'ram_util_percent': 6.0}}
Iteration 83/100
{'custom_metrics': {'default_policy/true_reward_mean': -22.994151099861153, 'default_policy/true_reward_min': -74.77961940777132, 'default_policy/true_reward_max': -0.49642135623730976, 'default_policy/proxy_reward_mean': -1.586151099861151, 'default_policy/proxy_reward_min': -4.808553390593273, 'default_policy/proxy_reward_max': -0.49642135623730976, 'default_policy/modified_reward_mean': -2.1570520394871138, 'default_policy/modified_reward_min': -5.508368231394475, 'default_policy/modified_reward_max': -0.8011226189864527, 'default_policy/corr_btw_rewards_mean': 0.4909571833761761, 'default_policy/corr_btw_rewards_min': 0.09400005572585993, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -22.994151099861153, 'true_reward_min': -74.77961940777132, 'true_reward_max': -0.49642135623730976, 'proxy_reward_mean': -1.586151099861151, 'proxy_reward_min': -4.808553390593273, 'proxy_reward_max': -0.49642135623730976, 'modified_reward_mean': -2.1570520394871138, 'modified_reward_min': -5.508368231394475, 'modified_reward_max': -0.8011226189864527, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003511917098445598, 'proxyInfectionSummaryAbsoluteReward_min': -0.001968911917098447, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.037976740925448255, 'proxyLowerStageReward_min': -0.07431354622420827, 'proxyLowerStageReward_max': -0.01833789410556008, 'proxySmoothStageChangesReward_mean': -0.09088082901554405, 'proxySmoothStageChangesReward_min': -0.18652849740932642, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003511917098445598, 'trueInfectionSummaryAbsoluteReward_min': -0.001968911917098447, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.01109222797927461, 'truePoliticalReward_min': -0.038134715025906735, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.037976740925448255, 'trueLowerStageReward_min': -0.07431354622420827, 'trueLowerStageReward_max': -0.01833789410556008, 'trueSmoothStageChangesReward_mean': -0.09088082901554405, 'trueSmoothStageChangesReward_min': -0.18652849740932642, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.1570520394871138, 'total_modified_reward_min': -5.508368231394475, 'total_modified_reward_max': -0.8011226189864527}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.8909820980330309, 'cur_kl_coeff': 0.010546874999999999, 'cur_lr': 0.0003, 'total_loss': -0.010012169534650941, 'policy_loss': -0.007198973055152843, 'vf_loss': 0.023332063577933392, 'vf_explained_var': 0.5288743122418722, 'kl': 0.007068312635872931, 'entropy': 0.3382522967457771, 'entropy_coeff': 0.0430264}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 24750.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 320380, 'num_env_steps_trained': 320380, 'num_agent_steps_sampled': 320380, 'num_agent_steps_trained': 320380}, 'sampler_results': {'episode_reward_max': -0.8011226189864527, 'episode_reward_min': -5.508368231394475, 'episode_reward_mean': -2.1570520394871138, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -22.994151099861153, 'default_policy/true_reward_min': -74.77961940777132, 'default_policy/true_reward_max': -0.49642135623730976, 'default_policy/proxy_reward_mean': -1.586151099861151, 'default_policy/proxy_reward_min': -4.808553390593273, 'default_policy/proxy_reward_max': -0.49642135623730976, 'default_policy/modified_reward_mean': -2.1570520394871138, 'default_policy/modified_reward_min': -5.508368231394475, 'default_policy/modified_reward_max': -0.8011226189864527, 'default_policy/corr_btw_rewards_mean': 0.4909571833761761, 'default_policy/corr_btw_rewards_min': 0.09400005572585993, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -22.994151099861153, 'true_reward_min': -74.77961940777132, 'true_reward_max': -0.49642135623730976, 'proxy_reward_mean': -1.586151099861151, 'proxy_reward_min': -4.808553390593273, 'proxy_reward_max': -0.49642135623730976, 'modified_reward_mean': -2.1570520394871138, 'modified_reward_min': -5.508368231394475, 'modified_reward_max': -0.8011226189864527, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003511917098445598, 'proxyInfectionSummaryAbsoluteReward_min': -0.001968911917098447, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.037976740925448255, 'proxyLowerStageReward_min': -0.07431354622420827, 'proxyLowerStageReward_max': -0.01833789410556008, 'proxySmoothStageChangesReward_mean': -0.09088082901554405, 'proxySmoothStageChangesReward_min': -0.18652849740932642, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003511917098445598, 'trueInfectionSummaryAbsoluteReward_min': -0.001968911917098447, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.01109222797927461, 'truePoliticalReward_min': -0.038134715025906735, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.037976740925448255, 'trueLowerStageReward_min': -0.07431354622420827, 'trueLowerStageReward_max': -0.01833789410556008, 'trueSmoothStageChangesReward_mean': -0.09088082901554405, 'trueSmoothStageChangesReward_min': -0.18652849740932642, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -2.1570520394871138, 'total_modified_reward_min': -5.508368231394475, 'total_modified_reward_max': -0.8011226189864527}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5366822658940458, 'mean_inference_ms': 1.6759028603461286, 'mean_action_processing_ms': 0.10675296417214776, 'mean_env_wait_ms': 742.1509755477849, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.8011226189864527, 'episode_reward_min': -5.508368231394475, 'episode_reward_mean': -2.1570520394871138, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5366822658940458, 'mean_inference_ms': 1.6759028603461286, 'mean_action_processing_ms': 0.10675296417214776, 'mean_env_wait_ms': 742.1509755477849, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 320380, 'num_agent_steps_trained': 320380, 'num_env_steps_sampled': 320380, 'num_env_steps_trained': 320380, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.357144352557194, 'num_env_steps_trained_throughput_per_sec': 13.357144352557194, 'timesteps_total': 320380, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 320380, 'timers': {'training_iteration_time_ms': 289179.832, 'sample_time_ms': 288177.529, 'load_time_ms': 4.365, 'load_throughput': 884390.893, 'learn_time_ms': 981.555, 'learn_throughput': 3932.535, 'synch_weights_time_ms': 15.625}, 'counters': {'num_env_steps_sampled': 320380, 'num_env_steps_trained': 320380, 'num_agent_steps_sampled': 320380, 'num_agent_steps_trained': 320380}, 'done': False, 'episodes_total': 1660, 'training_iteration': 83, 'trial_id': 'default', 'date': '2025-11-05_02-05-19', 'timestamp': 1762337119, 'time_this_iter_s': 289.0082323551178, 'time_total_s': 25939.49304008484, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e17789d0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e177a1a0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e177bf70>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e177a0e0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 25939.49304008484, 'iterations_since_restore': 83, 'perf': {'cpu_util_percent': 20.283698296836985, 'ram_util_percent': 6.0}}
Iteration 84/100
{'custom_metrics': {'default_policy/true_reward_mean': -20.46096899307997, 'default_policy/true_reward_min': -74.77961940777132, 'default_policy/true_reward_max': -0.7439213562373095, 'default_policy/proxy_reward_mean': -1.7129689930799654, 'default_policy/proxy_reward_min': -5.059974746830588, 'default_policy/proxy_reward_max': -0.4535660171779823, 'default_policy/modified_reward_mean': -2.279318223161906, 'default_policy/modified_reward_min': -5.890353852398022, 'default_policy/modified_reward_max': -0.6719744507803582, 'default_policy/corr_btw_rewards_mean': 0.531619952241059, 'default_policy/corr_btw_rewards_min': 0.09400005572585993, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -20.46096899307997, 'true_reward_min': -74.77961940777132, 'true_reward_max': -0.7439213562373095, 'proxy_reward_mean': -1.7129689930799654, 'proxy_reward_min': -5.059974746830588, 'proxy_reward_max': -0.4535660171779823, 'modified_reward_mean': -2.279318223161906, 'modified_reward_min': -5.890353852398022, 'modified_reward_max': -0.6719744507803582, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004208290155440416, 'proxyInfectionSummaryAbsoluteReward_min': -0.001968911917098447, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.037635699123314235, 'proxyLowerStageReward_min': -0.07431354622420827, 'proxyLowerStageReward_max': -0.015210674465180422, 'proxySmoothStageChangesReward_mean': -0.09036269430051813, 'proxySmoothStageChangesReward_min': -0.18652849740932642, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004208290155440416, 'trueInfectionSummaryAbsoluteReward_min': -0.001968911917098447, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.009713989637305699, 'truePoliticalReward_min': -0.038134715025906735, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.037635699123314235, 'trueLowerStageReward_min': -0.07431354622420827, 'trueLowerStageReward_max': -0.015210674465180422, 'trueSmoothStageChangesReward_mean': -0.09036269430051813, 'trueSmoothStageChangesReward_min': -0.18652849740932642, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.279318223161906, 'total_modified_reward_min': -5.890353852398022, 'total_modified_reward_max': -0.6719744507803582}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.4410461162030697, 'cur_kl_coeff': 0.010546874999999999, 'cur_lr': 0.0003, 'total_loss': 0.009079154555874993, 'policy_loss': -0.004227376816173394, 'vf_loss': 0.05688133928449436, 'vf_explained_var': 0.38942604502042133, 'kl': 0.01657727346957368, 'entropy': 0.3616442270576954, 'entropy_coeff': 0.0423316}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 25050.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 324240, 'num_env_steps_trained': 324240, 'num_agent_steps_sampled': 324240, 'num_agent_steps_trained': 324240}, 'sampler_results': {'episode_reward_max': -0.6719744507803582, 'episode_reward_min': -5.890353852398022, 'episode_reward_mean': -2.279318223161906, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -20.46096899307997, 'default_policy/true_reward_min': -74.77961940777132, 'default_policy/true_reward_max': -0.7439213562373095, 'default_policy/proxy_reward_mean': -1.7129689930799654, 'default_policy/proxy_reward_min': -5.059974746830588, 'default_policy/proxy_reward_max': -0.4535660171779823, 'default_policy/modified_reward_mean': -2.279318223161906, 'default_policy/modified_reward_min': -5.890353852398022, 'default_policy/modified_reward_max': -0.6719744507803582, 'default_policy/corr_btw_rewards_mean': 0.531619952241059, 'default_policy/corr_btw_rewards_min': 0.09400005572585993, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -20.46096899307997, 'true_reward_min': -74.77961940777132, 'true_reward_max': -0.7439213562373095, 'proxy_reward_mean': -1.7129689930799654, 'proxy_reward_min': -5.059974746830588, 'proxy_reward_max': -0.4535660171779823, 'modified_reward_mean': -2.279318223161906, 'modified_reward_min': -5.890353852398022, 'modified_reward_max': -0.6719744507803582, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004208290155440416, 'proxyInfectionSummaryAbsoluteReward_min': -0.001968911917098447, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.037635699123314235, 'proxyLowerStageReward_min': -0.07431354622420827, 'proxyLowerStageReward_max': -0.015210674465180422, 'proxySmoothStageChangesReward_mean': -0.09036269430051813, 'proxySmoothStageChangesReward_min': -0.18652849740932642, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004208290155440416, 'trueInfectionSummaryAbsoluteReward_min': -0.001968911917098447, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.009713989637305699, 'truePoliticalReward_min': -0.038134715025906735, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.037635699123314235, 'trueLowerStageReward_min': -0.07431354622420827, 'trueLowerStageReward_max': -0.015210674465180422, 'trueSmoothStageChangesReward_mean': -0.09036269430051813, 'trueSmoothStageChangesReward_min': -0.18652849740932642, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.279318223161906, 'total_modified_reward_min': -5.890353852398022, 'total_modified_reward_max': -0.6719744507803582}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5363283099542537, 'mean_inference_ms': 1.6759227167857773, 'mean_action_processing_ms': 0.10673201763752506, 'mean_env_wait_ms': 741.936568379167, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.6719744507803582, 'episode_reward_min': -5.890353852398022, 'episode_reward_mean': -2.279318223161906, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5363283099542537, 'mean_inference_ms': 1.6759227167857773, 'mean_action_processing_ms': 0.10673201763752506, 'mean_env_wait_ms': 741.936568379167, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 324240, 'num_agent_steps_trained': 324240, 'num_env_steps_sampled': 324240, 'num_env_steps_trained': 324240, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.38297852695025, 'num_env_steps_trained_throughput_per_sec': 13.38297852695025, 'timesteps_total': 324240, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 324240, 'timers': {'training_iteration_time_ms': 289182.153, 'sample_time_ms': 288178.557, 'load_time_ms': 4.389, 'load_throughput': 879528.751, 'learn_time_ms': 982.204, 'learn_throughput': 3929.938, 'synch_weights_time_ms': 16.236}, 'counters': {'num_env_steps_sampled': 324240, 'num_env_steps_trained': 324240, 'num_agent_steps_sampled': 324240, 'num_agent_steps_trained': 324240}, 'done': False, 'episodes_total': 1680, 'training_iteration': 84, 'trial_id': 'default', 'date': '2025-11-05_02-10-08', 'timestamp': 1762337408, 'time_this_iter_s': 288.44650506973267, 'time_total_s': 26227.93954515457, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e10c7f40>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e10c67a0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e10c6b60>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e10c68f0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 26227.93954515457, 'iterations_since_restore': 84, 'perf': {'cpu_util_percent': 20.222815533980587, 'ram_util_percent': 6.0}}
Iteration 85/100
{'custom_metrics': {'default_policy/true_reward_mean': -21.33441506089183, 'default_policy/true_reward_min': -74.77961940777132, 'default_policy/true_reward_max': -0.7439213562373095, 'default_policy/proxy_reward_mean': -1.7304150608918303, 'default_policy/proxy_reward_min': -5.059974746830588, 'default_policy/proxy_reward_max': -0.4535660171779823, 'default_policy/modified_reward_mean': -2.2972089823068687, 'default_policy/modified_reward_min': -5.890353852398022, 'default_policy/modified_reward_max': -0.6719744507803582, 'default_policy/corr_btw_rewards_mean': 0.49777856664356995, 'default_policy/corr_btw_rewards_min': 0.09400005572585993, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -21.33441506089183, 'true_reward_min': -74.77961940777132, 'true_reward_max': -0.7439213562373095, 'proxy_reward_mean': -1.7304150608918303, 'proxy_reward_min': -5.059974746830588, 'proxy_reward_max': -0.4535660171779823, 'modified_reward_mean': -2.2972089823068687, 'modified_reward_min': -5.890353852398022, 'modified_reward_max': -0.6719744507803582, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00043191709844559605, 'proxyInfectionSummaryAbsoluteReward_min': -0.001968911917098447, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.037140676730146656, 'proxyLowerStageReward_min': -0.07431354622420827, 'proxyLowerStageReward_max': -0.015210674465180422, 'proxySmoothStageChangesReward_mean': -0.09326424870466322, 'proxySmoothStageChangesReward_min': -0.18652849740932642, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.00043191709844559605, 'trueInfectionSummaryAbsoluteReward_min': -0.001968911917098447, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010157512953367875, 'truePoliticalReward_min': -0.038134715025906735, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.037140676730146656, 'trueLowerStageReward_min': -0.07431354622420827, 'trueLowerStageReward_max': -0.015210674465180422, 'trueSmoothStageChangesReward_mean': -0.09326424870466322, 'trueSmoothStageChangesReward_min': -0.18652849740932642, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.2972089823068687, 'total_modified_reward_min': -5.890353852398022, 'total_modified_reward_max': -0.6719744507803582}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.170634015724063, 'cur_kl_coeff': 0.010546874999999999, 'cur_lr': 0.0003, 'total_loss': 0.0016646336919317643, 'policy_loss': -0.0036722135667999587, 'vf_loss': 0.03988862022369479, 'vf_explained_var': 0.37677519182364144, 'kl': 0.006506986673588902, 'entropy': 0.3524787385761738, 'entropy_coeff': 0.04163680000000001}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 25350.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 328100, 'num_env_steps_trained': 328100, 'num_agent_steps_sampled': 328100, 'num_agent_steps_trained': 328100}, 'sampler_results': {'episode_reward_max': -0.6719744507803582, 'episode_reward_min': -5.890353852398022, 'episode_reward_mean': -2.2972089823068687, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -21.33441506089183, 'default_policy/true_reward_min': -74.77961940777132, 'default_policy/true_reward_max': -0.7439213562373095, 'default_policy/proxy_reward_mean': -1.7304150608918303, 'default_policy/proxy_reward_min': -5.059974746830588, 'default_policy/proxy_reward_max': -0.4535660171779823, 'default_policy/modified_reward_mean': -2.2972089823068687, 'default_policy/modified_reward_min': -5.890353852398022, 'default_policy/modified_reward_max': -0.6719744507803582, 'default_policy/corr_btw_rewards_mean': 0.49777856664356995, 'default_policy/corr_btw_rewards_min': 0.09400005572585993, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -21.33441506089183, 'true_reward_min': -74.77961940777132, 'true_reward_max': -0.7439213562373095, 'proxy_reward_mean': -1.7304150608918303, 'proxy_reward_min': -5.059974746830588, 'proxy_reward_max': -0.4535660171779823, 'modified_reward_mean': -2.2972089823068687, 'modified_reward_min': -5.890353852398022, 'modified_reward_max': -0.6719744507803582, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00043191709844559605, 'proxyInfectionSummaryAbsoluteReward_min': -0.001968911917098447, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.037140676730146656, 'proxyLowerStageReward_min': -0.07431354622420827, 'proxyLowerStageReward_max': -0.015210674465180422, 'proxySmoothStageChangesReward_mean': -0.09326424870466322, 'proxySmoothStageChangesReward_min': -0.18652849740932642, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.00043191709844559605, 'trueInfectionSummaryAbsoluteReward_min': -0.001968911917098447, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010157512953367875, 'truePoliticalReward_min': -0.038134715025906735, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.037140676730146656, 'trueLowerStageReward_min': -0.07431354622420827, 'trueLowerStageReward_max': -0.015210674465180422, 'trueSmoothStageChangesReward_mean': -0.09326424870466322, 'trueSmoothStageChangesReward_min': -0.18652849740932642, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.2972089823068687, 'total_modified_reward_min': -5.890353852398022, 'total_modified_reward_max': -0.6719744507803582}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5359937209523634, 'mean_inference_ms': 1.6759312016920649, 'mean_action_processing_ms': 0.10671635999969453, 'mean_env_wait_ms': 741.7316754344455, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.6719744507803582, 'episode_reward_min': -5.890353852398022, 'episode_reward_mean': -2.2972089823068687, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5359937209523634, 'mean_inference_ms': 1.6759312016920649, 'mean_action_processing_ms': 0.10671635999969453, 'mean_env_wait_ms': 741.7316754344455, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 328100, 'num_agent_steps_trained': 328100, 'num_env_steps_sampled': 328100, 'num_env_steps_trained': 328100, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.449019348082098, 'num_env_steps_trained_throughput_per_sec': 13.449019348082098, 'timesteps_total': 328100, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 328100, 'timers': {'training_iteration_time_ms': 289077.996, 'sample_time_ms': 288087.136, 'load_time_ms': 4.81, 'load_throughput': 802570.476, 'learn_time_ms': 969.223, 'learn_throughput': 3982.571, 'synch_weights_time_ms': 16.045}, 'counters': {'num_env_steps_sampled': 328100, 'num_env_steps_trained': 328100, 'num_agent_steps_sampled': 328100, 'num_agent_steps_trained': 328100}, 'done': False, 'episodes_total': 1700, 'training_iteration': 85, 'trial_id': 'default', 'date': '2025-11-05_02-14-55', 'timestamp': 1762337695, 'time_this_iter_s': 287.0353147983551, 'time_total_s': 26514.974859952927, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6882fc610>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6882fcc70>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6882fd870>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6882fe620>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 26514.974859952927, 'iterations_since_restore': 85, 'perf': {'cpu_util_percent': 20.345965770171148, 'ram_util_percent': 6.0}}
Iteration 86/100
{'custom_metrics': {'default_policy/true_reward_mean': -18.367818866814115, 'default_policy/true_reward_min': -74.83569805153401, 'default_policy/true_reward_max': -0.7439213562373095, 'default_policy/proxy_reward_mean': -1.7398188668141181, 'default_policy/proxy_reward_min': -5.059974746830588, 'default_policy/proxy_reward_max': -0.4535660171779823, 'default_policy/modified_reward_mean': -2.2967366714271047, 'default_policy/modified_reward_min': -5.890353852398022, 'default_policy/modified_reward_max': -0.6719744507803582, 'default_policy/corr_btw_rewards_mean': 0.48084141465076774, 'default_policy/corr_btw_rewards_min': 0.10728807477430272, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -18.367818866814115, 'true_reward_min': -74.83569805153401, 'true_reward_max': -0.7439213562373095, 'proxy_reward_mean': -1.7398188668141181, 'proxy_reward_min': -5.059974746830588, 'proxy_reward_max': -0.4535660171779823, 'modified_reward_mean': -2.2967366714271047, 'modified_reward_min': -5.890353852398022, 'modified_reward_max': -0.6719744507803582, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004453886010362697, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019481865284974107, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0363843972442548, 'proxyLowerStageReward_min': -0.06448739798894028, 'proxyLowerStageReward_max': -0.015210674465180422, 'proxySmoothStageChangesReward_mean': -0.0922279792746114, 'proxySmoothStageChangesReward_min': -0.18652849740932642, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004453886010362697, 'trueInfectionSummaryAbsoluteReward_min': -0.0019481865284974107, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.008615544041450776, 'truePoliticalReward_min': -0.0383419689119171, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.0363843972442548, 'trueLowerStageReward_min': -0.06448739798894028, 'trueLowerStageReward_max': -0.015210674465180422, 'trueSmoothStageChangesReward_mean': -0.0922279792746114, 'trueSmoothStageChangesReward_min': -0.18652849740932642, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.2967366714271047, 'total_modified_reward_min': -5.890353852398022, 'total_modified_reward_max': -0.6719744507803582}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.1492143086095652, 'cur_kl_coeff': 0.010546874999999999, 'cur_lr': 0.0003, 'total_loss': -0.0028354659800728164, 'policy_loss': -0.003019803836941719, 'vf_loss': 0.03331628749069447, 'vf_explained_var': 0.47762916386127474, 'kl': 0.010663951743024603, 'entropy': 0.40511643717686335, 'entropy_coeff': 0.04094199999999999}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 25650.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 331960, 'num_env_steps_trained': 331960, 'num_agent_steps_sampled': 331960, 'num_agent_steps_trained': 331960}, 'sampler_results': {'episode_reward_max': -0.6719744507803582, 'episode_reward_min': -5.890353852398022, 'episode_reward_mean': -2.2967366714271047, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -18.367818866814115, 'default_policy/true_reward_min': -74.83569805153401, 'default_policy/true_reward_max': -0.7439213562373095, 'default_policy/proxy_reward_mean': -1.7398188668141181, 'default_policy/proxy_reward_min': -5.059974746830588, 'default_policy/proxy_reward_max': -0.4535660171779823, 'default_policy/modified_reward_mean': -2.2967366714271047, 'default_policy/modified_reward_min': -5.890353852398022, 'default_policy/modified_reward_max': -0.6719744507803582, 'default_policy/corr_btw_rewards_mean': 0.48084141465076774, 'default_policy/corr_btw_rewards_min': 0.10728807477430272, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -18.367818866814115, 'true_reward_min': -74.83569805153401, 'true_reward_max': -0.7439213562373095, 'proxy_reward_mean': -1.7398188668141181, 'proxy_reward_min': -5.059974746830588, 'proxy_reward_max': -0.4535660171779823, 'modified_reward_mean': -2.2967366714271047, 'modified_reward_min': -5.890353852398022, 'modified_reward_max': -0.6719744507803582, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0004453886010362697, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019481865284974107, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.0363843972442548, 'proxyLowerStageReward_min': -0.06448739798894028, 'proxyLowerStageReward_max': -0.015210674465180422, 'proxySmoothStageChangesReward_mean': -0.0922279792746114, 'proxySmoothStageChangesReward_min': -0.18652849740932642, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.0004453886010362697, 'trueInfectionSummaryAbsoluteReward_min': -0.0019481865284974107, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.008615544041450776, 'truePoliticalReward_min': -0.0383419689119171, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.0363843972442548, 'trueLowerStageReward_min': -0.06448739798894028, 'trueLowerStageReward_max': -0.015210674465180422, 'trueSmoothStageChangesReward_mean': -0.0922279792746114, 'trueSmoothStageChangesReward_min': -0.18652849740932642, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.2967366714271047, 'total_modified_reward_min': -5.890353852398022, 'total_modified_reward_max': -0.6719744507803582}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5358397042986828, 'mean_inference_ms': 1.6759302761199353, 'mean_action_processing_ms': 0.1067007189374797, 'mean_env_wait_ms': 741.533057704685, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.6719744507803582, 'episode_reward_min': -5.890353852398022, 'episode_reward_mean': -2.2967366714271047, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5358397042986828, 'mean_inference_ms': 1.6759302761199353, 'mean_action_processing_ms': 0.1067007189374797, 'mean_env_wait_ms': 741.533057704685, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 331960, 'num_agent_steps_trained': 331960, 'num_env_steps_sampled': 331960, 'num_env_steps_trained': 331960, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.542185784577295, 'num_env_steps_trained_throughput_per_sec': 13.542185784577295, 'timesteps_total': 331960, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 331960, 'timers': {'training_iteration_time_ms': 288593.684, 'sample_time_ms': 287620.44, 'load_time_ms': 4.894, 'load_throughput': 788767.908, 'learn_time_ms': 951.683, 'learn_throughput': 4055.973, 'synch_weights_time_ms': 15.869}, 'counters': {'num_env_steps_sampled': 331960, 'num_env_steps_trained': 331960, 'num_agent_steps_sampled': 331960, 'num_agent_steps_trained': 331960}, 'done': False, 'episodes_total': 1720, 'training_iteration': 86, 'trial_id': 'default', 'date': '2025-11-05_02-19-40', 'timestamp': 1762337980, 'time_this_iter_s': 285.0617537498474, 'time_total_s': 26800.036613702774, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a699610ca0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699611000>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699613c40>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699611600>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 26800.036613702774, 'iterations_since_restore': 86, 'perf': {'cpu_util_percent': 20.332186732186734, 'ram_util_percent': 6.0}}
Iteration 87/100
{'custom_metrics': {'default_policy/true_reward_mean': -24.16467166260963, 'default_policy/true_reward_min': -85.99997474683069, 'default_policy/true_reward_max': -0.7439213562373095, 'default_policy/proxy_reward_mean': -1.7006716626096283, 'default_policy/proxy_reward_min': -5.059974746830588, 'default_policy/proxy_reward_max': -0.4535660171779823, 'default_policy/modified_reward_mean': -2.2751090047729763, 'default_policy/modified_reward_min': -5.890353852398022, 'default_policy/modified_reward_max': -0.6719744507803582, 'default_policy/corr_btw_rewards_mean': 0.5256597606757609, 'default_policy/corr_btw_rewards_min': 0.10728807477430272, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -24.16467166260963, 'true_reward_min': -85.99997474683069, 'true_reward_max': -0.7439213562373095, 'proxy_reward_mean': -1.7006716626096283, 'proxy_reward_min': -5.059974746830588, 'proxy_reward_max': -0.4535660171779823, 'modified_reward_mean': -2.2751090047729763, 'modified_reward_min': -5.890353852398022, 'modified_reward_max': -0.6719744507803582, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00041305699481865315, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019481865284974107, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03702961982433309, 'proxyLowerStageReward_min': -0.061804667662689654, 'proxyLowerStageReward_max': -0.015210674465180422, 'proxySmoothStageChangesReward_mean': -0.0978238341968912, 'proxySmoothStageChangesReward_min': -0.18652849740932642, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.00041305699481865315, 'trueInfectionSummaryAbsoluteReward_min': -0.0019481865284974107, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.01163937823834197, 'truePoliticalReward_min': -0.04393782383419689, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03702961982433309, 'trueLowerStageReward_min': -0.061804667662689654, 'trueLowerStageReward_max': -0.015210674465180422, 'trueSmoothStageChangesReward_mean': -0.0978238341968912, 'trueSmoothStageChangesReward_min': -0.18652849740932642, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.2751090047729763, 'total_modified_reward_min': -5.890353852398022, 'total_modified_reward_max': -0.6719744507803582}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.8781293759743373, 'cur_kl_coeff': 0.010546874999999999, 'cur_lr': 0.0003, 'total_loss': -0.022536966176703574, 'policy_loss': -0.012689024722203613, 'vf_loss': 0.01289887451159302, 'vf_explained_var': 0.6740625663598379, 'kl': 0.011051901275112878, 'entropy': 0.40782816330591837, 'entropy_coeff': 0.040247200000000004}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 25950.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 335820, 'num_env_steps_trained': 335820, 'num_agent_steps_sampled': 335820, 'num_agent_steps_trained': 335820}, 'sampler_results': {'episode_reward_max': -0.6719744507803582, 'episode_reward_min': -5.890353852398022, 'episode_reward_mean': -2.2751090047729763, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -24.16467166260963, 'default_policy/true_reward_min': -85.99997474683069, 'default_policy/true_reward_max': -0.7439213562373095, 'default_policy/proxy_reward_mean': -1.7006716626096283, 'default_policy/proxy_reward_min': -5.059974746830588, 'default_policy/proxy_reward_max': -0.4535660171779823, 'default_policy/modified_reward_mean': -2.2751090047729763, 'default_policy/modified_reward_min': -5.890353852398022, 'default_policy/modified_reward_max': -0.6719744507803582, 'default_policy/corr_btw_rewards_mean': 0.5256597606757609, 'default_policy/corr_btw_rewards_min': 0.10728807477430272, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -24.16467166260963, 'true_reward_min': -85.99997474683069, 'true_reward_max': -0.7439213562373095, 'proxy_reward_mean': -1.7006716626096283, 'proxy_reward_min': -5.059974746830588, 'proxy_reward_max': -0.4535660171779823, 'modified_reward_mean': -2.2751090047729763, 'modified_reward_min': -5.890353852398022, 'modified_reward_max': -0.6719744507803582, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00041305699481865315, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019481865284974107, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03702961982433309, 'proxyLowerStageReward_min': -0.061804667662689654, 'proxyLowerStageReward_max': -0.015210674465180422, 'proxySmoothStageChangesReward_mean': -0.0978238341968912, 'proxySmoothStageChangesReward_min': -0.18652849740932642, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.00041305699481865315, 'trueInfectionSummaryAbsoluteReward_min': -0.0019481865284974107, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.01163937823834197, 'truePoliticalReward_min': -0.04393782383419689, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03702961982433309, 'trueLowerStageReward_min': -0.061804667662689654, 'trueLowerStageReward_max': -0.015210674465180422, 'trueSmoothStageChangesReward_mean': -0.0978238341968912, 'trueSmoothStageChangesReward_min': -0.18652849740932642, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.2751090047729763, 'total_modified_reward_min': -5.890353852398022, 'total_modified_reward_max': -0.6719744507803582}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5356486661608308, 'mean_inference_ms': 1.6759646146728024, 'mean_action_processing_ms': 0.10669587008249408, 'mean_env_wait_ms': 741.3215729953683, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.6719744507803582, 'episode_reward_min': -5.890353852398022, 'episode_reward_mean': -2.2751090047729763, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5356486661608308, 'mean_inference_ms': 1.6759646146728024, 'mean_action_processing_ms': 0.10669587008249408, 'mean_env_wait_ms': 741.3215729953683, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 335820, 'num_agent_steps_trained': 335820, 'num_env_steps_sampled': 335820, 'num_env_steps_trained': 335820, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.89317250142629, 'num_env_steps_trained_throughput_per_sec': 12.89317250142629, 'timesteps_total': 335820, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 335820, 'timers': {'training_iteration_time_ms': 289875.793, 'sample_time_ms': 288902.053, 'load_time_ms': 4.805, 'load_throughput': 803374.938, 'learn_time_ms': 952.37, 'learn_throughput': 4053.045, 'synch_weights_time_ms': 15.771}, 'counters': {'num_env_steps_sampled': 335820, 'num_env_steps_trained': 335820, 'num_agent_steps_sampled': 335820, 'num_agent_steps_trained': 335820}, 'done': False, 'episodes_total': 1740, 'training_iteration': 87, 'trial_id': 'default', 'date': '2025-11-05_02-24-40', 'timestamp': 1762338280, 'time_this_iter_s': 299.4128975868225, 'time_total_s': 27099.449511289597, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e2513340>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e226bf70>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2511240>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2512aa0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 27099.449511289597, 'iterations_since_restore': 87, 'perf': {'cpu_util_percent': 19.429274004683844, 'ram_util_percent': 6.0}}
Iteration 88/100
[2m[36m(RolloutWorker pid=3144227)[0m /next/u/stephhk/standalone_envs_for_yoonho/flow_reward_misspecification/flow/utils/flow_warnings.py:23: PendingDeprecationWarning: The attribute minGap in SumoCarFollowingParams is deprecated, use min_gap instead.[32m [repeated 9x across cluster][0m
[2m[36m(RolloutWorker pid=3144227)[0m   warnings.warn([32m [repeated 9x across cluster][0m
[2m[36m(RolloutWorker pid=3144233)[0m 2025-11-04 18:52:39,599	WARNING algorithm_config.py:2578 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.[32m [repeated 9x across cluster][0m
[2m[36m(RolloutWorker pid=3144227)[0m 2025-11-04 18:52:39,732	WARNING catalog.py:629 -- Custom ModelV2 should accept all custom options as **kwargs, instead of expecting them in config['custom_model_config']![32m [repeated 9x across cluster][0m
{'custom_metrics': {'default_policy/true_reward_mean': -24.49541836175073, 'default_policy/true_reward_min': -85.99997474683069, 'default_policy/true_reward_max': -0.7439213562373095, 'default_policy/proxy_reward_mean': -1.6634183617507292, 'default_policy/proxy_reward_min': -5.059974746830588, 'default_policy/proxy_reward_max': -0.4535660171779823, 'default_policy/modified_reward_mean': -2.2372759445269508, 'default_policy/modified_reward_min': -5.890353852398022, 'default_policy/modified_reward_max': -0.6719744507803582, 'default_policy/corr_btw_rewards_mean': 0.5277666737469118, 'default_policy/corr_btw_rewards_min': 0.10728807477430272, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -24.49541836175073, 'true_reward_min': -85.99997474683069, 'true_reward_max': -0.7439213562373095, 'proxy_reward_mean': -1.6634183617507292, 'proxy_reward_min': -5.059974746830588, 'proxy_reward_max': -0.4535660171779823, 'modified_reward_mean': -2.2372759445269508, 'modified_reward_min': -5.890353852398022, 'modified_reward_max': -0.6719744507803582, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00039347150259067383, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019481865284974107, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.037156391800555924, 'proxyLowerStageReward_min': -0.061804667662689654, 'proxyLowerStageReward_max': -0.015210674465180422, 'proxySmoothStageChangesReward_mean': -0.09683937823834199, 'proxySmoothStageChangesReward_min': -0.16580310880829016, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.00039347150259067383, 'trueInfectionSummaryAbsoluteReward_min': -0.0019481865284974107, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.011830051813471505, 'truePoliticalReward_min': -0.04393782383419689, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.037156391800555924, 'trueLowerStageReward_min': -0.061804667662689654, 'trueLowerStageReward_max': -0.015210674465180422, 'trueSmoothStageChangesReward_mean': -0.09683937823834199, 'trueSmoothStageChangesReward_min': -0.16580310880829016, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.2372759445269508, 'total_modified_reward_min': -5.890353852398022, 'total_modified_reward_max': -0.6719744507803582}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.6866960994899273, 'cur_kl_coeff': 0.010546874999999999, 'cur_lr': 0.0003, 'total_loss': -0.021216003341057027, 'policy_loss': -0.011136700563753644, 'vf_loss': 0.005924601595907007, 'vf_explained_var': 0.8114715866247812, 'kl': 0.0074438470653453, 'entropy': 0.33171469390392305, 'entropy_coeff': 0.039552399999999995}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 26250.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 339680, 'num_env_steps_trained': 339680, 'num_agent_steps_sampled': 339680, 'num_agent_steps_trained': 339680}, 'sampler_results': {'episode_reward_max': -0.6719744507803582, 'episode_reward_min': -5.890353852398022, 'episode_reward_mean': -2.2372759445269508, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -24.49541836175073, 'default_policy/true_reward_min': -85.99997474683069, 'default_policy/true_reward_max': -0.7439213562373095, 'default_policy/proxy_reward_mean': -1.6634183617507292, 'default_policy/proxy_reward_min': -5.059974746830588, 'default_policy/proxy_reward_max': -0.4535660171779823, 'default_policy/modified_reward_mean': -2.2372759445269508, 'default_policy/modified_reward_min': -5.890353852398022, 'default_policy/modified_reward_max': -0.6719744507803582, 'default_policy/corr_btw_rewards_mean': 0.5277666737469118, 'default_policy/corr_btw_rewards_min': 0.10728807477430272, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -24.49541836175073, 'true_reward_min': -85.99997474683069, 'true_reward_max': -0.7439213562373095, 'proxy_reward_mean': -1.6634183617507292, 'proxy_reward_min': -5.059974746830588, 'proxy_reward_max': -0.4535660171779823, 'modified_reward_mean': -2.2372759445269508, 'modified_reward_min': -5.890353852398022, 'modified_reward_max': -0.6719744507803582, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00039347150259067383, 'proxyInfectionSummaryAbsoluteReward_min': -0.0019481865284974107, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.037156391800555924, 'proxyLowerStageReward_min': -0.061804667662689654, 'proxyLowerStageReward_max': -0.015210674465180422, 'proxySmoothStageChangesReward_mean': -0.09683937823834199, 'proxySmoothStageChangesReward_min': -0.16580310880829016, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.00039347150259067383, 'trueInfectionSummaryAbsoluteReward_min': -0.0019481865284974107, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.011830051813471505, 'truePoliticalReward_min': -0.04393782383419689, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.037156391800555924, 'trueLowerStageReward_min': -0.061804667662689654, 'trueLowerStageReward_max': -0.015210674465180422, 'trueSmoothStageChangesReward_mean': -0.09683937823834199, 'trueSmoothStageChangesReward_min': -0.16580310880829016, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -2.2372759445269508, 'total_modified_reward_min': -5.890353852398022, 'total_modified_reward_max': -0.6719744507803582}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5358148523238639, 'mean_inference_ms': 1.6760866306988962, 'mean_action_processing_ms': 0.10669476883154218, 'mean_env_wait_ms': 741.1034126653517, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.6719744507803582, 'episode_reward_min': -5.890353852398022, 'episode_reward_mean': -2.2372759445269508, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5358148523238639, 'mean_inference_ms': 1.6760866306988962, 'mean_action_processing_ms': 0.10669476883154218, 'mean_env_wait_ms': 741.1034126653517, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 339680, 'num_agent_steps_trained': 339680, 'num_env_steps_sampled': 339680, 'num_env_steps_trained': 339680, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.409487408382507, 'num_env_steps_trained_throughput_per_sec': 13.409487408382507, 'timesteps_total': 339680, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 339680, 'timers': {'training_iteration_time_ms': 289755.31, 'sample_time_ms': 288782.734, 'load_time_ms': 4.685, 'load_throughput': 823965.384, 'learn_time_ms': 951.215, 'learn_throughput': 4057.969, 'synch_weights_time_ms': 15.893}, 'counters': {'num_env_steps_sampled': 339680, 'num_env_steps_trained': 339680, 'num_agent_steps_sampled': 339680, 'num_agent_steps_trained': 339680}, 'done': False, 'episodes_total': 1760, 'training_iteration': 88, 'trial_id': 'default', 'date': '2025-11-05_02-29-28', 'timestamp': 1762338568, 'time_this_iter_s': 287.87330627441406, 'time_total_s': 27387.32281756401, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6995619c0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6995601c0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e1778fd0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e177a050>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 27387.32281756401, 'iterations_since_restore': 88, 'perf': {'cpu_util_percent': 20.239416058394163, 'ram_util_percent': 6.0}}
Iteration 89/100
{'custom_metrics': {'default_policy/true_reward_mean': -27.688468614282428, 'default_policy/true_reward_min': -85.99997474683069, 'default_policy/true_reward_max': -0.7321320343559642, 'default_policy/proxy_reward_mean': -1.4684686142824233, 'default_policy/proxy_reward_min': -4.088540764008567, 'default_policy/proxy_reward_max': -0.519276695296637, 'default_policy/modified_reward_mean': -2.037036507618108, 'default_policy/modified_reward_min': -4.901958069880701, 'default_policy/modified_reward_max': -0.8023506436247467, 'default_policy/corr_btw_rewards_mean': 0.5015274272245178, 'default_policy/corr_btw_rewards_min': 0.10728807477430272, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -27.688468614282428, 'true_reward_min': -85.99997474683069, 'true_reward_max': -0.7321320343559642, 'proxy_reward_mean': -1.4684686142824233, 'proxy_reward_min': -4.088540764008567, 'proxy_reward_max': -0.519276695296637, 'modified_reward_mean': -2.037036507618108, 'modified_reward_min': -4.901958069880701, 'modified_reward_max': -0.8023506436247467, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002970984455958551, 'proxyInfectionSummaryAbsoluteReward_min': -0.001481865284974094, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03674448778665407, 'proxyLowerStageReward_min': -0.06028708621806038, 'proxyLowerStageReward_max': -0.017579103383245434, 'proxySmoothStageChangesReward_mean': -0.09632124352331609, 'proxySmoothStageChangesReward_min': -0.16580310880829016, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002970984455958551, 'trueInfectionSummaryAbsoluteReward_min': -0.001481865284974094, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.013585492227979277, 'truePoliticalReward_min': -0.04393782383419689, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03674448778665407, 'trueLowerStageReward_min': -0.06028708621806038, 'trueLowerStageReward_max': -0.017579103383245434, 'trueSmoothStageChangesReward_mean': -0.09632124352331609, 'trueSmoothStageChangesReward_min': -0.16580310880829016, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -2.037036507618108, 'total_modified_reward_min': -4.901958069880701, 'total_modified_reward_max': -0.8023506436247467}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.8617240623136362, 'cur_kl_coeff': 0.010546874999999999, 'cur_lr': 0.0003, 'total_loss': -0.004491940096098309, 'policy_loss': 0.00022195509945352872, 'vf_loss': 0.01340108891366981, 'vf_explained_var': 0.597030966480573, 'kl': 0.005531659651587914, 'entropy': 0.29525189553697906, 'entropy_coeff': 0.0388576}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 26550.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 343540, 'num_env_steps_trained': 343540, 'num_agent_steps_sampled': 343540, 'num_agent_steps_trained': 343540}, 'sampler_results': {'episode_reward_max': -0.8023506436247467, 'episode_reward_min': -4.901958069880701, 'episode_reward_mean': -2.037036507618108, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -27.688468614282428, 'default_policy/true_reward_min': -85.99997474683069, 'default_policy/true_reward_max': -0.7321320343559642, 'default_policy/proxy_reward_mean': -1.4684686142824233, 'default_policy/proxy_reward_min': -4.088540764008567, 'default_policy/proxy_reward_max': -0.519276695296637, 'default_policy/modified_reward_mean': -2.037036507618108, 'default_policy/modified_reward_min': -4.901958069880701, 'default_policy/modified_reward_max': -0.8023506436247467, 'default_policy/corr_btw_rewards_mean': 0.5015274272245178, 'default_policy/corr_btw_rewards_min': 0.10728807477430272, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -27.688468614282428, 'true_reward_min': -85.99997474683069, 'true_reward_max': -0.7321320343559642, 'proxy_reward_mean': -1.4684686142824233, 'proxy_reward_min': -4.088540764008567, 'proxy_reward_max': -0.519276695296637, 'modified_reward_mean': -2.037036507618108, 'modified_reward_min': -4.901958069880701, 'modified_reward_max': -0.8023506436247467, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002970984455958551, 'proxyInfectionSummaryAbsoluteReward_min': -0.001481865284974094, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03674448778665407, 'proxyLowerStageReward_min': -0.06028708621806038, 'proxyLowerStageReward_max': -0.017579103383245434, 'proxySmoothStageChangesReward_mean': -0.09632124352331609, 'proxySmoothStageChangesReward_min': -0.16580310880829016, 'proxySmoothStageChangesReward_max': -0.05181347150259067, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002970984455958551, 'trueInfectionSummaryAbsoluteReward_min': -0.001481865284974094, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.013585492227979277, 'truePoliticalReward_min': -0.04393782383419689, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03674448778665407, 'trueLowerStageReward_min': -0.06028708621806038, 'trueLowerStageReward_max': -0.017579103383245434, 'trueSmoothStageChangesReward_mean': -0.09632124352331609, 'trueSmoothStageChangesReward_min': -0.16580310880829016, 'trueSmoothStageChangesReward_max': -0.05181347150259067, 'total_modified_reward_mean': -2.037036507618108, 'total_modified_reward_min': -4.901958069880701, 'total_modified_reward_max': -0.8023506436247467}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5359883660800303, 'mean_inference_ms': 1.6760564169743697, 'mean_action_processing_ms': 0.10669554350763696, 'mean_env_wait_ms': 740.8932707034555, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.8023506436247467, 'episode_reward_min': -4.901958069880701, 'episode_reward_mean': -2.037036507618108, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5359883660800303, 'mean_inference_ms': 1.6760564169743697, 'mean_action_processing_ms': 0.10669554350763696, 'mean_env_wait_ms': 740.8932707034555, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 343540, 'num_agent_steps_trained': 343540, 'num_env_steps_sampled': 343540, 'num_env_steps_trained': 343540, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.271038719444682, 'num_env_steps_trained_throughput_per_sec': 13.271038719444682, 'timesteps_total': 343540, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 343540, 'timers': {'training_iteration_time_ms': 289757.597, 'sample_time_ms': 288786.413, 'load_time_ms': 4.821, 'load_throughput': 800598.022, 'learn_time_ms': 949.431, 'learn_throughput': 4065.593, 'synch_weights_time_ms': 16.158}, 'counters': {'num_env_steps_sampled': 343540, 'num_env_steps_trained': 343540, 'num_agent_steps_sampled': 343540, 'num_agent_steps_trained': 343540}, 'done': False, 'episodes_total': 1780, 'training_iteration': 89, 'trial_id': 'default', 'date': '2025-11-05_02-34-19', 'timestamp': 1762338859, 'time_this_iter_s': 290.8811981678009, 'time_total_s': 27678.20401573181, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a6997839a0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e18c51b0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e1287970>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e1286770>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 27678.20401573181, 'iterations_since_restore': 89, 'perf': {'cpu_util_percent': 20.25434782608696, 'ram_util_percent': 6.0}}
Iteration 90/100
{'custom_metrics': {'default_policy/true_reward_mean': -27.46327279900226, 'default_policy/true_reward_min': -85.99997474683069, 'default_policy/true_reward_max': -0.7321320343559642, 'default_policy/proxy_reward_mean': -1.4232727990022522, 'default_policy/proxy_reward_min': -4.118540764008568, 'default_policy/proxy_reward_max': -0.47142135623730974, 'default_policy/modified_reward_mean': -1.9835479086929462, 'default_policy/modified_reward_min': -5.066858249340451, 'default_policy/modified_reward_max': -0.7626326010404776, 'default_policy/corr_btw_rewards_mean': 0.5201194457660241, 'default_policy/corr_btw_rewards_min': 0.10728807477430272, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -27.46327279900226, 'true_reward_min': -85.99997474683069, 'true_reward_max': -0.7321320343559642, 'proxy_reward_mean': -1.4232727990022522, 'proxy_reward_min': -4.118540764008568, 'proxy_reward_max': -0.47142135623730974, 'modified_reward_mean': -1.9835479086929462, 'modified_reward_min': -5.066858249340451, 'modified_reward_max': -0.7626326010404776, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00027854922279792763, 'proxyInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.036620352279909445, 'proxyLowerStageReward_min': -0.06417309658075468, 'proxyLowerStageReward_max': -0.019633230893124843, 'proxySmoothStageChangesReward_mean': -0.09269430051813472, 'proxySmoothStageChangesReward_min': -0.16580310880829016, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00027854922279792763, 'trueInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.013492227979274612, 'truePoliticalReward_min': -0.04393782383419689, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.036620352279909445, 'trueLowerStageReward_min': -0.06417309658075468, 'trueLowerStageReward_max': -0.019633230893124843, 'trueSmoothStageChangesReward_mean': -0.09269430051813472, 'trueSmoothStageChangesReward_min': -0.16580310880829016, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -1.9835479086929462, 'total_modified_reward_min': -5.066858249340451, 'total_modified_reward_max': -0.7626326010404776}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0524749358122547, 'cur_kl_coeff': 0.010546874999999999, 'cur_lr': 0.0003, 'total_loss': 0.000995078794658184, 'policy_loss': -0.0024353923834860326, 'vf_loss': 0.031194019588195565, 'vf_explained_var': 0.4515022627512614, 'kl': 0.008245292630219362, 'entropy': 0.32108487556378046, 'entropy_coeff': 0.03816279999999999}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 26850.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 347400, 'num_env_steps_trained': 347400, 'num_agent_steps_sampled': 347400, 'num_agent_steps_trained': 347400}, 'sampler_results': {'episode_reward_max': -0.7626326010404776, 'episode_reward_min': -5.066858249340451, 'episode_reward_mean': -1.9835479086929462, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -27.46327279900226, 'default_policy/true_reward_min': -85.99997474683069, 'default_policy/true_reward_max': -0.7321320343559642, 'default_policy/proxy_reward_mean': -1.4232727990022522, 'default_policy/proxy_reward_min': -4.118540764008568, 'default_policy/proxy_reward_max': -0.47142135623730974, 'default_policy/modified_reward_mean': -1.9835479086929462, 'default_policy/modified_reward_min': -5.066858249340451, 'default_policy/modified_reward_max': -0.7626326010404776, 'default_policy/corr_btw_rewards_mean': 0.5201194457660241, 'default_policy/corr_btw_rewards_min': 0.10728807477430272, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -27.46327279900226, 'true_reward_min': -85.99997474683069, 'true_reward_max': -0.7321320343559642, 'proxy_reward_mean': -1.4232727990022522, 'proxy_reward_min': -4.118540764008568, 'proxy_reward_max': -0.47142135623730974, 'modified_reward_mean': -1.9835479086929462, 'modified_reward_min': -5.066858249340451, 'modified_reward_max': -0.7626326010404776, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00027854922279792763, 'proxyInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.036620352279909445, 'proxyLowerStageReward_min': -0.06417309658075468, 'proxyLowerStageReward_max': -0.019633230893124843, 'proxySmoothStageChangesReward_mean': -0.09269430051813472, 'proxySmoothStageChangesReward_min': -0.16580310880829016, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00027854922279792763, 'trueInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.013492227979274612, 'truePoliticalReward_min': -0.04393782383419689, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.036620352279909445, 'trueLowerStageReward_min': -0.06417309658075468, 'trueLowerStageReward_max': -0.019633230893124843, 'trueSmoothStageChangesReward_mean': -0.09269430051813472, 'trueSmoothStageChangesReward_min': -0.16580310880829016, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -1.9835479086929462, 'total_modified_reward_min': -5.066858249340451, 'total_modified_reward_max': -0.7626326010404776}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5361442879816706, 'mean_inference_ms': 1.6760527673779924, 'mean_action_processing_ms': 0.10670056563185627, 'mean_env_wait_ms': 740.6776770067294, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.7626326010404776, 'episode_reward_min': -5.066858249340451, 'episode_reward_mean': -1.9835479086929462, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5361442879816706, 'mean_inference_ms': 1.6760527673779924, 'mean_action_processing_ms': 0.10670056563185627, 'mean_env_wait_ms': 740.6776770067294, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 347400, 'num_agent_steps_trained': 347400, 'num_env_steps_sampled': 347400, 'num_env_steps_trained': 347400, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.514261312245988, 'num_env_steps_trained_throughput_per_sec': 13.514261312245988, 'timesteps_total': 347400, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 347400, 'timers': {'training_iteration_time_ms': 289502.642, 'sample_time_ms': 288529.815, 'load_time_ms': 4.693, 'load_throughput': 822425.082, 'learn_time_ms': 951.095, 'learn_throughput': 4058.481, 'synch_weights_time_ms': 16.265}, 'counters': {'num_env_steps_sampled': 347400, 'num_env_steps_trained': 347400, 'num_agent_steps_sampled': 347400, 'num_agent_steps_trained': 347400}, 'done': False, 'episodes_total': 1800, 'training_iteration': 90, 'trial_id': 'default', 'date': '2025-11-05_02-39-05', 'timestamp': 1762339145, 'time_this_iter_s': 285.63729071617126, 'time_total_s': 27963.841306447983, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e177af50>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e177ba60>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e177a1a0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e177a050>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 27963.841306447983, 'iterations_since_restore': 90, 'perf': {'cpu_util_percent': 20.298774509803923, 'ram_util_percent': 6.0}}
Saved checkpoint to TrainingResult(checkpoint=Checkpoint(filesystem=local, path=logs/data/pandemic/20251104_185246/checkpoint_90), metrics={'custom_metrics': {'default_policy/true_reward_mean': -27.46327279900226, 'default_policy/true_reward_min': -85.99997474683069, 'default_policy/true_reward_max': -0.7321320343559642, 'default_policy/proxy_reward_mean': -1.4232727990022522, 'default_policy/proxy_reward_min': -4.118540764008568, 'default_policy/proxy_reward_max': -0.47142135623730974, 'default_policy/modified_reward_mean': -1.9835479086929462, 'default_policy/modified_reward_min': -5.066858249340451, 'default_policy/modified_reward_max': -0.7626326010404776, 'default_policy/corr_btw_rewards_mean': 0.5201194457660241, 'default_policy/corr_btw_rewards_min': 0.10728807477430272, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -27.46327279900226, 'true_reward_min': -85.99997474683069, 'true_reward_max': -0.7321320343559642, 'proxy_reward_mean': -1.4232727990022522, 'proxy_reward_min': -4.118540764008568, 'proxy_reward_max': -0.47142135623730974, 'modified_reward_mean': -1.9835479086929462, 'modified_reward_min': -5.066858249340451, 'modified_reward_max': -0.7626326010404776, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00027854922279792763, 'proxyInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.036620352279909445, 'proxyLowerStageReward_min': -0.06417309658075468, 'proxyLowerStageReward_max': -0.019633230893124843, 'proxySmoothStageChangesReward_mean': -0.09269430051813472, 'proxySmoothStageChangesReward_min': -0.16580310880829016, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00027854922279792763, 'trueInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.013492227979274612, 'truePoliticalReward_min': -0.04393782383419689, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.036620352279909445, 'trueLowerStageReward_min': -0.06417309658075468, 'trueLowerStageReward_max': -0.019633230893124843, 'trueSmoothStageChangesReward_mean': -0.09269430051813472, 'trueSmoothStageChangesReward_min': -0.16580310880829016, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -1.9835479086929462, 'total_modified_reward_min': -5.066858249340451, 'total_modified_reward_max': -0.7626326010404776}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0524749358122547, 'cur_kl_coeff': 0.010546874999999999, 'cur_lr': 0.0003, 'total_loss': 0.000995078794658184, 'policy_loss': -0.0024353923834860326, 'vf_loss': 0.031194019588195565, 'vf_explained_var': 0.4515022627512614, 'kl': 0.008245292630219362, 'entropy': 0.32108487556378046, 'entropy_coeff': 0.03816279999999999}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 26850.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 347400, 'num_env_steps_trained': 347400, 'num_agent_steps_sampled': 347400, 'num_agent_steps_trained': 347400}, 'sampler_results': {'episode_reward_max': -0.7626326010404776, 'episode_reward_min': -5.066858249340451, 'episode_reward_mean': -1.9835479086929462, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -27.46327279900226, 'default_policy/true_reward_min': -85.99997474683069, 'default_policy/true_reward_max': -0.7321320343559642, 'default_policy/proxy_reward_mean': -1.4232727990022522, 'default_policy/proxy_reward_min': -4.118540764008568, 'default_policy/proxy_reward_max': -0.47142135623730974, 'default_policy/modified_reward_mean': -1.9835479086929462, 'default_policy/modified_reward_min': -5.066858249340451, 'default_policy/modified_reward_max': -0.7626326010404776, 'default_policy/corr_btw_rewards_mean': 0.5201194457660241, 'default_policy/corr_btw_rewards_min': 0.10728807477430272, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -27.46327279900226, 'true_reward_min': -85.99997474683069, 'true_reward_max': -0.7321320343559642, 'proxy_reward_mean': -1.4232727990022522, 'proxy_reward_min': -4.118540764008568, 'proxy_reward_max': -0.47142135623730974, 'modified_reward_mean': -1.9835479086929462, 'modified_reward_min': -5.066858249340451, 'modified_reward_max': -0.7626326010404776, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00027854922279792763, 'proxyInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.036620352279909445, 'proxyLowerStageReward_min': -0.06417309658075468, 'proxyLowerStageReward_max': -0.019633230893124843, 'proxySmoothStageChangesReward_mean': -0.09269430051813472, 'proxySmoothStageChangesReward_min': -0.16580310880829016, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00027854922279792763, 'trueInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.013492227979274612, 'truePoliticalReward_min': -0.04393782383419689, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.036620352279909445, 'trueLowerStageReward_min': -0.06417309658075468, 'trueLowerStageReward_max': -0.019633230893124843, 'trueSmoothStageChangesReward_mean': -0.09269430051813472, 'trueSmoothStageChangesReward_min': -0.16580310880829016, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -1.9835479086929462, 'total_modified_reward_min': -5.066858249340451, 'total_modified_reward_max': -0.7626326010404776}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5361442879816706, 'mean_inference_ms': 1.6760527673779924, 'mean_action_processing_ms': 0.10670056563185627, 'mean_env_wait_ms': 740.6776770067294, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.7626326010404776, 'episode_reward_min': -5.066858249340451, 'episode_reward_mean': -1.9835479086929462, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5361442879816706, 'mean_inference_ms': 1.6760527673779924, 'mean_action_processing_ms': 0.10670056563185627, 'mean_env_wait_ms': 740.6776770067294, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 347400, 'num_agent_steps_trained': 347400, 'num_env_steps_sampled': 347400, 'num_env_steps_trained': 347400, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.514261312245988, 'num_env_steps_trained_throughput_per_sec': 13.514261312245988, 'timesteps_total': 347400, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 347400, 'timers': {'training_iteration_time_ms': 289502.642, 'sample_time_ms': 288529.815, 'load_time_ms': 4.693, 'load_throughput': 822425.082, 'learn_time_ms': 951.095, 'learn_throughput': 4058.481, 'synch_weights_time_ms': 16.265}, 'counters': {'num_env_steps_sampled': 347400, 'num_env_steps_trained': 347400, 'num_agent_steps_sampled': 347400, 'num_agent_steps_trained': 347400}, 'done': False, 'episodes_total': 1800, 'training_iteration': 90, 'trial_id': 'default', 'date': '2025-11-05_02-39-05', 'timestamp': 1762339145, 'time_this_iter_s': 285.63729071617126, 'time_total_s': 27963.841306447983, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e177af50>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e177ba60>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e177a1a0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e177a050>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 27963.841306447983, 'iterations_since_restore': 90, 'perf': {'cpu_util_percent': 20.298774509803923, 'ram_util_percent': 6.0}})
Iteration 91/100
{'custom_metrics': {'default_policy/true_reward_mean': -29.134848430331495, 'default_policy/true_reward_min': -85.99997474683069, 'default_policy/true_reward_max': -0.7321320343559642, 'default_policy/proxy_reward_mean': -1.3148484303314874, 'default_policy/proxy_reward_min': -4.118540764008568, 'default_policy/proxy_reward_max': -0.47142135623730974, 'default_policy/modified_reward_mean': -1.8599228191127368, 'default_policy/modified_reward_min': -5.066858249340451, 'default_policy/modified_reward_max': -0.7626326010404776, 'default_policy/corr_btw_rewards_mean': 0.5326183894697877, 'default_policy/corr_btw_rewards_min': 0.11133250935794216, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -29.134848430331495, 'true_reward_min': -85.99997474683069, 'true_reward_max': -0.7321320343559642, 'proxy_reward_mean': -1.3148484303314874, 'proxy_reward_min': -4.118540764008568, 'proxy_reward_max': -0.47142135623730974, 'modified_reward_mean': -1.8599228191127368, 'modified_reward_min': -5.066858249340451, 'modified_reward_max': -0.7626326010404776, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00023409326424870476, 'proxyInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03578489276328952, 'proxyLowerStageReward_min': -0.06417309658075468, 'proxyLowerStageReward_max': -0.018874440170810202, 'proxySmoothStageChangesReward_mean': -0.08932642487046633, 'proxySmoothStageChangesReward_min': -0.16580310880829016, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00023409326424870476, 'trueInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.014414507772020723, 'truePoliticalReward_min': -0.04393782383419689, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03578489276328952, 'trueLowerStageReward_min': -0.06417309658075468, 'trueLowerStageReward_max': -0.018874440170810202, 'trueSmoothStageChangesReward_mean': -0.08932642487046633, 'trueSmoothStageChangesReward_min': -0.16580310880829016, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -1.8599228191127368, 'total_modified_reward_min': -5.066858249340451, 'total_modified_reward_max': -0.7626326010404776}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.7775264187902212, 'cur_kl_coeff': 0.010546874999999999, 'cur_lr': 0.0003, 'total_loss': -0.009693466512253508, 'policy_loss': -0.006585067116344968, 'vf_loss': 0.018062209132767747, 'vf_explained_var': 0.5931672374407451, 'kl': 0.005123261585201788, 'entropy': 0.32543866490324336, 'entropy_coeff': 0.037468}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 27150.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 351260, 'num_env_steps_trained': 351260, 'num_agent_steps_sampled': 351260, 'num_agent_steps_trained': 351260}, 'sampler_results': {'episode_reward_max': -0.7626326010404776, 'episode_reward_min': -5.066858249340451, 'episode_reward_mean': -1.8599228191127368, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -29.134848430331495, 'default_policy/true_reward_min': -85.99997474683069, 'default_policy/true_reward_max': -0.7321320343559642, 'default_policy/proxy_reward_mean': -1.3148484303314874, 'default_policy/proxy_reward_min': -4.118540764008568, 'default_policy/proxy_reward_max': -0.47142135623730974, 'default_policy/modified_reward_mean': -1.8599228191127368, 'default_policy/modified_reward_min': -5.066858249340451, 'default_policy/modified_reward_max': -0.7626326010404776, 'default_policy/corr_btw_rewards_mean': 0.5326183894697877, 'default_policy/corr_btw_rewards_min': 0.11133250935794216, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -29.134848430331495, 'true_reward_min': -85.99997474683069, 'true_reward_max': -0.7321320343559642, 'proxy_reward_mean': -1.3148484303314874, 'proxy_reward_min': -4.118540764008568, 'proxy_reward_max': -0.47142135623730974, 'modified_reward_mean': -1.8599228191127368, 'modified_reward_min': -5.066858249340451, 'modified_reward_max': -0.7626326010404776, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00023409326424870476, 'proxyInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03578489276328952, 'proxyLowerStageReward_min': -0.06417309658075468, 'proxyLowerStageReward_max': -0.018874440170810202, 'proxySmoothStageChangesReward_mean': -0.08932642487046633, 'proxySmoothStageChangesReward_min': -0.16580310880829016, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00023409326424870476, 'trueInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.014414507772020723, 'truePoliticalReward_min': -0.04393782383419689, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03578489276328952, 'trueLowerStageReward_min': -0.06417309658075468, 'trueLowerStageReward_max': -0.018874440170810202, 'trueSmoothStageChangesReward_mean': -0.08932642487046633, 'trueSmoothStageChangesReward_min': -0.16580310880829016, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -1.8599228191127368, 'total_modified_reward_min': -5.066858249340451, 'total_modified_reward_max': -0.7626326010404776}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5361307607445701, 'mean_inference_ms': 1.6760647342396242, 'mean_action_processing_ms': 0.1067096295657094, 'mean_env_wait_ms': 740.4693142434705, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.7626326010404776, 'episode_reward_min': -5.066858249340451, 'episode_reward_mean': -1.8599228191127368, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5361307607445701, 'mean_inference_ms': 1.6760647342396242, 'mean_action_processing_ms': 0.1067096295657094, 'mean_env_wait_ms': 740.4693142434705, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 351260, 'num_agent_steps_trained': 351260, 'num_env_steps_sampled': 351260, 'num_env_steps_trained': 351260, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.416140845880813, 'num_env_steps_trained_throughput_per_sec': 13.416140845880813, 'timesteps_total': 351260, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 351260, 'timers': {'training_iteration_time_ms': 289224.235, 'sample_time_ms': 288239.153, 'load_time_ms': 4.715, 'load_throughput': 818611.822, 'learn_time_ms': 963.624, 'learn_throughput': 4005.713, 'synch_weights_time_ms': 15.97}, 'counters': {'num_env_steps_sampled': 351260, 'num_env_steps_trained': 351260, 'num_agent_steps_sampled': 351260, 'num_agent_steps_trained': 351260}, 'done': False, 'episodes_total': 1820, 'training_iteration': 91, 'trial_id': 'default', 'date': '2025-11-05_02-43-53', 'timestamp': 1762339433, 'time_this_iter_s': 287.73093366622925, 'time_total_s': 28251.572240114212, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e2269570>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e22693f0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2268f10>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2269b70>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 28251.572240114212, 'iterations_since_restore': 91, 'perf': {'cpu_util_percent': 20.2919315403423, 'ram_util_percent': 6.0}}
Iteration 92/100
{'custom_metrics': {'default_policy/true_reward_mean': -21.59100312011471, 'default_policy/true_reward_min': -81.04176406871198, 'default_policy/true_reward_max': -0.7321320343559642, 'default_policy/proxy_reward_mean': -1.3390031201147041, 'default_policy/proxy_reward_min': -4.118540764008568, 'default_policy/proxy_reward_max': -0.47142135623730974, 'default_policy/modified_reward_mean': -1.8495670343460875, 'default_policy/modified_reward_min': -5.066858249340451, 'default_policy/modified_reward_max': -0.7626326010404776, 'default_policy/corr_btw_rewards_mean': 0.5116331061289996, 'default_policy/corr_btw_rewards_min': 0.11133250935794216, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -21.59100312011471, 'true_reward_min': -81.04176406871198, 'true_reward_max': -0.7321320343559642, 'proxy_reward_mean': -1.3390031201147041, 'proxy_reward_min': -4.118540764008568, 'proxy_reward_max': -0.47142135623730974, 'modified_reward_mean': -1.8495670343460875, 'modified_reward_min': -5.066858249340451, 'modified_reward_max': -0.7626326010404776, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002728497409326427, 'proxyInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03396907358107278, 'proxyLowerStageReward_min': -0.06417309658075468, 'proxyLowerStageReward_max': -0.017690225711777693, 'proxySmoothStageChangesReward_mean': -0.08124352331606217, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002728497409326427, 'trueInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010493264248704665, 'truePoliticalReward_min': -0.04145077720207254, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03396907358107278, 'trueLowerStageReward_min': -0.06417309658075468, 'trueLowerStageReward_max': -0.017690225711777693, 'trueSmoothStageChangesReward_mean': -0.08124352331606217, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -1.8495670343460875, 'total_modified_reward_min': -5.066858249340451, 'total_modified_reward_max': -0.7626326010404776}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0725435660779477, 'cur_kl_coeff': 0.010546874999999999, 'cur_lr': 0.0003, 'total_loss': 0.0035430704802274704, 'policy_loss': -0.0027019468198219935, 'vf_loss': 0.03649576652174195, 'vf_explained_var': 0.28820780118306477, 'kl': 0.00871343517140955, 'entropy': 0.32890158077081044, 'entropy_coeff': 0.0367732}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 27450.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 355120, 'num_env_steps_trained': 355120, 'num_agent_steps_sampled': 355120, 'num_agent_steps_trained': 355120}, 'sampler_results': {'episode_reward_max': -0.7626326010404776, 'episode_reward_min': -5.066858249340451, 'episode_reward_mean': -1.8495670343460875, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -21.59100312011471, 'default_policy/true_reward_min': -81.04176406871198, 'default_policy/true_reward_max': -0.7321320343559642, 'default_policy/proxy_reward_mean': -1.3390031201147041, 'default_policy/proxy_reward_min': -4.118540764008568, 'default_policy/proxy_reward_max': -0.47142135623730974, 'default_policy/modified_reward_mean': -1.8495670343460875, 'default_policy/modified_reward_min': -5.066858249340451, 'default_policy/modified_reward_max': -0.7626326010404776, 'default_policy/corr_btw_rewards_mean': 0.5116331061289996, 'default_policy/corr_btw_rewards_min': 0.11133250935794216, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -21.59100312011471, 'true_reward_min': -81.04176406871198, 'true_reward_max': -0.7321320343559642, 'proxy_reward_mean': -1.3390031201147041, 'proxy_reward_min': -4.118540764008568, 'proxy_reward_max': -0.47142135623730974, 'modified_reward_mean': -1.8495670343460875, 'modified_reward_min': -5.066858249340451, 'modified_reward_max': -0.7626326010404776, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002728497409326427, 'proxyInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03396907358107278, 'proxyLowerStageReward_min': -0.06417309658075468, 'proxyLowerStageReward_max': -0.017690225711777693, 'proxySmoothStageChangesReward_mean': -0.08124352331606217, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002728497409326427, 'trueInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.010493264248704665, 'truePoliticalReward_min': -0.04145077720207254, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03396907358107278, 'trueLowerStageReward_min': -0.06417309658075468, 'trueLowerStageReward_max': -0.017690225711777693, 'trueSmoothStageChangesReward_mean': -0.08124352331606217, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -1.8495670343460875, 'total_modified_reward_min': -5.066858249340451, 'total_modified_reward_max': -0.7626326010404776}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5361710148114522, 'mean_inference_ms': 1.6760518642513353, 'mean_action_processing_ms': 0.10670960804766808, 'mean_env_wait_ms': 740.2997501033137, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.7626326010404776, 'episode_reward_min': -5.066858249340451, 'episode_reward_mean': -1.8495670343460875, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5361710148114522, 'mean_inference_ms': 1.6760518642513353, 'mean_action_processing_ms': 0.10670960804766808, 'mean_env_wait_ms': 740.2997501033137, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 355120, 'num_agent_steps_trained': 355120, 'num_env_steps_sampled': 355120, 'num_env_steps_trained': 355120, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.212270387722036, 'num_env_steps_trained_throughput_per_sec': 13.212270387722036, 'timesteps_total': 355120, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 355120, 'timers': {'training_iteration_time_ms': 289304.241, 'sample_time_ms': 288314.728, 'load_time_ms': 4.602, 'load_throughput': 838752.153, 'learn_time_ms': 968.514, 'learn_throughput': 3985.489, 'synch_weights_time_ms': 15.638}, 'counters': {'num_env_steps_sampled': 355120, 'num_env_steps_trained': 355120, 'num_agent_steps_sampled': 355120, 'num_agent_steps_trained': 355120}, 'done': False, 'episodes_total': 1840, 'training_iteration': 92, 'trial_id': 'default', 'date': '2025-11-05_02-48-45', 'timestamp': 1762339725, 'time_this_iter_s': 292.17080545425415, 'time_total_s': 28543.743045568466, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a698079540>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6a9255cf0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e18c4820>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14cba9d0f700>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 28543.743045568466, 'iterations_since_restore': 92, 'perf': {'cpu_util_percent': 20.271702637889693, 'ram_util_percent': 6.0}}
Iteration 93/100
{'custom_metrics': {'default_policy/true_reward_mean': -17.16298878028648, 'default_policy/true_reward_min': -63.61176406871194, 'default_policy/true_reward_max': -0.7321320343559642, 'default_policy/proxy_reward_mean': -1.3949887802864844, 'default_policy/proxy_reward_min': -4.118540764008568, 'default_policy/proxy_reward_max': -0.47142135623730974, 'default_policy/modified_reward_mean': -1.9001018786744317, 'default_policy/modified_reward_min': -5.066858249340451, 'default_policy/modified_reward_max': -0.7626326010404776, 'default_policy/corr_btw_rewards_mean': 0.5214781207498597, 'default_policy/corr_btw_rewards_min': 0.11133250935794216, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -17.16298878028648, 'true_reward_min': -63.61176406871194, 'true_reward_max': -0.7321320343559642, 'proxy_reward_mean': -1.3949887802864844, 'proxy_reward_min': -4.118540764008568, 'proxy_reward_max': -0.47142135623730974, 'modified_reward_mean': -1.9001018786744317, 'modified_reward_min': -5.066858249340451, 'modified_reward_max': -0.7626326010404776, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00030404145077720225, 'proxyInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03410822695784894, 'proxyLowerStageReward_min': -0.06417309658075468, 'proxyLowerStageReward_max': -0.017690225711777693, 'proxySmoothStageChangesReward_mean': -0.07766839378238342, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.00030404145077720225, 'trueInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.008169948186528499, 'truePoliticalReward_min': -0.03150259067357513, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03410822695784894, 'trueLowerStageReward_min': -0.06417309658075468, 'trueLowerStageReward_max': -0.017690225711777693, 'trueSmoothStageChangesReward_mean': -0.07766839378238342, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -1.9001018786744317, 'total_modified_reward_min': -5.066858249340451, 'total_modified_reward_max': -0.7626326010404776}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0689686705172061, 'cur_kl_coeff': 0.010546874999999999, 'cur_lr': 0.0003, 'total_loss': -0.001005339262386163, 'policy_loss': -0.005607489893833796, 'vf_loss': 0.03146831874386408, 'vf_explained_var': 0.46516406536102295, 'kl': 0.007895265863343, 'entropy': 0.31085855637987453, 'entropy_coeff': 0.036078400000000004}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 27750.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 358980, 'num_env_steps_trained': 358980, 'num_agent_steps_sampled': 358980, 'num_agent_steps_trained': 358980}, 'sampler_results': {'episode_reward_max': -0.7626326010404776, 'episode_reward_min': -5.066858249340451, 'episode_reward_mean': -1.9001018786744317, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -17.16298878028648, 'default_policy/true_reward_min': -63.61176406871194, 'default_policy/true_reward_max': -0.7321320343559642, 'default_policy/proxy_reward_mean': -1.3949887802864844, 'default_policy/proxy_reward_min': -4.118540764008568, 'default_policy/proxy_reward_max': -0.47142135623730974, 'default_policy/modified_reward_mean': -1.9001018786744317, 'default_policy/modified_reward_min': -5.066858249340451, 'default_policy/modified_reward_max': -0.7626326010404776, 'default_policy/corr_btw_rewards_mean': 0.5214781207498597, 'default_policy/corr_btw_rewards_min': 0.11133250935794216, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -17.16298878028648, 'true_reward_min': -63.61176406871194, 'true_reward_max': -0.7321320343559642, 'proxy_reward_mean': -1.3949887802864844, 'proxy_reward_min': -4.118540764008568, 'proxy_reward_max': -0.47142135623730974, 'modified_reward_mean': -1.9001018786744317, 'modified_reward_min': -5.066858249340451, 'modified_reward_max': -0.7626326010404776, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00030404145077720225, 'proxyInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03410822695784894, 'proxyLowerStageReward_min': -0.06417309658075468, 'proxyLowerStageReward_max': -0.017690225711777693, 'proxySmoothStageChangesReward_mean': -0.07766839378238342, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.00030404145077720225, 'trueInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.008169948186528499, 'truePoliticalReward_min': -0.03150259067357513, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03410822695784894, 'trueLowerStageReward_min': -0.06417309658075468, 'trueLowerStageReward_max': -0.017690225711777693, 'trueSmoothStageChangesReward_mean': -0.07766839378238342, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -1.9001018786744317, 'total_modified_reward_min': -5.066858249340451, 'total_modified_reward_max': -0.7626326010404776}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5358834198923209, 'mean_inference_ms': 1.6759749306949823, 'mean_action_processing_ms': 0.10670767907777957, 'mean_env_wait_ms': 740.158335684464, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.7626326010404776, 'episode_reward_min': -5.066858249340451, 'episode_reward_mean': -1.9001018786744317, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5358834198923209, 'mean_inference_ms': 1.6759749306949823, 'mean_action_processing_ms': 0.10670767907777957, 'mean_env_wait_ms': 740.158335684464, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 358980, 'num_agent_steps_trained': 358980, 'num_env_steps_sampled': 358980, 'num_env_steps_trained': 358980, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.442393693809207, 'num_env_steps_trained_throughput_per_sec': 13.442393693809207, 'timesteps_total': 358980, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 358980, 'timers': {'training_iteration_time_ms': 289120.971, 'sample_time_ms': 288130.352, 'load_time_ms': 4.629, 'load_throughput': 833913.489, 'learn_time_ms': 969.665, 'learn_throughput': 3980.758, 'synch_weights_time_ms': 15.559}, 'counters': {'num_env_steps_sampled': 358980, 'num_env_steps_trained': 358980, 'num_agent_steps_sampled': 358980, 'num_agent_steps_trained': 358980}, 'done': False, 'episodes_total': 1860, 'training_iteration': 93, 'trial_id': 'default', 'date': '2025-11-05_02-53-32', 'timestamp': 1762340012, 'time_this_iter_s': 287.1705105304718, 'time_total_s': 28830.913556098938, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a699562cb0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699561d50>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699561ff0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699563520>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 28830.913556098938, 'iterations_since_restore': 93, 'perf': {'cpu_util_percent': 20.488508557457216, 'ram_util_percent': 6.0}}
Iteration 94/100
{'custom_metrics': {'default_policy/true_reward_mean': -14.710460858225122, 'default_policy/true_reward_min': -63.61176406871194, 'default_policy/true_reward_max': -0.5642766952966369, 'default_policy/proxy_reward_mean': -1.4384608582251264, 'default_policy/proxy_reward_min': -4.118540764008568, 'default_policy/proxy_reward_max': -0.47142135623730974, 'default_policy/modified_reward_mean': -1.9325435650392, 'default_policy/modified_reward_min': -5.066858249340451, 'default_policy/modified_reward_max': -0.7626326010404776, 'default_policy/corr_btw_rewards_mean': 0.5028572222568468, 'default_policy/corr_btw_rewards_min': 0.11133250935794216, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -14.710460858225122, 'true_reward_min': -63.61176406871194, 'true_reward_max': -0.5642766952966369, 'proxy_reward_mean': -1.4384608582251264, 'proxy_reward_min': -4.118540764008568, 'proxy_reward_max': -0.47142135623730974, 'modified_reward_mean': -1.9325435650392, 'modified_reward_min': -5.066858249340451, 'modified_reward_max': -0.7626326010404776, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003338860103626945, 'proxyInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03375962995985112, 'proxyLowerStageReward_min': -0.06417309658075468, 'proxyLowerStageReward_max': -0.017690225711777693, 'proxySmoothStageChangesReward_mean': -0.07383419689119172, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003338860103626945, 'trueInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.006876683937823836, 'truePoliticalReward_min': -0.03150259067357513, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03375962995985112, 'trueLowerStageReward_min': -0.06417309658075468, 'trueLowerStageReward_max': -0.017690225711777693, 'trueSmoothStageChangesReward_mean': -0.07383419689119172, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -1.9325435650392, 'total_modified_reward_min': -5.066858249340451, 'total_modified_reward_max': -0.7626326010404776}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0125435383742054, 'cur_kl_coeff': 0.010546874999999999, 'cur_lr': 0.0003, 'total_loss': 0.0005316116979035238, 'policy_loss': -0.004573706875865658, 'vf_loss': 0.030620382004999554, 'vf_explained_var': 0.3857645946741104, 'kl': 0.007709413596485405, 'entropy': 0.29070476432641346, 'entropy_coeff': 0.03538359999999999}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 28050.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 362840, 'num_env_steps_trained': 362840, 'num_agent_steps_sampled': 362840, 'num_agent_steps_trained': 362840}, 'sampler_results': {'episode_reward_max': -0.7626326010404776, 'episode_reward_min': -5.066858249340451, 'episode_reward_mean': -1.9325435650392, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -14.710460858225122, 'default_policy/true_reward_min': -63.61176406871194, 'default_policy/true_reward_max': -0.5642766952966369, 'default_policy/proxy_reward_mean': -1.4384608582251264, 'default_policy/proxy_reward_min': -4.118540764008568, 'default_policy/proxy_reward_max': -0.47142135623730974, 'default_policy/modified_reward_mean': -1.9325435650392, 'default_policy/modified_reward_min': -5.066858249340451, 'default_policy/modified_reward_max': -0.7626326010404776, 'default_policy/corr_btw_rewards_mean': 0.5028572222568468, 'default_policy/corr_btw_rewards_min': 0.11133250935794216, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -14.710460858225122, 'true_reward_min': -63.61176406871194, 'true_reward_max': -0.5642766952966369, 'proxy_reward_mean': -1.4384608582251264, 'proxy_reward_min': -4.118540764008568, 'proxy_reward_max': -0.47142135623730974, 'modified_reward_mean': -1.9325435650392, 'modified_reward_min': -5.066858249340451, 'modified_reward_max': -0.7626326010404776, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003338860103626945, 'proxyInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03375962995985112, 'proxyLowerStageReward_min': -0.06417309658075468, 'proxyLowerStageReward_max': -0.017690225711777693, 'proxySmoothStageChangesReward_mean': -0.07383419689119172, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003338860103626945, 'trueInfectionSummaryAbsoluteReward_min': -0.0014818652849740942, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.006876683937823836, 'truePoliticalReward_min': -0.03150259067357513, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03375962995985112, 'trueLowerStageReward_min': -0.06417309658075468, 'trueLowerStageReward_max': -0.017690225711777693, 'trueSmoothStageChangesReward_mean': -0.07383419689119172, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -1.9325435650392, 'total_modified_reward_min': -5.066858249340451, 'total_modified_reward_max': -0.7626326010404776}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5355911481126776, 'mean_inference_ms': 1.675899653793212, 'mean_action_processing_ms': 0.10670593912604008, 'mean_env_wait_ms': 740.0220627219902, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.7626326010404776, 'episode_reward_min': -5.066858249340451, 'episode_reward_mean': -1.9325435650392, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5355911481126776, 'mean_inference_ms': 1.675899653793212, 'mean_action_processing_ms': 0.10670593912604008, 'mean_env_wait_ms': 740.0220627219902, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 362840, 'num_agent_steps_trained': 362840, 'num_env_steps_sampled': 362840, 'num_env_steps_trained': 362840, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.491232970774067, 'num_env_steps_trained_throughput_per_sec': 13.491232970774067, 'timesteps_total': 362840, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 362840, 'timers': {'training_iteration_time_ms': 288889.54, 'sample_time_ms': 287899.456, 'load_time_ms': 4.557, 'load_throughput': 847019.396, 'learn_time_ms': 969.784, 'learn_throughput': 3980.267, 'synch_weights_time_ms': 14.991}, 'counters': {'num_env_steps_sampled': 362840, 'num_env_steps_trained': 362840, 'num_agent_steps_sampled': 362840, 'num_agent_steps_trained': 362840}, 'done': False, 'episodes_total': 1880, 'training_iteration': 94, 'trial_id': 'default', 'date': '2025-11-05_02-58-18', 'timestamp': 1762340298, 'time_this_iter_s': 286.1308419704437, 'time_total_s': 29117.04439806938, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e1285900>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6a9cdb910>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e177a800>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e177bdf0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 29117.04439806938, 'iterations_since_restore': 94, 'perf': {'cpu_util_percent': 20.396332518337413, 'ram_util_percent': 6.0}}
Iteration 95/100
{'custom_metrics': {'default_policy/true_reward_mean': -15.098367838740462, 'default_policy/true_reward_min': -63.61176406871194, 'default_policy/true_reward_max': -0.5642766952966369, 'default_policy/proxy_reward_mean': -1.4463678387404661, 'default_policy/proxy_reward_min': -3.636053390593279, 'default_policy/proxy_reward_max': -0.501776695296637, 'default_policy/modified_reward_mean': -1.9426161924609788, 'default_policy/modified_reward_min': -4.276396385952356, 'default_policy/modified_reward_max': -0.8074445046182834, 'default_policy/corr_btw_rewards_mean': 0.49428706672066197, 'default_policy/corr_btw_rewards_min': 0.12571748980495198, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -15.098367838740462, 'true_reward_min': -63.61176406871194, 'true_reward_max': -0.5642766952966369, 'proxy_reward_mean': -1.4463678387404661, 'proxy_reward_min': -3.636053390593279, 'proxy_reward_max': -0.501776695296637, 'modified_reward_mean': -1.9426161924609788, 'modified_reward_min': -4.276396385952356, 'modified_reward_max': -0.8074445046182834, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00033678756476683954, 'proxyInfectionSummaryAbsoluteReward_min': -0.0013575129533678764, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03377553568603452, 'proxyLowerStageReward_min': -0.0640619742522224, 'proxyLowerStageReward_max': -0.017690225711777693, 'proxySmoothStageChangesReward_mean': -0.07487046632124353, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.00033678756476683954, 'trueInfectionSummaryAbsoluteReward_min': -0.0013575129533678764, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.0070735751295336775, 'truePoliticalReward_min': -0.03150259067357513, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03377553568603452, 'trueLowerStageReward_min': -0.0640619742522224, 'trueLowerStageReward_max': -0.017690225711777693, 'trueSmoothStageChangesReward_mean': -0.07487046632124353, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -1.9426161924609788, 'total_modified_reward_min': -4.276396385952356, 'total_modified_reward_max': -0.8074445046182834}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0886897823214532, 'cur_kl_coeff': 0.010546874999999999, 'cur_lr': 0.0003, 'total_loss': 0.005863681230694056, 'policy_loss': -0.0029140479365984597, 'vf_loss': 0.037638362059757735, 'vf_explained_var': 0.41603213250637056, 'kl': 0.006526068011999004, 'entropy': 0.29145659257968265, 'entropy_coeff': 0.034688799999999985}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 28350.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 366700, 'num_env_steps_trained': 366700, 'num_agent_steps_sampled': 366700, 'num_agent_steps_trained': 366700}, 'sampler_results': {'episode_reward_max': -0.8074445046182834, 'episode_reward_min': -4.276396385952356, 'episode_reward_mean': -1.9426161924609788, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -15.098367838740462, 'default_policy/true_reward_min': -63.61176406871194, 'default_policy/true_reward_max': -0.5642766952966369, 'default_policy/proxy_reward_mean': -1.4463678387404661, 'default_policy/proxy_reward_min': -3.636053390593279, 'default_policy/proxy_reward_max': -0.501776695296637, 'default_policy/modified_reward_mean': -1.9426161924609788, 'default_policy/modified_reward_min': -4.276396385952356, 'default_policy/modified_reward_max': -0.8074445046182834, 'default_policy/corr_btw_rewards_mean': 0.49428706672066197, 'default_policy/corr_btw_rewards_min': 0.12571748980495198, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -15.098367838740462, 'true_reward_min': -63.61176406871194, 'true_reward_max': -0.5642766952966369, 'proxy_reward_mean': -1.4463678387404661, 'proxy_reward_min': -3.636053390593279, 'proxy_reward_max': -0.501776695296637, 'modified_reward_mean': -1.9426161924609788, 'modified_reward_min': -4.276396385952356, 'modified_reward_max': -0.8074445046182834, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00033678756476683954, 'proxyInfectionSummaryAbsoluteReward_min': -0.0013575129533678764, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03377553568603452, 'proxyLowerStageReward_min': -0.0640619742522224, 'proxyLowerStageReward_max': -0.017690225711777693, 'proxySmoothStageChangesReward_mean': -0.07487046632124353, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.00033678756476683954, 'trueInfectionSummaryAbsoluteReward_min': -0.0013575129533678764, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.0070735751295336775, 'truePoliticalReward_min': -0.03150259067357513, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03377553568603452, 'trueLowerStageReward_min': -0.0640619742522224, 'trueLowerStageReward_max': -0.017690225711777693, 'trueSmoothStageChangesReward_mean': -0.07487046632124353, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -1.9426161924609788, 'total_modified_reward_min': -4.276396385952356, 'total_modified_reward_max': -0.8074445046182834}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5353308345296455, 'mean_inference_ms': 1.6757672401353971, 'mean_action_processing_ms': 0.10669934226491082, 'mean_env_wait_ms': 739.8525396776547, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.8074445046182834, 'episode_reward_min': -4.276396385952356, 'episode_reward_mean': -1.9426161924609788, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5353308345296455, 'mean_inference_ms': 1.6757672401353971, 'mean_action_processing_ms': 0.10669934226491082, 'mean_env_wait_ms': 739.8525396776547, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 366700, 'num_agent_steps_trained': 366700, 'num_env_steps_sampled': 366700, 'num_env_steps_trained': 366700, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.30571228181654, 'num_env_steps_trained_throughput_per_sec': 12.30571228181654, 'timesteps_total': 366700, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 366700, 'timers': {'training_iteration_time_ms': 291556.11, 'sample_time_ms': 290546.113, 'load_time_ms': 4.197, 'load_throughput': 919714.681, 'learn_time_ms': 989.804, 'learn_throughput': 3899.76, 'synch_weights_time_ms': 15.279}, 'counters': {'num_env_steps_sampled': 366700, 'num_env_steps_trained': 366700, 'num_agent_steps_sampled': 366700, 'num_agent_steps_trained': 366700}, 'done': False, 'episodes_total': 1900, 'training_iteration': 95, 'trial_id': 'default', 'date': '2025-11-05_03-03-32', 'timestamp': 1762340612, 'time_this_iter_s': 313.6968855857849, 'time_total_s': 29430.741283655167, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a688215030>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a688214d90>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e1285e40>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e1286fb0>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 29430.741283655167, 'iterations_since_restore': 95, 'perf': {'cpu_util_percent': 13.144843049327354, 'ram_util_percent': 6.0}}
Iteration 96/100
{'custom_metrics': {'default_policy/true_reward_mean': -12.925410858225122, 'default_policy/true_reward_min': -45.10534271247463, 'default_policy/true_reward_max': -0.5196320343559644, 'default_policy/proxy_reward_mean': -1.4094108582251268, 'default_policy/proxy_reward_min': -3.636053390593279, 'default_policy/proxy_reward_max': -0.501776695296637, 'default_policy/modified_reward_mean': -1.8948948537332355, 'default_policy/modified_reward_min': -4.276396385952356, 'default_policy/modified_reward_max': -0.8074445046182834, 'default_policy/corr_btw_rewards_mean': 0.4991198733656684, 'default_policy/corr_btw_rewards_min': 0.12571748980495198, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -12.925410858225122, 'true_reward_min': -45.10534271247463, 'true_reward_max': -0.5196320343559644, 'proxy_reward_mean': -1.4094108582251268, 'proxy_reward_min': -3.636053390593279, 'proxy_reward_max': -0.501776695296637, 'modified_reward_mean': -1.8948948537332355, 'modified_reward_min': -4.276396385952356, 'modified_reward_max': -0.8074445046182834, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00032704663212435243, 'proxyInfectionSummaryAbsoluteReward_min': -0.0013575129533678764, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.032943567783685325, 'proxyLowerStageReward_min': -0.0640619742522224, 'proxyLowerStageReward_max': -0.017690225711777693, 'proxySmoothStageChangesReward_mean': -0.07378238341968912, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.00032704663212435243, 'trueInfectionSummaryAbsoluteReward_min': -0.0013575129533678764, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.0059668393782383415, 'truePoliticalReward_min': -0.02259067357512953, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.032943567783685325, 'trueLowerStageReward_min': -0.0640619742522224, 'trueLowerStageReward_max': -0.017690225711777693, 'trueSmoothStageChangesReward_mean': -0.07378238341968912, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -1.8948948537332355, 'total_modified_reward_min': -4.276396385952356, 'total_modified_reward_max': -0.8074445046182834}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.7534251055121421, 'cur_kl_coeff': 0.010546874999999999, 'cur_lr': 0.0003, 'total_loss': -0.004219640675000846, 'policy_loss': -0.004141471879556775, 'vf_loss': 0.019257349354593317, 'vf_explained_var': 0.43251704235871635, 'kl': 0.004453488049168748, 'entropy': 0.2869275072713693, 'entropy_coeff': 0.03399399999999999}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 28650.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 370560, 'num_env_steps_trained': 370560, 'num_agent_steps_sampled': 370560, 'num_agent_steps_trained': 370560}, 'sampler_results': {'episode_reward_max': -0.8074445046182834, 'episode_reward_min': -4.276396385952356, 'episode_reward_mean': -1.8948948537332355, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -12.925410858225122, 'default_policy/true_reward_min': -45.10534271247463, 'default_policy/true_reward_max': -0.5196320343559644, 'default_policy/proxy_reward_mean': -1.4094108582251268, 'default_policy/proxy_reward_min': -3.636053390593279, 'default_policy/proxy_reward_max': -0.501776695296637, 'default_policy/modified_reward_mean': -1.8948948537332355, 'default_policy/modified_reward_min': -4.276396385952356, 'default_policy/modified_reward_max': -0.8074445046182834, 'default_policy/corr_btw_rewards_mean': 0.4991198733656684, 'default_policy/corr_btw_rewards_min': 0.12571748980495198, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -12.925410858225122, 'true_reward_min': -45.10534271247463, 'true_reward_max': -0.5196320343559644, 'proxy_reward_mean': -1.4094108582251268, 'proxy_reward_min': -3.636053390593279, 'proxy_reward_max': -0.501776695296637, 'modified_reward_mean': -1.8948948537332355, 'modified_reward_min': -4.276396385952356, 'modified_reward_max': -0.8074445046182834, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00032704663212435243, 'proxyInfectionSummaryAbsoluteReward_min': -0.0013575129533678764, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.032943567783685325, 'proxyLowerStageReward_min': -0.0640619742522224, 'proxyLowerStageReward_max': -0.017690225711777693, 'proxySmoothStageChangesReward_mean': -0.07378238341968912, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.00032704663212435243, 'trueInfectionSummaryAbsoluteReward_min': -0.0013575129533678764, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.0059668393782383415, 'truePoliticalReward_min': -0.02259067357512953, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.032943567783685325, 'trueLowerStageReward_min': -0.0640619742522224, 'trueLowerStageReward_max': -0.017690225711777693, 'trueSmoothStageChangesReward_mean': -0.07378238341968912, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -1.8948948537332355, 'total_modified_reward_min': -4.276396385952356, 'total_modified_reward_max': -0.8074445046182834}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5350338402068415, 'mean_inference_ms': 1.6754534632550486, 'mean_action_processing_ms': 0.10668541833442624, 'mean_env_wait_ms': 739.5727304448939, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.8074445046182834, 'episode_reward_min': -4.276396385952356, 'episode_reward_mean': -1.8948948537332355, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5350338402068415, 'mean_inference_ms': 1.6754534632550486, 'mean_action_processing_ms': 0.10668541833442624, 'mean_env_wait_ms': 739.5727304448939, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 370560, 'num_agent_steps_trained': 370560, 'num_env_steps_sampled': 370560, 'num_env_steps_trained': 370560, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 12.941761529133707, 'num_env_steps_trained_throughput_per_sec': 12.941761529133707, 'timesteps_total': 370560, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 370560, 'timers': {'training_iteration_time_ms': 292878.518, 'sample_time_ms': 291847.081, 'load_time_ms': 4.287, 'load_throughput': 900460.711, 'learn_time_ms': 1010.939, 'learn_throughput': 3818.234, 'synch_weights_time_ms': 15.505}, 'counters': {'num_env_steps_sampled': 370560, 'num_env_steps_trained': 370560, 'num_agent_steps_sampled': 370560, 'num_agent_steps_trained': 370560}, 'done': False, 'episodes_total': 1920, 'training_iteration': 96, 'trial_id': 'default', 'date': '2025-11-05_03-08-31', 'timestamp': 1762340911, 'time_this_iter_s': 298.27852153778076, 'time_total_s': 29729.019805192947, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e1284fa0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a5e2511870>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699563d60>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a699560820>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 29729.019805192947, 'iterations_since_restore': 96, 'perf': {'cpu_util_percent': 9.532159624413147, 'ram_util_percent': 5.262676056338028}}
Iteration 97/100
{'custom_metrics': {'default_policy/true_reward_mean': -12.697236363288512, 'default_policy/true_reward_min': -65.25676406871196, 'default_policy/true_reward_max': -0.5196320343559644, 'default_policy/proxy_reward_mean': -1.3772363632885147, 'default_policy/proxy_reward_min': -3.8749747468305817, 'default_policy/proxy_reward_max': -0.501776695296637, 'default_policy/modified_reward_mean': -1.8500688292874423, 'default_policy/modified_reward_min': -4.759783978019843, 'default_policy/modified_reward_max': -0.8074445046182834, 'default_policy/corr_btw_rewards_mean': 0.4962475793614965, 'default_policy/corr_btw_rewards_min': 0.12571748980495198, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -12.697236363288512, 'true_reward_min': -65.25676406871196, 'true_reward_max': -0.5196320343559644, 'proxy_reward_mean': -1.3772363632885147, 'proxy_reward_min': -3.8749747468305817, 'proxy_reward_max': -0.501776695296637, 'modified_reward_mean': -1.8500688292874423, 'modified_reward_min': -4.759783978019843, 'modified_reward_max': -0.8074445046182834, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00032093264248704676, 'proxyInfectionSummaryAbsoluteReward_min': -0.0013575129533678764, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03207442296831684, 'proxyLowerStageReward_min': -0.0640619742522224, 'proxyLowerStageReward_max': -0.017690225711777696, 'proxySmoothStageChangesReward_mean': -0.07191709844559586, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.00032093264248704676, 'trueInfectionSummaryAbsoluteReward_min': -0.0013575129533678764, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.0058652849740932645, 'truePoliticalReward_min': -0.03295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03207442296831684, 'trueLowerStageReward_min': -0.0640619742522224, 'trueLowerStageReward_max': -0.017690225711777696, 'trueSmoothStageChangesReward_mean': -0.07191709844559586, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -1.8500688292874423, 'total_modified_reward_min': -4.759783978019843, 'total_modified_reward_max': -0.8074445046182834}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.900287476554513, 'cur_kl_coeff': 0.0052734374999999995, 'cur_lr': 0.0003, 'total_loss': 7.048151766260465e-05, 'policy_loss': -0.0034203916198263565, 'vf_loss': 0.027050930185941978, 'vf_explained_var': 0.35398967246214547, 'kl': 0.003793395378344133, 'entropy': 0.30194702913363775, 'entropy_coeff': 0.0332992}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 28950.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 374420, 'num_env_steps_trained': 374420, 'num_agent_steps_sampled': 374420, 'num_agent_steps_trained': 374420}, 'sampler_results': {'episode_reward_max': -0.8074445046182834, 'episode_reward_min': -4.759783978019843, 'episode_reward_mean': -1.8500688292874423, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -12.697236363288512, 'default_policy/true_reward_min': -65.25676406871196, 'default_policy/true_reward_max': -0.5196320343559644, 'default_policy/proxy_reward_mean': -1.3772363632885147, 'default_policy/proxy_reward_min': -3.8749747468305817, 'default_policy/proxy_reward_max': -0.501776695296637, 'default_policy/modified_reward_mean': -1.8500688292874423, 'default_policy/modified_reward_min': -4.759783978019843, 'default_policy/modified_reward_max': -0.8074445046182834, 'default_policy/corr_btw_rewards_mean': 0.4962475793614965, 'default_policy/corr_btw_rewards_min': 0.12571748980495198, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -12.697236363288512, 'true_reward_min': -65.25676406871196, 'true_reward_max': -0.5196320343559644, 'proxy_reward_mean': -1.3772363632885147, 'proxy_reward_min': -3.8749747468305817, 'proxy_reward_max': -0.501776695296637, 'modified_reward_mean': -1.8500688292874423, 'modified_reward_min': -4.759783978019843, 'modified_reward_max': -0.8074445046182834, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00032093264248704676, 'proxyInfectionSummaryAbsoluteReward_min': -0.0013575129533678764, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03207442296831684, 'proxyLowerStageReward_min': -0.0640619742522224, 'proxyLowerStageReward_max': -0.017690225711777696, 'proxySmoothStageChangesReward_mean': -0.07191709844559586, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.031088082901554404, 'trueInfectionSummaryAbsoluteReward_mean': -0.00032093264248704676, 'trueInfectionSummaryAbsoluteReward_min': -0.0013575129533678764, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.0058652849740932645, 'truePoliticalReward_min': -0.03295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03207442296831684, 'trueLowerStageReward_min': -0.0640619742522224, 'trueLowerStageReward_max': -0.017690225711777696, 'trueSmoothStageChangesReward_mean': -0.07191709844559586, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.031088082901554404, 'total_modified_reward_mean': -1.8500688292874423, 'total_modified_reward_min': -4.759783978019843, 'total_modified_reward_max': -0.8074445046182834}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5346828702015394, 'mean_inference_ms': 1.6749765978763957, 'mean_action_processing_ms': 0.10666942486889798, 'mean_env_wait_ms': 739.2569591450804, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.8074445046182834, 'episode_reward_min': -4.759783978019843, 'episode_reward_mean': -1.8500688292874423, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5346828702015394, 'mean_inference_ms': 1.6749765978763957, 'mean_action_processing_ms': 0.10666942486889798, 'mean_env_wait_ms': 739.2569591450804, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 374420, 'num_agent_steps_trained': 374420, 'num_env_steps_sampled': 374420, 'num_env_steps_trained': 374420, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.837238356586393, 'num_env_steps_trained_throughput_per_sec': 13.837238356586393, 'timesteps_total': 374420, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 374420, 'timers': {'training_iteration_time_ms': 290835.932, 'sample_time_ms': 289805.288, 'load_time_ms': 4.199, 'load_throughput': 919359.54, 'learn_time_ms': 1010.075, 'learn_throughput': 3821.498, 'synch_weights_time_ms': 15.668}, 'counters': {'num_env_steps_sampled': 374420, 'num_env_steps_trained': 374420, 'num_agent_steps_sampled': 374420, 'num_agent_steps_trained': 374420}, 'done': False, 'episodes_total': 1940, 'training_iteration': 97, 'trial_id': 'default', 'date': '2025-11-05_03-13-10', 'timestamp': 1762341190, 'time_this_iter_s': 278.9739315509796, 'time_total_s': 30007.993736743927, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a699563550>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699782b00>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2510ee0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2510670>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 30007.993736743927, 'iterations_since_restore': 97, 'perf': {'cpu_util_percent': 10.265239294710328, 'ram_util_percent': 3.6000000000000005}}
Iteration 98/100
{'custom_metrics': {'default_policy/true_reward_mean': -15.226172149726139, 'default_policy/true_reward_min': -65.25676406871196, 'default_policy/true_reward_max': -0.5196320343559644, 'default_policy/proxy_reward_mean': -1.3581721497261419, 'default_policy/proxy_reward_min': -4.116053390593276, 'default_policy/proxy_reward_max': -0.501776695296637, 'default_policy/modified_reward_mean': -1.821435389099717, 'default_policy/modified_reward_min': -4.759783978019843, 'default_policy/modified_reward_max': -0.8185756884896843, 'default_policy/corr_btw_rewards_mean': 0.49687343760867014, 'default_policy/corr_btw_rewards_min': 0.12571748980495198, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -15.226172149726139, 'true_reward_min': -65.25676406871196, 'true_reward_max': -0.5196320343559644, 'proxy_reward_mean': -1.3581721497261419, 'proxy_reward_min': -4.116053390593276, 'proxy_reward_max': -0.501776695296637, 'modified_reward_mean': -1.821435389099717, 'modified_reward_min': -4.759783978019843, 'modified_reward_max': -0.8185756884896843, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003216580310880831, 'proxyInfectionSummaryAbsoluteReward_min': -0.0016683937823834209, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.030848297913271604, 'proxyLowerStageReward_min': -0.061915789991221916, 'proxyLowerStageReward_max': -0.015636098201898284, 'proxySmoothStageChangesReward_mean': -0.07357512953367877, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003216580310880831, 'trueInfectionSummaryAbsoluteReward_min': -0.0016683937823834209, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.007185492227979274, 'truePoliticalReward_min': -0.03295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.030848297913271604, 'trueLowerStageReward_min': -0.061915789991221916, 'trueLowerStageReward_max': -0.015636098201898284, 'trueSmoothStageChangesReward_mean': -0.07357512953367877, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -1.821435389099717, 'total_modified_reward_min': -4.759783978019843, 'total_modified_reward_max': -0.8185756884896843}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.0471711239218713, 'cur_kl_coeff': 0.0026367187499999997, 'cur_lr': 0.0003, 'total_loss': 0.004761321542270404, 'policy_loss': -0.0005383094493299723, 'vf_loss': 0.030459637039505955, 'vf_explained_var': 0.3272098795572917, 'kl': 0.007686437022327794, 'entropy': 0.305187454521656, 'entropy_coeff': 0.032604400000000006}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 29250.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 378280, 'num_env_steps_trained': 378280, 'num_agent_steps_sampled': 378280, 'num_agent_steps_trained': 378280}, 'sampler_results': {'episode_reward_max': -0.8185756884896843, 'episode_reward_min': -4.759783978019843, 'episode_reward_mean': -1.821435389099717, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -15.226172149726139, 'default_policy/true_reward_min': -65.25676406871196, 'default_policy/true_reward_max': -0.5196320343559644, 'default_policy/proxy_reward_mean': -1.3581721497261419, 'default_policy/proxy_reward_min': -4.116053390593276, 'default_policy/proxy_reward_max': -0.501776695296637, 'default_policy/modified_reward_mean': -1.821435389099717, 'default_policy/modified_reward_min': -4.759783978019843, 'default_policy/modified_reward_max': -0.8185756884896843, 'default_policy/corr_btw_rewards_mean': 0.49687343760867014, 'default_policy/corr_btw_rewards_min': 0.12571748980495198, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -15.226172149726139, 'true_reward_min': -65.25676406871196, 'true_reward_max': -0.5196320343559644, 'proxy_reward_mean': -1.3581721497261419, 'proxy_reward_min': -4.116053390593276, 'proxy_reward_max': -0.501776695296637, 'modified_reward_mean': -1.821435389099717, 'modified_reward_min': -4.759783978019843, 'modified_reward_max': -0.8185756884896843, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0003216580310880831, 'proxyInfectionSummaryAbsoluteReward_min': -0.0016683937823834209, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.030848297913271604, 'proxyLowerStageReward_min': -0.061915789991221916, 'proxyLowerStageReward_max': -0.015636098201898284, 'proxySmoothStageChangesReward_mean': -0.07357512953367877, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0003216580310880831, 'trueInfectionSummaryAbsoluteReward_min': -0.0016683937823834209, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.007185492227979274, 'truePoliticalReward_min': -0.03295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.030848297913271604, 'trueLowerStageReward_min': -0.061915789991221916, 'trueLowerStageReward_max': -0.015636098201898284, 'trueSmoothStageChangesReward_mean': -0.07357512953367877, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -1.821435389099717, 'total_modified_reward_min': -4.759783978019843, 'total_modified_reward_max': -0.8185756884896843}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5342839343644102, 'mean_inference_ms': 1.6743121337013576, 'mean_action_processing_ms': 0.10666318200349827, 'mean_env_wait_ms': 738.8844296867703, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.8185756884896843, 'episode_reward_min': -4.759783978019843, 'episode_reward_mean': -1.821435389099717, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5342839343644102, 'mean_inference_ms': 1.6743121337013576, 'mean_action_processing_ms': 0.10666318200349827, 'mean_env_wait_ms': 738.8844296867703, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 378280, 'num_agent_steps_trained': 378280, 'num_env_steps_sampled': 378280, 'num_env_steps_trained': 378280, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.899523738494395, 'num_env_steps_trained_throughput_per_sec': 13.899523738494395, 'timesteps_total': 378280, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 378280, 'timers': {'training_iteration_time_ms': 289821.078, 'sample_time_ms': 288781.695, 'load_time_ms': 4.6, 'load_throughput': 839091.224, 'learn_time_ms': 1018.464, 'learn_throughput': 3790.02, 'synch_weights_time_ms': 15.594}, 'counters': {'num_env_steps_sampled': 378280, 'num_env_steps_trained': 378280, 'num_agent_steps_sampled': 378280, 'num_agent_steps_trained': 378280}, 'done': False, 'episodes_total': 1960, 'training_iteration': 98, 'trial_id': 'default', 'date': '2025-11-05_03-17-48', 'timestamp': 1762341468, 'time_this_iter_s': 277.72634983062744, 'time_total_s': 30285.720086574554, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a699613ac0>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6996114b0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e24f8e50>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e24f9c90>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 30285.720086574554, 'iterations_since_restore': 98, 'perf': {'cpu_util_percent': 10.242569269521411, 'ram_util_percent': 3.6000000000000005}}
Iteration 99/100
{'custom_metrics': {'default_policy/true_reward_mean': -17.623300071787497, 'default_policy/true_reward_min': -65.25676406871196, 'default_policy/true_reward_max': -0.5196320343559644, 'default_policy/proxy_reward_mean': -1.3273000717875, 'default_policy/proxy_reward_min': -4.116053390593276, 'default_policy/proxy_reward_max': -0.45177669529663705, 'default_policy/modified_reward_mean': -1.7956768969922365, 'default_policy/modified_reward_min': -4.759783978019843, 'default_policy/modified_reward_max': -0.7415956525977341, 'default_policy/corr_btw_rewards_mean': 0.5399958169061579, 'default_policy/corr_btw_rewards_min': 0.13981156361002905, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -17.623300071787497, 'true_reward_min': -65.25676406871196, 'true_reward_max': -0.5196320343559644, 'proxy_reward_mean': -1.3273000717875, 'proxy_reward_min': -4.116053390593276, 'proxy_reward_max': -0.45177669529663705, 'modified_reward_mean': -1.7956768969922365, 'modified_reward_min': -4.759783978019843, 'modified_reward_max': -0.7415956525977341, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00030331606217616594, 'proxyInfectionSummaryAbsoluteReward_min': -0.0016683937823834209, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.030782387139248694, 'proxyLowerStageReward_min': -0.061915789991221916, 'proxyLowerStageReward_max': -0.015636098201898284, 'proxySmoothStageChangesReward_mean': -0.07658031088082902, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00030331606217616594, 'trueInfectionSummaryAbsoluteReward_min': -0.0016683937823834209, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.008443523316062178, 'truePoliticalReward_min': -0.03295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.030782387139248694, 'trueLowerStageReward_min': -0.061915789991221916, 'trueLowerStageReward_max': -0.015636098201898284, 'trueSmoothStageChangesReward_mean': -0.07658031088082902, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -1.7956768969922365, 'total_modified_reward_min': -4.759783978019843, 'total_modified_reward_max': -0.7415956525977341}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.8618447217841944, 'cur_kl_coeff': 0.0026367187499999997, 'cur_lr': 0.0003, 'total_loss': -0.0015816208285590013, 'policy_loss': -0.005060543430348238, 'vf_loss': 0.02859323648289622, 'vf_explained_var': 0.5624464801947275, 'kl': 0.013998303647072535, 'entropy': 0.3401674122114976, 'entropy_coeff': 0.03190959999999999}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 29550.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 382140, 'num_env_steps_trained': 382140, 'num_agent_steps_sampled': 382140, 'num_agent_steps_trained': 382140}, 'sampler_results': {'episode_reward_max': -0.7415956525977341, 'episode_reward_min': -4.759783978019843, 'episode_reward_mean': -1.7956768969922365, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -17.623300071787497, 'default_policy/true_reward_min': -65.25676406871196, 'default_policy/true_reward_max': -0.5196320343559644, 'default_policy/proxy_reward_mean': -1.3273000717875, 'default_policy/proxy_reward_min': -4.116053390593276, 'default_policy/proxy_reward_max': -0.45177669529663705, 'default_policy/modified_reward_mean': -1.7956768969922365, 'default_policy/modified_reward_min': -4.759783978019843, 'default_policy/modified_reward_max': -0.7415956525977341, 'default_policy/corr_btw_rewards_mean': 0.5399958169061579, 'default_policy/corr_btw_rewards_min': 0.13981156361002905, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -17.623300071787497, 'true_reward_min': -65.25676406871196, 'true_reward_max': -0.5196320343559644, 'proxy_reward_mean': -1.3273000717875, 'proxy_reward_min': -4.116053390593276, 'proxy_reward_max': -0.45177669529663705, 'modified_reward_mean': -1.7956768969922365, 'modified_reward_min': -4.759783978019843, 'modified_reward_max': -0.7415956525977341, 'proxyInfectionSummaryAbsoluteReward_mean': -0.00030331606217616594, 'proxyInfectionSummaryAbsoluteReward_min': -0.0016683937823834209, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.030782387139248694, 'proxyLowerStageReward_min': -0.061915789991221916, 'proxyLowerStageReward_max': -0.015636098201898284, 'proxySmoothStageChangesReward_mean': -0.07658031088082902, 'proxySmoothStageChangesReward_min': -0.14507772020725387, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.00030331606217616594, 'trueInfectionSummaryAbsoluteReward_min': -0.0016683937823834209, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.008443523316062178, 'truePoliticalReward_min': -0.03295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.030782387139248694, 'trueLowerStageReward_min': -0.061915789991221916, 'trueLowerStageReward_max': -0.015636098201898284, 'trueSmoothStageChangesReward_mean': -0.07658031088082902, 'trueSmoothStageChangesReward_min': -0.14507772020725387, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -1.7956768969922365, 'total_modified_reward_min': -4.759783978019843, 'total_modified_reward_max': -0.7415956525977341}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5338483948488008, 'mean_inference_ms': 1.6734631077110629, 'mean_action_processing_ms': 0.10665420913670012, 'mean_env_wait_ms': 738.4645414507415, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.7415956525977341, 'episode_reward_min': -4.759783978019843, 'episode_reward_mean': -1.7956768969922365, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5338483948488008, 'mean_inference_ms': 1.6734631077110629, 'mean_action_processing_ms': 0.10665420913670012, 'mean_env_wait_ms': 738.4645414507415, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 382140, 'num_agent_steps_trained': 382140, 'num_env_steps_sampled': 382140, 'num_env_steps_trained': 382140, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.764950936985894, 'num_env_steps_trained_throughput_per_sec': 13.764950936985894, 'timesteps_total': 382140, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 382140, 'timers': {'training_iteration_time_ms': 288777.423, 'sample_time_ms': 287723.899, 'load_time_ms': 4.892, 'load_throughput': 789048.534, 'learn_time_ms': 1032.211, 'learn_throughput': 3739.547, 'synch_weights_time_ms': 15.692}, 'counters': {'num_env_steps_sampled': 382140, 'num_env_steps_trained': 382140, 'num_agent_steps_sampled': 382140, 'num_agent_steps_trained': 382140}, 'done': False, 'episodes_total': 1980, 'training_iteration': 99, 'trial_id': 'default', 'date': '2025-11-05_03-22-28', 'timestamp': 1762341748, 'time_this_iter_s': 280.44724345207214, 'time_total_s': 30566.167330026627, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a699536620>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a699534880>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e24f80d0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a6a9cdb970>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 30566.167330026627, 'iterations_since_restore': 99, 'perf': {'cpu_util_percent': 10.047869674185465, 'ram_util_percent': 3.6000000000000014}}
Iteration 100/100
{'custom_metrics': {'default_policy/true_reward_mean': -19.192696013333517, 'default_policy/true_reward_min': -65.25676406871196, 'default_policy/true_reward_max': -0.5196320343559644, 'default_policy/proxy_reward_mean': -1.288696013333518, 'default_policy/proxy_reward_min': -4.116053390593276, 'default_policy/proxy_reward_max': -0.45177669529663705, 'default_policy/modified_reward_mean': -1.767437937064073, 'default_policy/modified_reward_min': -4.759783978019843, 'default_policy/modified_reward_max': -0.7415956525977341, 'default_policy/corr_btw_rewards_mean': 0.5205272384721138, 'default_policy/corr_btw_rewards_min': 0.16998096891723033, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -19.192696013333517, 'true_reward_min': -65.25676406871196, 'true_reward_max': -0.5196320343559644, 'proxy_reward_mean': -1.288696013333518, 'proxy_reward_min': -4.116053390593276, 'proxy_reward_max': -0.45177669529663705, 'modified_reward_mean': -1.767437937064073, 'modified_reward_min': -4.759783978019843, 'modified_reward_max': -0.7415956525977341, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002751295336787566, 'proxyInfectionSummaryAbsoluteReward_min': -0.0016683937823834209, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03139357582038955, 'proxyLowerStageReward_min': -0.061915789991221916, 'proxyLowerStageReward_max': -0.015636098201898284, 'proxySmoothStageChangesReward_mean': -0.07865284974093265, 'proxySmoothStageChangesReward_min': -0.15544041450777202, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002751295336787566, 'trueInfectionSummaryAbsoluteReward_min': -0.0016683937823834209, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.009276683937823833, 'truePoliticalReward_min': -0.03295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03139357582038955, 'trueLowerStageReward_min': -0.061915789991221916, 'trueLowerStageReward_max': -0.015636098201898284, 'trueSmoothStageChangesReward_mean': -0.07865284974093265, 'trueSmoothStageChangesReward_min': -0.15544041450777202, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -1.767437937064073, 'total_modified_reward_min': -4.759783978019843, 'total_modified_reward_max': -0.7415956525977341}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9700549560909469, 'cur_kl_coeff': 0.0026367187499999997, 'cur_lr': 0.0003, 'total_loss': -0.0023131495465834938, 'policy_loss': -0.00458836168050766, 'vf_loss': 0.027084951060047994, 'vf_explained_var': 0.3360250655810038, 'kl': 0.00760497481445699, 'entropy': 0.36160135969519613, 'entropy_coeff': 0.031214799999999994}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 29850.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 386000, 'num_env_steps_trained': 386000, 'num_agent_steps_sampled': 386000, 'num_agent_steps_trained': 386000}, 'sampler_results': {'episode_reward_max': -0.7415956525977341, 'episode_reward_min': -4.759783978019843, 'episode_reward_mean': -1.767437937064073, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -19.192696013333517, 'default_policy/true_reward_min': -65.25676406871196, 'default_policy/true_reward_max': -0.5196320343559644, 'default_policy/proxy_reward_mean': -1.288696013333518, 'default_policy/proxy_reward_min': -4.116053390593276, 'default_policy/proxy_reward_max': -0.45177669529663705, 'default_policy/modified_reward_mean': -1.767437937064073, 'default_policy/modified_reward_min': -4.759783978019843, 'default_policy/modified_reward_max': -0.7415956525977341, 'default_policy/corr_btw_rewards_mean': 0.5205272384721138, 'default_policy/corr_btw_rewards_min': 0.16998096891723033, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -19.192696013333517, 'true_reward_min': -65.25676406871196, 'true_reward_max': -0.5196320343559644, 'proxy_reward_mean': -1.288696013333518, 'proxy_reward_min': -4.116053390593276, 'proxy_reward_max': -0.45177669529663705, 'modified_reward_mean': -1.767437937064073, 'modified_reward_min': -4.759783978019843, 'modified_reward_max': -0.7415956525977341, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002751295336787566, 'proxyInfectionSummaryAbsoluteReward_min': -0.0016683937823834209, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03139357582038955, 'proxyLowerStageReward_min': -0.061915789991221916, 'proxyLowerStageReward_max': -0.015636098201898284, 'proxySmoothStageChangesReward_mean': -0.07865284974093265, 'proxySmoothStageChangesReward_min': -0.15544041450777202, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002751295336787566, 'trueInfectionSummaryAbsoluteReward_min': -0.0016683937823834209, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.009276683937823833, 'truePoliticalReward_min': -0.03295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03139357582038955, 'trueLowerStageReward_min': -0.061915789991221916, 'trueLowerStageReward_max': -0.015636098201898284, 'trueSmoothStageChangesReward_mean': -0.07865284974093265, 'trueSmoothStageChangesReward_min': -0.15544041450777202, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -1.767437937064073, 'total_modified_reward_min': -4.759783978019843, 'total_modified_reward_max': -0.7415956525977341}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5335676926843235, 'mean_inference_ms': 1.6724224931281872, 'mean_action_processing_ms': 0.10664043546480263, 'mean_env_wait_ms': 738.0382413958926, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.7415956525977341, 'episode_reward_min': -4.759783978019843, 'episode_reward_mean': -1.767437937064073, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5335676926843235, 'mean_inference_ms': 1.6724224931281872, 'mean_action_processing_ms': 0.10664043546480263, 'mean_env_wait_ms': 738.0382413958926, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 386000, 'num_agent_steps_trained': 386000, 'num_env_steps_sampled': 386000, 'num_env_steps_trained': 386000, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.592076829534166, 'num_env_steps_trained_throughput_per_sec': 13.592076829534166, 'timesteps_total': 386000, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 386000, 'timers': {'training_iteration_time_ms': 288613.9, 'sample_time_ms': 287516.047, 'load_time_ms': 5.098, 'load_throughput': 757122.909, 'learn_time_ms': 1076.133, 'learn_throughput': 3586.917, 'synch_weights_time_ms': 15.868}, 'counters': {'num_env_steps_sampled': 386000, 'num_env_steps_trained': 386000, 'num_agent_steps_sampled': 386000, 'num_agent_steps_trained': 386000}, 'done': False, 'episodes_total': 2000, 'training_iteration': 100, 'trial_id': 'default', 'date': '2025-11-05_03-27-12', 'timestamp': 1762342032, 'time_this_iter_s': 284.0148551464081, 'time_total_s': 30850.182185173035, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e2512680>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6997839a0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2512fe0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2513460>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 30850.182185173035, 'iterations_since_restore': 100, 'perf': {'cpu_util_percent': 9.950985221674877, 'ram_util_percent': 3.6000000000000014}}
Training completed!
Saved final checkpoint to TrainingResult(checkpoint=Checkpoint(filesystem=local, path=logs/data/pandemic/20251104_185246/checkpoint_99), metrics={'custom_metrics': {'default_policy/true_reward_mean': -19.192696013333517, 'default_policy/true_reward_min': -65.25676406871196, 'default_policy/true_reward_max': -0.5196320343559644, 'default_policy/proxy_reward_mean': -1.288696013333518, 'default_policy/proxy_reward_min': -4.116053390593276, 'default_policy/proxy_reward_max': -0.45177669529663705, 'default_policy/modified_reward_mean': -1.767437937064073, 'default_policy/modified_reward_min': -4.759783978019843, 'default_policy/modified_reward_max': -0.7415956525977341, 'default_policy/corr_btw_rewards_mean': 0.5205272384721138, 'default_policy/corr_btw_rewards_min': 0.16998096891723033, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -19.192696013333517, 'true_reward_min': -65.25676406871196, 'true_reward_max': -0.5196320343559644, 'proxy_reward_mean': -1.288696013333518, 'proxy_reward_min': -4.116053390593276, 'proxy_reward_max': -0.45177669529663705, 'modified_reward_mean': -1.767437937064073, 'modified_reward_min': -4.759783978019843, 'modified_reward_max': -0.7415956525977341, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002751295336787566, 'proxyInfectionSummaryAbsoluteReward_min': -0.0016683937823834209, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03139357582038955, 'proxyLowerStageReward_min': -0.061915789991221916, 'proxyLowerStageReward_max': -0.015636098201898284, 'proxySmoothStageChangesReward_mean': -0.07865284974093265, 'proxySmoothStageChangesReward_min': -0.15544041450777202, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002751295336787566, 'trueInfectionSummaryAbsoluteReward_min': -0.0016683937823834209, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.009276683937823833, 'truePoliticalReward_min': -0.03295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03139357582038955, 'trueLowerStageReward_min': -0.061915789991221916, 'trueLowerStageReward_max': -0.015636098201898284, 'trueSmoothStageChangesReward_mean': -0.07865284974093265, 'trueSmoothStageChangesReward_min': -0.15544041450777202, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -1.767437937064073, 'total_modified_reward_min': -4.759783978019843, 'total_modified_reward_max': -0.7415956525977341}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 0.9700549560909469, 'cur_kl_coeff': 0.0026367187499999997, 'cur_lr': 0.0003, 'total_loss': -0.0023131495465834938, 'policy_loss': -0.00458836168050766, 'vf_loss': 0.027084951060047994, 'vf_explained_var': 0.3360250655810038, 'kl': 0.00760497481445699, 'entropy': 0.36160135969519613, 'entropy_coeff': 0.031214799999999994}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 29850.5, 'diff_num_grad_updates_vs_sampler_policy': 149.5}}, 'num_env_steps_sampled': 386000, 'num_env_steps_trained': 386000, 'num_agent_steps_sampled': 386000, 'num_agent_steps_trained': 386000}, 'sampler_results': {'episode_reward_max': -0.7415956525977341, 'episode_reward_min': -4.759783978019843, 'episode_reward_mean': -1.767437937064073, 'episode_len_mean': 193.0, 'episode_media': {}, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {'default_policy/true_reward_mean': -19.192696013333517, 'default_policy/true_reward_min': -65.25676406871196, 'default_policy/true_reward_max': -0.5196320343559644, 'default_policy/proxy_reward_mean': -1.288696013333518, 'default_policy/proxy_reward_min': -4.116053390593276, 'default_policy/proxy_reward_max': -0.45177669529663705, 'default_policy/modified_reward_mean': -1.767437937064073, 'default_policy/modified_reward_min': -4.759783978019843, 'default_policy/modified_reward_max': -0.7415956525977341, 'default_policy/corr_btw_rewards_mean': 0.5205272384721138, 'default_policy/corr_btw_rewards_min': 0.16998096891723033, 'default_policy/corr_btw_rewards_max': 1.0, 'true_reward_mean': -19.192696013333517, 'true_reward_min': -65.25676406871196, 'true_reward_max': -0.5196320343559644, 'proxy_reward_mean': -1.288696013333518, 'proxy_reward_min': -4.116053390593276, 'proxy_reward_max': -0.45177669529663705, 'modified_reward_mean': -1.767437937064073, 'modified_reward_min': -4.759783978019843, 'modified_reward_max': -0.7415956525977341, 'proxyInfectionSummaryAbsoluteReward_mean': -0.0002751295336787566, 'proxyInfectionSummaryAbsoluteReward_min': -0.0016683937823834209, 'proxyInfectionSummaryAbsoluteReward_max': 0.0, 'proxyLowerStageReward_mean': -0.03139357582038955, 'proxyLowerStageReward_min': -0.061915789991221916, 'proxyLowerStageReward_max': -0.015636098201898284, 'proxySmoothStageChangesReward_mean': -0.07865284974093265, 'proxySmoothStageChangesReward_min': -0.15544041450777202, 'proxySmoothStageChangesReward_max': -0.04145077720207254, 'trueInfectionSummaryAbsoluteReward_mean': -0.0002751295336787566, 'trueInfectionSummaryAbsoluteReward_min': -0.0016683937823834209, 'trueInfectionSummaryAbsoluteReward_max': 0.0, 'truePoliticalReward_mean': -0.009276683937823833, 'truePoliticalReward_min': -0.03295336787564766, 'truePoliticalReward_max': 0.0, 'trueLowerStageReward_mean': -0.03139357582038955, 'trueLowerStageReward_min': -0.061915789991221916, 'trueLowerStageReward_max': -0.015636098201898284, 'trueSmoothStageChangesReward_mean': -0.07865284974093265, 'trueSmoothStageChangesReward_min': -0.15544041450777202, 'trueSmoothStageChangesReward_max': -0.04145077720207254, 'total_modified_reward_mean': -1.767437937064073, 'total_modified_reward_min': -4.759783978019843, 'total_modified_reward_max': -0.7415956525977341}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5335676926843235, 'mean_inference_ms': 1.6724224931281872, 'mean_action_processing_ms': 0.10664043546480263, 'mean_env_wait_ms': 738.0382413958926, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': -0.7415956525977341, 'episode_reward_min': -4.759783978019843, 'episode_reward_mean': -1.767437937064073, 'episode_len_mean': 193.0, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.5335676926843235, 'mean_inference_ms': 1.6724224931281872, 'mean_action_processing_ms': 0.10664043546480263, 'mean_env_wait_ms': 738.0382413958926, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 10, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 386000, 'num_agent_steps_trained': 386000, 'num_env_steps_sampled': 386000, 'num_env_steps_trained': 386000, 'num_env_steps_sampled_this_iter': 3860, 'num_env_steps_trained_this_iter': 3860, 'num_env_steps_sampled_throughput_per_sec': 13.592076829534166, 'num_env_steps_trained_throughput_per_sec': 13.592076829534166, 'timesteps_total': 386000, 'num_steps_trained_this_iter': 3860, 'agent_timesteps_total': 386000, 'timers': {'training_iteration_time_ms': 288613.9, 'sample_time_ms': 287516.047, 'load_time_ms': 5.098, 'load_throughput': 757122.909, 'learn_time_ms': 1076.133, 'learn_throughput': 3586.917, 'synch_weights_time_ms': 15.868}, 'counters': {'num_env_steps_sampled': 386000, 'num_env_steps_trained': 386000, 'num_agent_steps_sampled': 386000, 'num_agent_steps_trained': 386000}, 'done': False, 'episodes_total': 2000, 'training_iteration': 100, 'trial_id': 'default', 'date': '2025-11-05_03-27-12', 'timestamp': 1762342032, 'time_this_iter_s': 284.0148551464081, 'time_total_s': 30850.182185173035, 'pid': 3140418, 'hostname': 'next5.stanford.edu', 'node_ip': '10.79.12.129', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': 'pandemic_env', 'env_config': {'sim_config': PandemicSimConfig(num_persons=500, delta_start_lo=95, delta_start_hi=105, location_configs=[LocationConfig(location_type=<class 'pandemic_simulator.environment.location.home.Home'>, num=150, num_assignees=-1, state_opts={}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.GroceryStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.office.Office'>, num=2, num_assignees=150, state_opts={'visitor_capacity': 0}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.school.School'>, num=10, num_assignees=2, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hospital.Hospital'>, num=1, num_assignees=15, state_opts={'patient_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.store.RetailStore'>, num=2, num_assignees=5, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>, num=2, num_assignees=3, state_opts={'visitor_capacity': 5}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Restaurant'>, num=1, num_assignees=6, state_opts={'visitor_capacity': 30}, extra_opts={}), LocationConfig(location_type=<class 'pandemic_simulator.environment.location.restaurant.Bar'>, num=1, num_assignees=3, state_opts={'visitor_capacity': 30}, extra_opts={})], regulation_compliance_prob=0.99, max_hospital_capacity=5, person_routine_assignment=<pandemic_simulator.script_helpers.person_routines.DefaultPersonRoutineAssignment object at 0x14a5e2512680>), 'sim_opts': PandemicSimOpts(infection_spread_rate_mean=0.021, infection_spread_rate_sigma=0.01, infection_delta_spread_rate_mean=0.03, infection_delta_spread_rate_sigma=0.01, spontaneous_testing_rate=0.3, symp_testing_rate=0.3, critical_testing_rate=1.0, testing_false_positive_rate=0.001, testing_false_negative_rate=0.01, retest_rate=0.033, sim_steps_per_regulation=24, use_contact_tracer=False, contact_tracer_history_size=5, infection_threshold=10), 'pandemic_regulations': [PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=False, practice_good_hygiene=False, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.LOW: 0>: -1, <Risk.HIGH: 1>: -1}, risk_to_avoid_location_types=None, stage=0), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': False}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': False}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=False, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 25, <Risk.LOW: 0>: 50}, risk_to_avoid_location_types=None, stage=1), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.3, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 10, <Risk.LOW: 0>: 25}, risk_to_avoid_location_types=None, stage=2), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': False}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.5, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=3), PandemicRegulation(location_type_to_rule_kwargs={<class 'pandemic_simulator.environment.location.office.Office'>: {'lock': True}, <class 'pandemic_simulator.environment.location.school.School'>: {'lock': True}, <class 'pandemic_simulator.environment.location.hair_salon.HairSalon'>: {'lock': True}, <class 'pandemic_simulator.environment.location.store.RetailStore'>: {'lock': True}, <class 'pandemic_simulator.environment.location.restaurant.Restaurant'>: {'lock': False}, <class 'pandemic_simulator.environment.location.restaurant.Bar'>: {'lock': False}}, business_type_to_rule_kwargs=None, social_distancing=0.7, quarantine=False, quarantine_if_contact_positive=False, quarantine_if_household_quarantined=False, stay_home_if_sick=True, practice_good_hygiene=True, wear_facial_coverings=True, risk_to_avoid_gathering_size={<Risk.HIGH: 1>: 0, <Risk.LOW: 0>: 0}, risk_to_avoid_location_types=None, stage=4)], 'done_fn': <pandemic_simulator.environment.done.TimeLimitDone object at 0x14a6997839a0>, 'reward_fun': 'true', 'true_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2512fe0>, 'proxy_reward_fun': <pandemic_simulator.environment.reward.SumReward object at 0x14a5e2513460>, 'constrain': True, 'four_start': False, 'obs_history_size': 3, 'num_days_in_obs': 8, 'use_safe_policy_actions': False, 'safe_policy': 'S0-4-0', 'horizon': 192, 'env_type': 'pandemic', 'reward_fun_type': 'proxy_reward_fn'}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': True, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'rollout_fragment_length': 386, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 10, 'grad_clip_by': 'global_norm', 'train_batch_size': 3860, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [128, 128], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': 'model_with_discriminator', 'custom_model_config': {'discriminator_depth': 2, 'discriminator_width': 256, 'discriminator_state_dim': 13, 'use_action_for_disc': True, 'use_history_for_disc': False, 'time_dim': 1, 'history_range': (-1, 0)}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, '_enable_learner_api': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x14cbac434700>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'count_steps_by': 'env_steps', 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, 'rl_module_spec': None, '_enable_rl_module_api': False, '_AlgorithmConfig__prior_exploration_config': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 64, 'num_sgd_iter': 5, 'shuffle_sequences': True, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': [[0, 0.1], [500000, 0.01]], 'clip_param': 0.3, 'vf_clip_param': 20, 'vf_share_layers': -1, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'occupancy_measures.envs.pandemic_callbacks.PandemicCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 10}, 'time_since_restore': 30850.182185173035, 'iterations_since_restore': 100, 'perf': {'cpu_util_percent': 9.950985221674877, 'ram_util_percent': 3.6000000000000014}})

=== Final Policy Evaluation ===

=== Evaluating policy at iteration 100 ===
Episode 1 return: -1.5396100315941912
Episode 2 return: -2.6781000495401663
Episode 3 return: -2.698855040567179
Episode 4 return: -1.7596100315941912
Episode 5 return: -1.9973450585131534

Mean return over 5 episodes: -2.13 Â± 0.47

=== Evaluation Summary ===
Final: -2.13 Â± 0.47
